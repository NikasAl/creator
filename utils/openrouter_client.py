#!/usr/bin/env python3
"""
–£–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–ª–∏–µ–Ω—Ç –¥–ª—è OpenRouter API.

–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤—Å–µ–º–∏ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞–º–∏ –ø—Ä–æ–µ–∫—Ç–∞ –≤–º–µ—Å—Ç–æ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è –∫–æ–¥–∞.
–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç retry, rate limiting –∏ –æ–±—Ä–∞–±–æ—Ç–∫—É –æ—à–∏–±–æ–∫.

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    from utils.openrouter_client import OpenRouterClient

    client = OpenRouterClient()
    response = client.chat("–ü—Ä–∏–≤–µ—Ç, –∫–∞–∫ –¥–µ–ª–∞?")
    response = client.chat_with_system("–¢—ã –ø–æ–º–æ—â–Ω–∏–∫", "–í–æ–ø—Ä–æ—Å")
"""

import os
import time
import json
import requests
from typing import Optional, Dict, List, Any, Generator
from dataclasses import dataclass
from pathlib import Path

from .config_loader import ConfigLoader, get_config


@dataclass
class ChatMessage:
    """–°–æ–æ–±—â–µ–Ω–∏–µ –≤ —á–∞—Ç–µ."""
    role: str  # 'system', 'user', 'assistant'
    content: str


@dataclass
class ChatResponse:
    """–û—Ç–≤–µ—Ç –æ—Ç API."""
    content: str
    model: str
    usage: Dict[str, int]
    finish_reason: str
    raw_response: Dict[str, Any]


class OpenRouterClient:
    """
    –£–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–ª–∏–µ–Ω—Ç –¥–ª—è OpenRouter API.

    –ó–∞–º–µ–Ω—è–µ—Ç –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–¥ API-–≤—ã–∑–æ–≤–æ–≤ –≤ 10+ —Ñ–∞–π–ª–∞—Ö –ø—Ä–æ–µ–∫—Ç–∞.
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç:
    - –ü—Ä–æ–∑—Ä–∞—á–Ω—É—é –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—é
    - Retry —Å —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–π –∑–∞–¥–µ—Ä–∂–∫–æ–π
    - Rate limiting
    - Stream-—Ä–µ–∂–∏–º
    - –ü–æ–¥—Å—á—ë—Ç —Ç–æ–∫–µ–Ω–æ–≤ –∏ —Å—Ç–æ–∏–º–æ—Å—Ç–∏

    Examples:
        # –ü—Ä–æ—Å—Ç–µ–π—à–µ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
        client = OpenRouterClient()
        response = client.chat("–†–∞—Å—Å–∫–∞–∂–∏ –æ —Å–µ–±–µ")

        # –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
        response = client.chat_with_system(
            system="–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ Python",
            user="–ö–∞–∫ —Ä–∞–±–æ—Ç–∞—é—Ç –¥–µ–∫–æ—Ä–∞—Ç–æ—Ä—ã?"
        )

        # –ü–æ—Ç–æ–∫–æ–≤—ã–π –≤—ã–≤–æ–¥
        for chunk in client.chat_stream("–ù–∞–ø–∏—à–∏ —Å—Ç–∏—Ö"):
            print(chunk, end='', flush=True)

        # –° –∏—Å—Ç–æ—Ä–∏–µ–π —Å–æ–æ–±—â–µ–Ω–∏–π
        messages = [
            ChatMessage(role="user", content="–ü—Ä–∏–≤–µ—Ç"),
            ChatMessage(role="assistant", content="–ü—Ä–∏–≤–µ—Ç! –ß–µ–º –ø–æ–º–æ—á—å?"),
            ChatMessage(role="user", content="–†–∞—Å—Å–∫–∞–∂–∏ –æ Python"),
        ]
        response = client.chat_messages(messages)
    """

    DEFAULT_BASE_URL = "https://openrouter.ai/api/v1"
    DEFAULT_MODEL = "anthropic/claude-3.5-sonnet"
    DEFAULT_MAX_TOKENS = 4000
    DEFAULT_TEMPERATURE = 0.7
    MAX_RETRIES = 3
    RETRY_DELAY = 2.0  # –ë–∞–∑–æ–≤–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö

    def __init__(
        self,
        config: Optional[ConfigLoader] = None,
        api_key: Optional[str] = None,
        base_url: Optional[str] = None,
        model: Optional[str] = None,
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞.

        Args:
            config: –≠–∫–∑–µ–º–ø–ª—è—Ä ConfigLoader (–µ—Å–ª–∏ None - –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≥–ª–æ–±–∞–ª—å–Ω—ã–π)
            api_key: API –∫–ª—é—á (–µ—Å–ª–∏ None - –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏)
            base_url: Base URL API (–µ—Å–ª–∏ None - –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏)
            model: –ú–æ–¥–µ–ª—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        """
        self.config = config or get_config()

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        or_config = self.config.get_openrouter_config()

        self.api_key = api_key or or_config['api_key']
        self.base_url = base_url or or_config['base_url']
        self.default_model = model or or_config['default_model'].name

        self.headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
            **or_config['headers']
        }

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.total_requests = 0
        self.total_tokens = 0
        self.total_cost = 0.0

    def _make_request(
        self,
        messages: List[Dict[str, str]],
        model: Optional[str] = None,
        max_tokens: Optional[int] = None,
        temperature: Optional[float] = None,
        stream: bool = False,
        **kwargs
    ) -> requests.Response:
        """
        –í—ã–ø–æ–ª–Ω—è–µ—Ç –∑–∞–ø—Ä–æ—Å –∫ API —Å retry-–ª–æ–≥–∏–∫–æ–π.

        Args:
            messages: –°–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π
            model: –ú–æ–¥–µ–ª—å –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
            max_tokens: –ú–∞–∫—Å–∏–º—É–º —Ç–æ–∫–µ–Ω–æ–≤
            temperature: –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
            stream: –ü–æ—Ç–æ–∫–æ–≤—ã–π —Ä–µ–∂–∏–º
            **kwargs: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã

        Returns:
            Response –æ–±—ä–µ–∫—Ç
        """
        model = model or self.default_model
        max_tokens = max_tokens or self.DEFAULT_MAX_TOKENS
        temperature = temperature if temperature is not None else self.DEFAULT_TEMPERATURE

        payload = {
            "model": model,
            "messages": messages,
            "max_tokens": max_tokens,
            "temperature": temperature,
            **kwargs
        }

        last_error = None

        for attempt in range(self.MAX_RETRIES):
            try:
                response = requests.post(
                    f"{self.base_url}/chat/completions",
                    headers=self.headers,
                    json=payload,
                    timeout=120,
                    stream=stream
                )

                # –£—Å–ø–µ—à–Ω—ã–π –æ—Ç–≤–µ—Ç
                if response.status_code == 200:
                    self.total_requests += 1
                    return response

                # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫
                error_data = {}
                try:
                    error_data = response.json()
                except:
                    pass

                # Rate limit - –∂–¥—ë–º –¥–æ–ª—å—à–µ
                if response.status_code == 429:
                    retry_after = response.headers.get('Retry-After', 60)
                    wait_time = int(retry_after) if retry_after.isdigit() else 60
                    print(f"‚ö†Ô∏è Rate limited. –ñ–¥—ë–º {wait_time} —Å–µ–∫—É–Ω–¥...")
                    time.sleep(wait_time)
                    continue

                # –û—à–∏–±–∫–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ - –Ω–µ retry
                if response.status_code == 401:
                    raise ValueError(f"–û—à–∏–±–∫–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏: {error_data}")

                # –î—Ä—É–≥–∏–µ –æ—à–∏–±–∫–∏
                error_msg = error_data.get('error', {}).get('message', response.text)
                print(f"‚ùå –û—à–∏–±–∫–∞ API (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{self.MAX_RETRIES}): {response.status_code} - {error_msg}")

                if attempt < self.MAX_RETRIES - 1:
                    wait = self.RETRY_DELAY * (2 ** attempt)  # –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞
                    print(f"   –ü–æ–≤—Ç–æ—Ä —á–µ—Ä–µ–∑ {wait} —Å–µ–∫—É–Ω–¥...")
                    time.sleep(wait)

                last_error = error_msg

            except requests.exceptions.Timeout:
                print(f"‚è±Ô∏è –¢–∞–π–º–∞—É—Ç –∑–∞–ø—Ä–æ—Å–∞ (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{self.MAX_RETRIES})")
                if attempt < self.MAX_RETRIES - 1:
                    wait = self.RETRY_DELAY * (2 ** attempt)
                    time.sleep(wait)
                last_error = "Timeout"

            except requests.exceptions.ConnectionError as e:
                print(f"üåê –û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{self.MAX_RETRIES}): {e}")
                if attempt < self.MAX_RETRIES - 1:
                    wait = self.RETRY_DELAY * (2 ** attempt)
                    time.sleep(wait)
                last_error = str(e)

        raise RuntimeError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å –∑–∞–ø—Ä–æ—Å –ø–æ—Å–ª–µ {self.MAX_RETRIES} –ø–æ–ø—ã—Ç–æ–∫: {last_error}")

    def chat(
        self,
        user_message: str,
        model: Optional[str] = None,
        max_tokens: Optional[int] = None,
        temperature: Optional[float] = None,
        **kwargs
    ) -> str:
        """
        –ü—Ä–æ—Å—Ç–æ–π —á–∞—Ç-–∑–∞–ø—Ä–æ—Å.

        Args:
            user_message: –°–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            model: –ú–æ–¥–µ–ª—å (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            max_tokens: –ú–∞–∫—Å–∏–º—É–º —Ç–æ–∫–µ–Ω–æ–≤
            temperature: –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞

        Returns:
            –¢–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞
        """
        messages = [{"role": "user", "content": user_message}]
        response = self._make_request(messages, model, max_tokens, temperature, **kwargs)

        data = response.json()
        content = data['choices'][0]['message']['content']

        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        if 'usage' in data:
            self.total_tokens += data['usage'].get('total_tokens', 0)

        return content

    def chat_with_system(
        self,
        system: str,
        user: str,
        model: Optional[str] = None,
        max_tokens: Optional[int] = None,
        temperature: Optional[float] = None,
        **kwargs
    ) -> str:
        """
        –ß–∞—Ç —Å —Å–∏—Å—Ç–µ–º–Ω—ã–º –ø—Ä–æ–º–ø—Ç–æ–º.

        Args:
            system: –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
            user: –°–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            model: –ú–æ–¥–µ–ª—å
            max_tokens: –ú–∞–∫—Å–∏–º—É–º —Ç–æ–∫–µ–Ω–æ–≤
            temperature: –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞

        Returns:
            –¢–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞
        """
        messages = [
            {"role": "system", "content": system},
            {"role": "user", "content": user}
        ]
        response = self._make_request(messages, model, max_tokens, temperature, **kwargs)

        data = response.json()
        content = data['choices'][0]['message']['content']

        if 'usage' in data:
            self.total_tokens += data['usage'].get('total_tokens', 0)

        return content

    def chat_messages(
        self,
        messages: List[Any],
        model: Optional[str] = None,
        max_tokens: Optional[int] = None,
        temperature: Optional[float] = None,
        **kwargs
    ) -> ChatResponse:
        """
        –ß–∞—Ç —Å –ø–æ–ª–Ω–æ–π –∏—Å—Ç–æ—Ä–∏–µ–π —Å–æ–æ–±—â–µ–Ω–∏–π.

        Args:
            messages: –°–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π (—Å–ª–æ–≤–∞—Ä–∏ –∏–ª–∏ ChatMessage –æ–±—ä–µ–∫—Ç—ã)
            model: –ú–æ–¥–µ–ª—å
            max_tokens: –ú–∞–∫—Å–∏–º—É–º —Ç–æ–∫–µ–Ω–æ–≤
            temperature: –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞

        Returns:
            ChatResponse —Å –ø–æ–ª–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
        """
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º ChatMessage –≤ —Å–ª–æ–≤–∞—Ä–∏ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        formatted_messages = []
        for msg in messages:
            if isinstance(msg, ChatMessage):
                formatted_messages.append({"role": msg.role, "content": msg.content})
            elif isinstance(msg, dict):
                formatted_messages.append(msg)
            else:
                raise ValueError(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ç–∏–ø —Å–æ–æ–±—â–µ–Ω–∏—è: {type(msg)}")

        response = self._make_request(formatted_messages, model, max_tokens, temperature, **kwargs)
        data = response.json()

        content = data['choices'][0]['message']['content']
        usage = data.get('usage', {})
        finish_reason = data['choices'][0].get('finish_reason', 'unknown')
        response_model = data.get('model', model or self.default_model)

        if usage:
            self.total_tokens += usage.get('total_tokens', 0)

        return ChatResponse(
            content=content,
            model=response_model,
            usage=usage,
            finish_reason=finish_reason,
            raw_response=data
        )

    def chat_stream(
        self,
        user_message: str,
        model: Optional[str] = None,
        max_tokens: Optional[int] = None,
        temperature: Optional[float] = None,
        **kwargs
    ) -> Generator[str, None, None]:
        """
        –ü–æ—Ç–æ–∫–æ–≤—ã–π —á–∞—Ç.

        Yields:
            –ß–∞–Ω–∫–∏ —Ç–µ–∫—Å—Ç–∞ –ø–æ –º–µ—Ä–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        """
        messages = [{"role": "user", "content": user_message}]
        response = self._make_request(messages, model, max_tokens, temperature, stream=True, **kwargs)

        for line in response.iter_lines():
            if line:
                line = line.decode('utf-8')
                if line.startswith('data: '):
                    data_str = line[6:]
                    if data_str == '[DONE]':
                        break
                    try:
                        data = json.loads(data_str)
                        if 'choices' in data and len(data['choices']) > 0:
                            delta = data['choices'][0].get('delta', {})
                            if 'content' in delta:
                                yield delta['content']
                    except json.JSONDecodeError:
                        continue

    def get_stats(self) -> Dict[str, Any]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è."""
        return {
            'total_requests': self.total_requests,
            'total_tokens': self.total_tokens,
            'estimated_cost': self.total_cost,
        }

    def __repr__(self) -> str:
        return f"OpenRouterClient(model={self.default_model}, requests={self.total_requests})"


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞
_global_client: Optional[OpenRouterClient] = None


def get_client(config: Optional[ConfigLoader] = None, reload: bool = False) -> OpenRouterClient:
    """
    –ü–æ–ª—É—á–∞–µ—Ç –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –∫–ª–∏–µ–Ω—Ç–∞.

    Args:
        config: ConfigLoader (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        reload: –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –ø–µ—Ä–µ—Å–æ–∑–¥–∞—Ç—å

    Returns:
        –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä OpenRouterClient
    """
    global _global_client

    if _global_client is None or reload:
        _global_client = OpenRouterClient(config)

    return _global_client


# === CLI –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è ===
if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ OpenRouter API")
    parser.add_argument("prompt", help="–ü—Ä–æ–º–ø—Ç –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏")
    parser.add_argument("--model", help="–ú–æ–¥–µ–ª—å –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è")
    parser.add_argument("--system", help="–°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç")
    parser.add_argument("--stream", action="store_true", help="–ü–æ—Ç–æ–∫–æ–≤—ã–π —Ä–µ–∂–∏–º")
    parser.add_argument("--max-tokens", type=int, default=1000, help="–ú–∞–∫—Å–∏–º—É–º —Ç–æ–∫–µ–Ω–æ–≤")
    parser.add_argument("--temperature", type=float, default=0.7, help="–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞")

    args = parser.parse_args()

    client = OpenRouterClient()

    print(f"ü§ñ –ú–æ–¥–µ–ª—å: {args.model or client.default_model}")
    print(f"üìù –ü—Ä–æ–º–ø—Ç: {args.prompt[:100]}...")
    print()

    if args.stream:
        print("üì§ –û—Ç–≤–µ—Ç (stream):")
        for chunk in client.chat_stream(
            args.prompt,
            model=args.model,
            max_tokens=args.max_tokens,
            temperature=args.temperature
        ):
            print(chunk, end='', flush=True)
        print()
    elif args.system:
        print(f"üìã –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç: {args.system[:100]}...")
        response = client.chat_with_system(
            system=args.system,
            user=args.prompt,
            model=args.model,
            max_tokens=args.max_tokens,
            temperature=args.temperature
        )
        print(f"üì§ –û—Ç–≤–µ—Ç:\n{response}")
    else:
        response = client.chat(
            args.prompt,
            model=args.model,
            max_tokens=args.max_tokens,
            temperature=args.temperature
        )
        print(f"üì§ –û—Ç–≤–µ—Ç:\n{response}")

    print()
    print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {client.get_stats()}")
