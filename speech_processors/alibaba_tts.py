import os
import argparse
from dotenv import load_dotenv
import dashscope
import base64
import re
import tempfile
import soundfile as sf
import numpy as np

# === –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è ===
load_dotenv('config.env')

# === –ö–ª—é—á–∏ –¥–ª—è Alibaba Cloud ===
ALIBABA_API_KEY = os.getenv("ALIBABA_API_KEY")
ALIBABA_BASE_URL = os.getenv("ALIBABA_BASE_URL", "https://dashscope-intl.aliyuncs.com/api/v1")

dashscope.base_http_api_url = ALIBABA_BASE_URL

if not ALIBABA_API_KEY:
    raise ValueError("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω ALIBABA_API_KEY –≤ config.env")

# === –ê—Ä–≥—É–º–µ–Ω—Ç—ã –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏ ===
def parse_args():
    parser = argparse.ArgumentParser(description="–°–∏–Ω—Ç–µ–∑ —Ä–µ—á–∏ —Å –ø–æ–º–æ—â—å—é Alibaba Cloud Qwen TTS")
    parser.add_argument("text_file", help="–ü—É—Ç—å –∫ —Ç–µ–∫—Å—Ç–æ–≤–æ–º—É —Ñ–∞–π–ª—É –¥–ª—è —Å–∏–Ω—Ç–µ–∑–∞")
    parser.add_argument("--voice", default="Cherry", help="–ì–æ–ª–æ—Å –¥–ª—è —Å–∏–Ω—Ç–µ–∑–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: Cherry)")
    parser.add_argument("--language", default="Auto", help="–Ø–∑—ã–∫ –¥–ª—è —Å–∏–Ω—Ç–µ–∑–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: Auto)")
    parser.add_argument("--output", default="output.wav", help="–ò–º—è –≤—ã—Ö–æ–¥–Ω–æ–≥–æ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: output.wav)")
    return parser.parse_args()

# === –°–∏–Ω—Ç–µ–∑ —Ä–µ—á–∏ —á–µ—Ä–µ–∑ Alibaba Cloud Qwen TTS ===
TEMP_DIR = os.path.join(tempfile.gettempdir(), "alibaba_tts")

# –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –ø—Ä–∏ –∏–º–ø–æ—Ä—Ç–µ
os.makedirs(TEMP_DIR, exist_ok=True)


def split_text_into_chunks(text, max_chars=500):
    """
    –†–∞–∑–±–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ —á–∞–Ω–∫–∏ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏—Ö –≥—Ä–∞–Ω–∏—Ü.
    –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ —á–∞–Ω–∫–∞ - 500 —Å–∏–º–≤–æ–ª–æ–≤ (–±–µ–∑–æ–ø–∞—Å–Ω—ã–π –ª–∏–º–∏—Ç –¥–ª—è Alibaba TTS).
    """
    # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ –ø–µ—Ä–µ–Ω–æ—Å—ã –≤ –Ω–∞—á–∞–ª–µ/–∫–æ–Ω—Ü–µ
    text = text.strip()
    
    # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –∞–±–∑–∞—Ü—ã –ø–æ –ø—É—Å—Ç—ã–º —Å—Ç—Ä–æ–∫–∞–º
    paragraphs = re.split(r'\n\s*\n', text)
    
    chunks = []
    current_chunk = ""
    
    for paragraph in paragraphs:
        paragraph = paragraph.strip()
        if not paragraph:
            continue
            
        # –ï—Å–ª–∏ –∞–±–∑–∞—Ü —Å–∞–º –ø–æ —Å–µ–±–µ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π, —Ä–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
        if len(paragraph) > max_chars:
            # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è, —Å–æ—Ö—Ä–∞–Ω—è—è –∑–Ω–∞–∫–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è
            sentences = re.split(r'(?<=[.!?])\s+', paragraph)
            for sentence in sentences:
                sentence = sentence.strip()
                if not sentence:
                    continue
                    
                if len(current_chunk) + len(sentence) + 1 <= max_chars:
                    if current_chunk:
                        current_chunk += " " + sentence
                    else:
                        current_chunk = sentence
                else:
                    if current_chunk:
                        chunks.append(current_chunk)
                    current_chunk = sentence
        else:
            # –ï—Å–ª–∏ —Ç–µ–∫—É—â–∏–π —á–∞–Ω–∫ + –∞–±–∑–∞—Ü –Ω–µ –ø—Ä–µ–≤—ã—à–∞—é—Ç –ª–∏–º–∏—Ç - –¥–æ–±–∞–≤–ª—è–µ–º
            if len(current_chunk) + len(paragraph) + 2 <= max_chars:
                if current_chunk:
                    current_chunk += "\n\n" + paragraph
                else:
                    current_chunk = paragraph
            else:
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—É—â–∏–π —á–∞–Ω–∫ –∏ –Ω–∞—á–∏–Ω–∞–µ–º –Ω–æ–≤—ã–π
                if current_chunk:
                    chunks.append(current_chunk)
                current_chunk = paragraph
    
    # –ù–µ –∑–∞–±—ã–≤–∞–µ–º –¥–æ–±–∞–≤–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–π —á–∞–Ω–∫
    if current_chunk:
        chunks.append(current_chunk)
    
    return chunks


def synthesize_speech_chunk(text, voice, language):
    """
    –°–∏–Ω—Ç–µ–∑–∏—Ä—É–µ—Ç —Ä–µ—á—å –¥–ª—è –æ–¥–Ω–æ–≥–æ —á–∞–Ω–∫–∞ —Ç–µ–∫—Å—Ç–∞.
    
    Returns:
        numpy array audio data or None on failure
    """
    try:
        response = dashscope.MultiModalConversation.call(
            model="qwen3-tts-flash-2025-09-18",
            api_key=ALIBABA_API_KEY,
            text=text,
            voice=voice,
            language_type=language,
            stream=False
        )
        
        if response.status_code == 200:
            # –ü–æ–ª—É—á–∞–µ–º URL –∫ –∞—É–¥–∏–æ—Ñ–∞–π–ª—É
            audio_url = response.output.audio.url
            
            # –°–∫–∞—á–∏–≤–∞–µ–º –∞—É–¥–∏–æ—Ñ–∞–π–ª
            import requests
            audio_response = requests.get(audio_url)
            audio_response.raise_for_status()
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∞—É–¥–∏–æ –≤ –ø–∞–º—è—Ç—å
            audio_data, sample_rate = sf.read(io.BytesIO(audio_response.content))
            
            # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –∞—É–¥–∏–æ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
            if len(audio_data.shape) > 1:
                audio_data = audio_data.mean(axis=1)  # –º–æ–Ω–æ
            
            return audio_data, sample_rate
        else:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∏–Ω—Ç–µ–∑–µ —Ä–µ—á–∏ –¥–ª—è —á–∞–Ω–∫–∞: {response.code} - {response.message}")
            return None, None
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ Alibaba Cloud API –¥–ª—è —á–∞–Ω–∫–∞: {e}")
        return None, None


def synthesize_speech(text, voice, language, output_file):
    """
    –°–∏–Ω—Ç–µ–∑–∏—Ä—É–µ—Ç —Ä–µ—á—å —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Alibaba Cloud Qwen TTS —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –¥–ª–∏–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤.
    –¢–µ–∫—Å—Ç —Ä–∞–∑–±–∏–≤–∞–µ—Ç—Å—è –Ω–∞ —á–∞–Ω–∫–∏, –∫–∞–∂–¥—ã–π –∏–∑ –∫–æ—Ç–æ—Ä—ã—Ö —Å–∏–Ω—Ç–µ–∑–∏—Ä—É–µ—Ç—Å—è –æ—Ç–¥–µ–ª—å–Ω–æ, –∑–∞—Ç–µ–º –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç—Å—è.
    
    Args:
        text: –¢–µ–∫—Å—Ç –¥–ª—è —Å–∏–Ω—Ç–µ–∑–∞
        voice: –í—ã–±—Ä–∞–Ω–Ω—ã–π –≥–æ–ª–æ—Å
        language: –Ø–∑—ã–∫ —Å–∏–Ω—Ç–µ–∑–∞
        output_file: –ü—É—Ç—å –∫ –≤—ã—Ö–æ–¥–Ω–æ–º—É —Ñ–∞–π–ª—É
    """
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–ª–∏–Ω—É —Ç–µ–∫—Å—Ç–∞
    if len(text) <= 600:
        print(f"–¢–µ–∫—Å—Ç –∫–æ—Ä–æ—á–µ 600 —Å–∏–º–≤–æ–ª–æ–≤, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä—è–º–æ–π —Å–∏–Ω—Ç–µ–∑...")
        return synthesize_speech_chunk(text, voice, language)[0] is not None
    
    # –†–∞–∑–±–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –Ω–∞ —á–∞–Ω–∫–∏
    chunks = split_text_into_chunks(text, max_chars=500)
    print(f"–¢–µ–∫—Å—Ç —Ä–∞–∑–±–∏—Ç –Ω–∞ {len(chunks)} —á–∞—Å—Ç–µ–π –¥–ª—è —Å–∏–Ω—Ç–µ–∑–∞")
    
    audio_chunks = []
    sample_rate = None
    pause_duration = int(0.3 * 48000)  # 0.3 —Å–µ–∫—É–Ω–¥—ã –ø–∞—É–∑—ã –º–µ–∂–¥—É —á–∞—Å—Ç—è–º–∏ (48–∫–ì—Ü)
    
    for i, chunk in enumerate(chunks):
        print(f"–°–∏–Ω—Ç–µ–∑ —Ä–µ—á–∏ –¥–ª—è —á–∞—Å—Ç–∏ {i+1}/{len(chunks)} ({len(chunk)} —Å–∏–º–≤–æ–ª–æ–≤)...")
        
        audio_data, sr = synthesize_speech_chunk(chunk, voice, language)
        
        if audio_data is None:
            print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–∏–Ω—Ç–µ–∑–∏—Ä–æ–≤–∞—Ç—å —á–∞—Å—Ç—å {i+1}")
            continue
        
        if sample_rate is None:
            sample_rate = sr
        
        audio_chunks.append(audio_data)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø–∞—É–∑—É –º–µ–∂–¥—É —á–∞—Å—Ç—è–º–∏ (–∫—Ä–æ–º–µ –ø–æ—Å–ª–µ–¥–Ω–µ–π)
        if i < len(chunks) - 1:
            pause = np.zeros(pause_duration, dtype=np.float32)
            audio_chunks.append(pause)
    
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ –∞—É–¥–∏–æ —á–∞–Ω–∫–∏
    if audio_chunks:
        full_audio = np.concatenate(audio_chunks)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–µ –∞—É–¥–∏–æ
        try:
            sf.write(output_file, full_audio, sample_rate)
            print(f"‚úÖ –ê—É–¥–∏–æ —É—Å–ø–µ—à–Ω–æ —Å–∏–Ω—Ç–µ–∑–∏—Ä–æ–≤–∞–Ω–æ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ –∫–∞–∫ '{output_file}'")
            return True
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞: {e}")
            return False
    else:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–∏–Ω—Ç–µ–∑–∏—Ä–æ–≤–∞—Ç—å –Ω–∏ –æ–¥–Ω—É —á–∞—Å—Ç—å —Ç–µ–∫—Å—Ç–∞")
        return False

# === –û—Å–Ω–æ–≤–Ω–æ–π –∑–∞–ø—É—Å–∫ ===
if __name__ == "__main__":
    args = parse_args()

    # –ß–∏—Ç–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ —Ñ–∞–π–ª–∞
    try:
        with open(args.text_file, "r", encoding="utf-8") as f:
            text = f.read()
        print(f"üìÑ –¢–µ–∫—Å—Ç –∑–∞–≥—Ä—É–∂–µ–Ω –∏–∑ '{args.text_file}' ({len(text)} —Å–∏–º–≤–æ–ª–æ–≤)")
    except FileNotFoundError:
        print(f"‚ùå –§–∞–π–ª '{args.text_file}' –Ω–µ –Ω–∞–π–¥–µ–Ω.")
        exit(1)
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {e}")
        exit(1)

    # –î–æ–±–∞–≤–ª—è–µ–º –∏–º–ø–æ—Ä—Ç
    import io

    # –°–∏–Ω—Ç–µ–∑–∏—Ä—É–µ–º —Ä–µ—á—å
    success = synthesize_speech(text, args.voice, args.language, args.output)
    if not success:
        exit(1)
