import uuid
import requests
import argparse
from dotenv import load_dotenv
import os
import re
import tempfile
import soundfile as sf
import numpy as np
import io

# === –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è ===
load_dotenv('config.env')

AUTHORIZATION_KEY = os.getenv("SBER_SPEECH_KEY")
RQ_UID = str(uuid.uuid4())

if not AUTHORIZATION_KEY:
    raise ValueError("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω AUTHORIZATION_KEY –≤ config.env")

# === –ê—Ä–≥—É–º–µ–Ω—Ç—ã –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏ ===
def parse_args():
    parser = argparse.ArgumentParser(description="–°–∏–Ω—Ç–µ–∑ —Ä–µ—á–∏ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –ø–∞—É–∑ [[PAUSE:—Å–µ–∫—É–Ω–¥—ã]]")
    parser.add_argument("text_file", help="–ü—É—Ç—å –∫ —Ç–µ–∫—Å—Ç–æ–≤–æ–º—É —Ñ–∞–π–ª—É –¥–ª—è —Å–∏–Ω—Ç–µ–∑–∞")
    parser.add_argument("--voice", default="Bys_24000", help="–ì–æ–ª–æ—Å –¥–ª—è —Å–∏–Ω—Ç–µ–∑–∞")
    parser.add_argument("--output", default="output.wav", help="–ò–º—è –≤—ã—Ö–æ–¥–Ω–æ–≥–æ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞")
    return parser.parse_args()

# === –ü–æ–ª—É—á–µ–Ω–∏–µ Access Token ===
def get_access_token():
    url = "https://ngw.devices.sberbank.ru:9443/api/v2/oauth"
    headers = {
        "Content-Type": "application/x-www-form-urlencoded",
        "Accept": "application/json",
        "RqUID": RQ_UID,
        "Authorization": f"Basic {AUTHORIZATION_KEY}"
    }
    data = {"scope": "SALUTE_SPEECH_PERS"}

    try:
        response = requests.post(url, headers=headers, data=data, verify=False)
        response.raise_for_status()
        return response.json().get("access_token")
    except Exception as e:
        print("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Ç–æ–∫–µ–Ω–∞:", e)
        return None

# === –õ–æ–≥–∏–∫–∞ —Ä–∞–∑–±–∏–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ (–æ—Å—Ç–∞–≤–ª–µ–Ω–∞ –≤–∞—à–∞ –ª–æ–≥–∏–∫–∞ –¥–ª—è –¥–ª–∏–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤) ===
def split_text_into_chunks(text, max_chars=3500):
    text = text.strip()
    paragraphs = re.split(r'\n\s*\n', text)
    chunks = []
    current_chunk = ""

    for paragraph in paragraphs:
        paragraph = paragraph.strip()
        if not paragraph: continue

        if len(paragraph) > max_chars:
            sentences = re.split(r'(?<=[.!?])\s+', paragraph)
            for sentence in sentences:
                sentence = sentence.strip()
                if not sentence: continue
                if len(current_chunk) + len(sentence) + 1 <= max_chars:
                    current_chunk += " " + sentence if current_chunk else sentence
                else:
                    if current_chunk: chunks.append(current_chunk)
                    current_chunk = sentence
        else:
            if len(current_chunk) + len(paragraph) + 2 <= max_chars:
                current_chunk += "\n\n" + paragraph if current_chunk else paragraph
            else:
                if current_chunk: chunks.append(current_chunk)
                current_chunk = paragraph

    if current_chunk: chunks.append(current_chunk)
    return chunks

# === –°–∏–Ω—Ç–µ–∑ –∫—É—Å–∫–∞ —Ç–µ–∫—Å—Ç–∞ ===
def synthesize_speech_chunk(token, text, voice):
    url = "https://smartspeech.sber.ru/rest/v1/text:synthesize"
    headers = {
        "Authorization": f"Bearer {token}",
        "Content-Type": "application/text" # –î–ª—è —è–≤–Ω–æ–≥–æ SSML –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å application/ssml, –Ω–æ text —Ç–æ–∂–µ —Ä–∞–±–æ—Ç–∞–µ—Ç
    }
    params = {"voice": voice, "format": "wav16"}

    # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–±–æ—Ä–∞—á–∏–≤–∞–µ–º –≤ speak, –µ—Å–ª–∏ –µ—Å—Ç—å —Ç–µ–≥–∏, –Ω–æ –ª—É—á—à–µ –≤—Å–µ–≥–¥–∞ –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏
    # –ù–æ –µ—Å–ª–∏ –º—ã —à–ª–µ–º —á–∏—Å—Ç—ã–π —Ç–µ–∫—Å—Ç, speak –Ω–µ –ø–æ–≤—Ä–µ–¥–∏—Ç
    payload = text.strip()

    try:
        response = requests.post(
            url, headers=headers, data=payload, params=params, stream=True,
            verify="/etc/ssl/certs/ca-certificates.crt"
            # verify=False # –†–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ, –µ—Å–ª–∏ –ø—Ä–æ–±–ª–µ–º—ã —Å SSL
        )
        response.raise_for_status()
        audio_data, sample_rate = sf.read(io.BytesIO(response.content))
        if len(audio_data.shape) > 1: audio_data = audio_data.mean(axis=1)
        return audio_data, sample_rate
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–∏–Ω—Ç–µ–∑–∞ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞: {e}")
        return None, None

# === –ì–õ–ê–í–ù–ê–Ø –ù–û–í–ê–Ø –§–£–ù–ö–¶–ò–Ø ===
def process_text_with_pauses(token, text, voice):
    """
    –†–∞–∑–±–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –ø–æ –º–∞—Ä–∫–µ—Ä–∞–º [[PAUSE:X]], —Å–∏–Ω—Ç–µ–∑–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç –∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–∏—à–∏–Ω—É.
    """
    # –†–µ–≥—É–ª—è—Ä–∫–∞ –∏—â–µ—Ç [[PAUSE:—á–∏—Å–ª–æ]] –∏–ª–∏ [[PAUSE:—á–∏—Å–ª–æ.—á–∏—Å–ª–æ]]
    # –ì—Ä—É–ø–ø–∞ –∑–∞—Ö–≤–∞—Ç–∞ (r'...') –ø–æ–∑–≤–æ–ª—è–µ—Ç re.split —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏ –≤ —Å–ø–∏—Å–∫–µ
    parts = re.split(r'(\[\[PAUSE:\s*[\d\.]+\]\])', text)

    full_audio_parts = []
    sample_rate = 48000 # –î–µ—Ñ–æ–ª—Ç, –æ–±–Ω–æ–≤–∏—Ç—Å—è –ø–æ—Å–ª–µ –ø–µ—Ä–≤–æ–≥–æ —Å–∏–Ω—Ç–µ–∑–∞ –∏–ª–∏ –æ—Å—Ç–∞–Ω–µ—Ç—Å—è —Ç–∞–∫–∏–º –¥–ª—è —Ç–∏—à–∏–Ω—ã

    print(f"üîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞: –Ω–∞–π–¥–µ–Ω–æ {len(parts)} —Å–µ–≥–º–µ–Ω—Ç–æ–≤ (—Ç–µ–∫—Å—Ç + –ø–∞—É–∑—ã)")

    for part in parts:
        part = part.strip()
        if not part:
            continue

        # –ü—Ä–æ–≤–µ—Ä–∫–∞: —ç—Ç–æ –º–∞—Ä–∫–µ—Ä –ø–∞—É–∑—ã?
        pause_match = re.match(r'\[\[PAUSE:\s*([\d\.]+)\]\]', part)

        if pause_match:
            # === –ì–ï–ù–ï–†–ê–¶–ò–Ø –¢–ò–®–ò–ù–´ ===
            seconds = float(pause_match.group(1))
            print(f"‚è≥ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–∞—É–∑—ã: {seconds} —Å–µ–∫.")
            num_samples = int(seconds * sample_rate)
            silence = np.zeros(num_samples, dtype=np.float32)
            full_audio_parts.append(silence)
        else:
            # === –°–ò–ù–¢–ï–ó –¢–ï–ö–°–¢–ê ===
            # –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç –≤–Ω—É—Ç—Ä–∏ —Å–µ–≥–º–µ–Ω—Ç–∞ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞—Ä—ã–π —Å–ø–ª–∏—Ç—Ç–µ—Ä
            sub_chunks = split_text_into_chunks(part)

            for sub_chunk in sub_chunks:
                print(f"üéô –°–∏–Ω—Ç–µ–∑ —Ç–µ–∫—Å—Ç–∞ ({len(sub_chunk)} —Å–∏–º–≤)...")
                audio, sr = synthesize_speech_chunk(token, sub_chunk, voice)
                if audio is not None:
                    sample_rate = sr # –û–±–Ω–æ–≤–ª—è–µ–º SR –æ—Ç —Ä–µ–∞–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ API
                    full_audio_parts.append(audio)
                    # –ú–∞–ª–µ–Ω—å–∫–∞—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É —Å–∫–ª–µ–π–∫–∞–º–∏ —Ç–µ–∫—Å—Ç–∞ (0.1—Å), —á—Ç–æ–±—ã –Ω–µ –≥–ª–æ—Ç–∞–ª–∏—Å—å –æ–∫–æ–Ω—á–∞–Ω–∏—è
                    full_audio_parts.append(np.zeros(int(0.1 * sr), dtype=np.float32))

    if not full_audio_parts:
        return None, None

    return np.concatenate(full_audio_parts), sample_rate

# === –û—Å–Ω–æ–≤–Ω–æ–π –∑–∞–ø—É—Å–∫ ===
if __name__ == "__main__":
    args = parse_args()

    try:
        with open(args.text_file, "r", encoding="utf-8") as f:
            text = f.read()
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Ñ–∞–π–ª–∞: {e}")
        exit(1)

    token = get_access_token()
    if token:
        print("üöÄ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É...")
        final_audio, sr = process_text_with_pauses(token, text, args.voice)

        if final_audio is not None:
            sf.write(args.output, final_audio, sr)
            print(f"‚úÖ –ì–æ—Ç–æ–≤–æ! –§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {args.output}")
        else:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –∞—É–¥–∏–æ.")