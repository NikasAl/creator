#!/usr/bin/env python3
"""
ĞĞ½Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ‚Ğ¾Ñ€ Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½Ğ° Ğ´Ğ»Ñ Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ñ Ğ¼ĞµÑ‚Ğ°Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ²Ğ¸Ğ´ĞµĞ¾
"""

import json
import re
from pathlib import Path
from typing import Dict, Any, Optional, List, Tuple
from dataclasses import dataclass


@dataclass
class PipelineMetadata:
    """ĞœĞµÑ‚Ğ°Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¸Ğ· Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½Ğ°"""
    pipeline_name: str
    video_path: str
    promo_description: Optional[str] = None
    illustrations: Optional[List[Dict]] = None
    clean_text: Optional[str] = None
    summary_text: Optional[str] = None
    short_summary: Optional[str] = None
    book_title: Optional[str] = None
    book_author: Optional[str] = None
    page_range: Optional[str] = None
    
    def has_video(self) -> bool:
        """ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµÑ‚ Ğ½Ğ°Ğ»Ğ¸Ñ‡Ğ¸Ğµ Ğ²Ğ¸Ğ´ĞµĞ¾Ñ„Ğ°Ğ¹Ğ»Ğ°"""
        return Path(self.video_path).exists() if self.video_path else False
    
    def has_promo_description(self) -> bool:
        """ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµÑ‚ Ğ½Ğ°Ğ»Ğ¸Ñ‡Ğ¸Ğµ Ğ¿Ñ€Ğ¾Ğ¼Ğ¾-Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ñ"""
        return bool(self.promo_description and self.promo_description.strip())
    
    def has_illustrations(self) -> bool:
        """ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµÑ‚ Ğ½Ğ°Ğ»Ğ¸Ñ‡Ğ¸Ğµ Ğ¸Ğ»Ğ»ÑÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ğ¹"""
        return bool(self.illustrations and len(self.illustrations) > 0)


class PipelineAnalyzer:
    """ĞĞ½Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ‚Ğ¾Ñ€ Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½Ğ° Ğ´Ğ»Ñ Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ñ Ğ¼ĞµÑ‚Ğ°Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…"""
    
    def __init__(self, pipeline_path: str):
        """
        Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ‚Ğ¾Ñ€Ğ°
        
        Args:
            pipeline_path: ĞŸÑƒÑ‚ÑŒ Ğº Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ¸ Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½Ğ°
        """
        self.pipeline_path = Path(pipeline_path)
        self.metadata = None
        
    def analyze(self) -> PipelineMetadata:
        """
        ĞĞ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½ Ğ¸ Ğ¸Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµÑ‚ Ğ¼ĞµÑ‚Ğ°Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ
        
        Returns:
            ĞœĞµÑ‚Ğ°Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½Ğ°
        """
        if not self.pipeline_path.exists():
            raise FileNotFoundError(f"Ğ”Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ñ Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½Ğ° Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ°: {self.pipeline_path}")
        
        # Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµĞ¼ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½Ğ° Ğ¸Ğ· Ğ¿ÑƒÑ‚Ğ¸
        pipeline_name = self.pipeline_path.name
        
        # Ğ˜Ñ‰ĞµĞ¼ Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ñ‹Ğµ Ñ„Ğ°Ğ¹Ğ»Ñ‹
        video_path = self._find_video_file()
        promo_description = self._read_promo_description()
        illustrations = self._read_illustrations()
        clean_text = self._read_clean_text()
        summary_text = self._read_summary_text()
        short_summary = self._read_short_summary()
        
        # Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµĞ¼ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¾ ĞºĞ½Ğ¸Ğ³Ğµ Ğ¸Ğ· Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½Ğ°
        book_title, book_author, page_range = self._extract_book_info(pipeline_name)
        
        self.metadata = PipelineMetadata(
            pipeline_name=pipeline_name,
            video_path=str(video_path) if video_path else "",
            promo_description=promo_description,
            illustrations=illustrations,
            clean_text=clean_text,
            summary_text=summary_text,
            short_summary=short_summary,
            book_title=book_title,
            book_author=book_author,
            page_range=page_range
        )
        
        return self.metadata
    
    def _find_video_file(self) -> Optional[Path]:
        """Ğ˜Ñ‰ĞµÑ‚ Ğ²Ğ¸Ğ´ĞµĞ¾Ñ„Ğ°Ğ¹Ğ» Ğ² Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½Ğµ"""
        video_extensions = ['.mp4', '.avi', '.mov', '.mkv', '.webm']
        
        for ext in video_extensions:
            video_file = self.pipeline_path / f"video{ext}"
            if video_file.exists():
                return video_file
        
        return None
    
    def _read_promo_description(self) -> Optional[str]:
        """Ğ§Ğ¸Ñ‚Ğ°ĞµÑ‚ Ğ¿Ñ€Ğ¾Ğ¼Ğ¾-Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ"""
        promo_file = self.pipeline_path / "promo_description.txt"
        
        if promo_file.exists():
            try:
                with open(promo_file, 'r', encoding='utf-8') as f:
                    return f.read().strip()
            except Exception as e:
                print(f"âš ï¸  ĞÑˆĞ¸Ğ±ĞºĞ° Ñ‡Ñ‚ĞµĞ½Ğ¸Ñ Ğ¿Ñ€Ğ¾Ğ¼Ğ¾-Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ñ: {e}")
        
        return None
    
    def _read_illustrations(self) -> Optional[List[Dict]]:
        """Ğ§Ğ¸Ñ‚Ğ°ĞµÑ‚ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¾Ğ± Ğ¸Ğ»Ğ»ÑÑÑ‚Ñ€Ğ°Ñ†Ğ¸ÑÑ…"""
        illustrations_file = self.pipeline_path / "illustrations.json"
        
        if illustrations_file.exists():
            try:
                with open(illustrations_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    return data.get('illustrations', [])
            except Exception as e:
                print(f"âš ï¸  ĞÑˆĞ¸Ğ±ĞºĞ° Ñ‡Ñ‚ĞµĞ½Ğ¸Ñ Ğ¸Ğ»Ğ»ÑÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ğ¹: {e}")
        
        return None
    
    def _read_clean_text(self) -> Optional[str]:
        """Ğ§Ğ¸Ñ‚Ğ°ĞµÑ‚ Ğ¾Ñ‡Ğ¸Ñ‰ĞµĞ½Ğ½Ñ‹Ğ¹ Ñ‚ĞµĞºÑÑ‚"""
        clean_files = list(self.pipeline_path.glob("*_clean.txt"))
        
        if clean_files:
            try:
                with open(clean_files[0], 'r', encoding='utf-8') as f:
                    return f.read().strip()
            except Exception as e:
                print(f"âš ï¸  ĞÑˆĞ¸Ğ±ĞºĞ° Ñ‡Ñ‚ĞµĞ½Ğ¸Ñ Ğ¾Ñ‡Ğ¸Ñ‰ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ñ‚ĞµĞºÑÑ‚Ğ°: {e}")
        
        return None
    
    def _read_summary_text(self) -> Optional[str]:
        """Ğ§Ğ¸Ñ‚Ğ°ĞµÑ‚ Ñ‚ĞµĞºÑÑ‚ Ğ¿ĞµÑ€ĞµÑĞºĞ°Ğ·Ğ°"""
        summary_files = list(self.pipeline_path.glob("*_summary_*.txt"))
        
        if summary_files:
            try:
                with open(summary_files[0], 'r', encoding='utf-8') as f:
                    return f.read().strip()
            except Exception as e:
                print(f"âš ï¸  ĞÑˆĞ¸Ğ±ĞºĞ° Ñ‡Ñ‚ĞµĞ½Ğ¸Ñ Ğ¿ĞµÑ€ĞµÑĞºĞ°Ğ·Ğ°: {e}")
        
        return None
    
    def _read_short_summary(self) -> Optional[str]:
        """Ğ§Ğ¸Ñ‚Ğ°ĞµÑ‚ ĞºÑ€Ğ°Ñ‚ĞºÑƒÑ ÑĞ²Ğ¾Ğ´ĞºÑƒ"""
        short_summary_files = list(self.pipeline_path.glob("*_short_summary.txt"))
        
        if short_summary_files:
            try:
                with open(short_summary_files[0], 'r', encoding='utf-8') as f:
                    return f.read().strip()
            except Exception as e:
                print(f"âš ï¸  ĞÑˆĞ¸Ğ±ĞºĞ° Ñ‡Ñ‚ĞµĞ½Ğ¸Ñ ĞºÑ€Ğ°Ñ‚ĞºĞ¾Ğ¹ ÑĞ²Ğ¾Ğ´ĞºĞ¸: {e}")
        
        return None
    
    def _extract_book_info(self, pipeline_name: str) -> Tuple[Optional[str], Optional[str], Optional[str]]:
        """
        Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµÑ‚ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¾ ĞºĞ½Ğ¸Ğ³Ğµ Ğ¸Ğ· Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½Ğ°
        
        Args:
            pipeline_name: ĞĞ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½Ğ°
            
        Returns:
            ĞšĞ¾Ñ€Ñ‚ĞµĞ¶ (Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ_ĞºĞ½Ğ¸Ğ³Ğ¸, Ğ°Ğ²Ñ‚Ğ¾Ñ€, Ğ´Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½_ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†)
        """
        book_title = None
        book_author = None
        page_range = None
        
        # Ğ˜Ñ‰ĞµĞ¼ Ğ´Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½ ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ† Ğ² ĞºĞ¾Ğ½Ñ†Ğµ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ñ
        page_match = re.search(r'_(\d+)_(\d+)$', pipeline_name)
        if page_match:
            start_page, end_page = page_match.groups()
            page_range = f"{start_page}-{end_page}"
            # Ğ£Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ Ğ´Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½ ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ† Ğ¸Ğ· Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ñ Ğ´Ğ»Ñ Ğ´Ğ°Ğ»ÑŒĞ½ĞµĞ¹ÑˆĞµĞ³Ğ¾ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°
            pipeline_name = pipeline_name[:page_match.start()]
        
        # ĞŸÑ‹Ñ‚Ğ°ĞµĞ¼ÑÑ Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡ÑŒ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ ĞºĞ½Ğ¸Ğ³Ğ¸ Ğ¸ Ğ°Ğ²Ñ‚Ğ¾Ñ€Ğ° Ğ¸Ğ· Ğ¾ÑÑ‚Ğ°Ğ²ÑˆĞµĞ¹ÑÑ Ñ‡Ğ°ÑÑ‚Ğ¸
        # Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚ Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ±Ñ‹Ñ‚ÑŒ Ñ€Ğ°Ğ·Ğ½Ñ‹Ğ¼, Ğ½Ğ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€:
        # pipeline_LemEng_87_111 -> LemEng
        # pipeline_Gantrip_G_-_Shizoidnye_yavlenia_obektnye_otnoshenia_i_samost_61_90
        
        # Ğ£Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ Ğ¿Ñ€ĞµÑ„Ğ¸ĞºÑ "pipeline_"
        if pipeline_name.startswith("pipeline_"):
            pipeline_name = pipeline_name[9:]  # ÑƒĞ±Ğ¸Ñ€Ğ°ĞµĞ¼ "pipeline_"
        
        # Ğ•ÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ Ğ¿Ğ¾Ğ´Ñ‡ĞµÑ€ĞºĞ¸Ğ²Ğ°Ğ½Ğ¸Ñ, Ğ¿Ñ‹Ñ‚Ğ°ĞµĞ¼ÑÑ Ñ€Ğ°Ğ·Ğ´ĞµĞ»Ğ¸Ñ‚ÑŒ Ğ½Ğ° Ñ‡Ğ°ÑÑ‚Ğ¸
        parts = pipeline_name.split('_')
        
        if len(parts) >= 2:
            # ĞŸĞµÑ€Ğ²Ğ°Ñ Ñ‡Ğ°ÑÑ‚ÑŒ Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ±Ñ‹Ñ‚ÑŒ Ğ°Ğ²Ñ‚Ğ¾Ñ€Ğ¾Ğ¼ Ğ¸Ğ»Ğ¸ Ñ‡Ğ°ÑÑ‚ÑŒÑ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ñ
            potential_author = parts[0]
            
            # Ğ•ÑĞ»Ğ¸ Ğ²Ñ‚Ğ¾Ñ€Ğ°Ñ Ñ‡Ğ°ÑÑ‚ÑŒ Ğ½Ğ°Ñ‡Ğ¸Ğ½Ğ°ĞµÑ‚ÑÑ Ñ Ğ·Ğ°Ğ³Ğ»Ğ°Ğ²Ğ½Ğ¾Ğ¹ Ğ±ÑƒĞºĞ²Ñ‹, ÑÑ‚Ğ¾ Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ±Ñ‹Ñ‚ÑŒ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ
            if len(parts) > 1 and parts[1][0].isupper():
                book_title = ' '.join(parts[1:])
                book_author = potential_author
            else:
                # Ğ˜Ğ½Ğ°Ñ‡Ğµ Ğ²ÑÑ ÑÑ‚Ñ€Ğ¾ĞºĞ° Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ±Ñ‹Ñ‚ÑŒ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼
                book_title = ' '.join(parts)
        
        return book_title, book_author, page_range
    
    def get_available_thumbnails(self) -> List[Path]:
        """ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµÑ‚ ÑĞ¿Ğ¸ÑĞ¾Ğº Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹Ñ… Ğ¿Ñ€ĞµĞ²ÑŒÑ"""
        images_dir = self.pipeline_path / "images"
        
        if not images_dir.exists():
            return []
        
        # Ğ˜Ñ‰ĞµĞ¼ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğµ Ğ¼Ğ¾Ğ³ÑƒÑ‚ ÑĞ»ÑƒĞ¶Ğ¸Ñ‚ÑŒ Ğ¿Ñ€ĞµĞ²ÑŒÑ
        thumbnail_extensions = ['.png', '.jpg', '.jpeg', '.webp']
        thumbnails = []
        
        for ext in thumbnail_extensions:
            thumbnails.extend(images_dir.glob(f"*{ext}"))
        
        return sorted(thumbnails)
    
    def suggest_title(self, max_length: int = 100) -> str:
        """
        ĞŸÑ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ĞµÑ‚ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ»Ñ Ğ²Ğ¸Ğ´ĞµĞ¾ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ¼ĞµÑ‚Ğ°Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
        
        Args:
            max_length: ĞœĞ°ĞºÑĞ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ°Ñ Ğ´Ğ»Ğ¸Ğ½Ğ° Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ñ
            
        Returns:
            ĞŸÑ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ĞµĞ¼Ğ¾Ğµ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ
        """
        if not self.metadata:
            return "Ğ’Ğ¸Ğ´ĞµĞ¾ Ğ¸Ğ· Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½Ğ°"
        
        # Ğ•ÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ ĞºĞ½Ğ¸Ğ³Ğ¸, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ ĞµĞ³Ğ¾
        if self.metadata.book_title:
            title = self.metadata.book_title
            if self.metadata.book_author:
                title = f"{self.metadata.book_author} - {title}"
        else:
            # Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½Ğ°
            title = self.metadata.pipeline_name.replace('_', ' ').title()
        
        # ĞĞ±Ñ€ĞµĞ·Ğ°ĞµĞ¼ Ğ´Ğ¾ Ğ¼Ğ°ĞºÑĞ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğ¹ Ğ´Ğ»Ğ¸Ğ½Ñ‹
        if len(title) > max_length:
            title = title[:max_length-3] + "..."
        
        return title
    
    def suggest_description(self, max_length: int = 5000) -> str:
        """
        ĞŸÑ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ĞµÑ‚ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ Ğ´Ğ»Ñ Ğ²Ğ¸Ğ´ĞµĞ¾
        
        Args:
            max_length: ĞœĞ°ĞºÑĞ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ°Ñ Ğ´Ğ»Ğ¸Ğ½Ğ° Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ñ
            
        Returns:
            ĞŸÑ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ĞµĞ¼Ğ¾Ğµ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ
        """
        if not self.metadata:
            return ""
        
        # Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Ğ¿Ñ€Ğ¾Ğ¼Ğ¾-Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ
        if self.metadata.promo_description:
            description = self.metadata.promo_description
        elif self.metadata.short_summary:
            description = self.metadata.short_summary
        elif self.metadata.summary_text:
            description = self.metadata.summary_text
        else:
            description = "Ğ’Ğ¸Ğ´ĞµĞ¾ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¾ Ğ¸Ğ· Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½Ğ° Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ Ñ‚ĞµĞºÑÑ‚Ğ°."
        
        # ĞĞ±Ñ€ĞµĞ·Ğ°ĞµĞ¼ Ğ´Ğ¾ Ğ¼Ğ°ĞºÑĞ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğ¹ Ğ´Ğ»Ğ¸Ğ½Ñ‹
        if len(description) > max_length:
            description = description[:max_length-3] + "..."
        
        return description
    
    def suggest_tags(self, max_tags: int = 15) -> List[str]:
        """
        ĞŸÑ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ĞµÑ‚ Ñ‚ĞµĞ³Ğ¸ Ğ´Ğ»Ñ Ğ²Ğ¸Ğ´ĞµĞ¾
        
        Args:
            max_tags: ĞœĞ°ĞºÑĞ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ñ‚ĞµĞ³Ğ¾Ğ²
            
        Returns:
            Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ĞµĞ¼Ñ‹Ñ… Ñ‚ĞµĞ³Ğ¾Ğ²
        """
        if not self.metadata:
            return []
        
        tags = []
        
        # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ñ‚ĞµĞ³Ğ¸ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ñ ĞºĞ½Ğ¸Ğ³Ğ¸
        if self.metadata.book_title:
            # Ğ Ğ°Ğ·Ğ±Ğ¸Ğ²Ğ°ĞµĞ¼ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ½Ğ° ÑĞ»Ğ¾Ğ²Ğ° Ğ¸ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ ĞºĞ°Ğº Ñ‚ĞµĞ³Ğ¸
            words = re.findall(r'\b\w+\b', self.metadata.book_title.lower())
            tags.extend([word for word in words if len(word) > 3])
        
        # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ñ‚ĞµĞ³Ğ¸ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ°Ğ²Ñ‚Ğ¾Ñ€Ğ°
        if self.metadata.book_author:
            tags.append(self.metadata.book_author.lower())
        
        # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ¾Ğ±Ñ‰Ğ¸Ğµ Ñ‚ĞµĞ³Ğ¸
        general_tags = [
            "Ğ°ÑƒĞ´Ğ¸Ğ¾ĞºĞ½Ğ¸Ğ³Ğ°", "Ğ¿ĞµÑ€ĞµÑĞºĞ°Ğ·", "Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ", "Ğ½Ğ°ÑƒĞºĞ°", 
            "Ñ„Ğ¸Ğ»Ğ¾ÑĞ¾Ñ„Ğ¸Ñ", "Ğ»Ğ¸Ñ‚ĞµÑ€Ğ°Ñ‚ÑƒÑ€Ğ°", "Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·", "Ğ¾Ğ±Ğ·Ğ¾Ñ€"
        ]
        tags.extend(general_tags)
        
        # Ğ£Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ Ğ´ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ‚Ñ‹ Ğ¸ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡Ğ¸Ğ²Ğ°ĞµĞ¼ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾
        unique_tags = []
        for tag in tags:
            if tag and tag not in unique_tags and len(tag) > 2:
                unique_tags.append(tag)
        
        return unique_tags[:max_tags]
    
    def get_summary(self) -> str:
        """ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµÑ‚ ĞºÑ€Ğ°Ñ‚ĞºÑƒÑ ÑĞ²Ğ¾Ğ´ĞºÑƒ Ğ¾ Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½Ğµ"""
        if not self.metadata:
            return "ĞŸĞ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½ Ğ½Ğµ Ğ¿Ñ€Ğ¾Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½"
        
        summary_parts = []
        
        summary_parts.append(f"ğŸ“ ĞŸĞ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½: {self.metadata.pipeline_name}")
        
        if self.metadata.book_title:
            summary_parts.append(f"ğŸ“š ĞšĞ½Ğ¸Ğ³Ğ°: {self.metadata.book_title}")
            if self.metadata.book_author:
                summary_parts.append(f"ğŸ‘¤ ĞĞ²Ñ‚Ğ¾Ñ€: {self.metadata.book_author}")
        
        if self.metadata.page_range:
            summary_parts.append(f"ğŸ“„ Ğ¡Ñ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ñ‹: {self.metadata.page_range}")
        
        summary_parts.append(f"ğŸ¬ Ğ’Ğ¸Ğ´ĞµĞ¾: {'âœ…' if self.metadata.has_video() else 'âŒ'}")
        summary_parts.append(f"ğŸ“ ĞŸÑ€Ğ¾Ğ¼Ğ¾-Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ: {'âœ…' if self.metadata.has_promo_description() else 'âŒ'}")
        summary_parts.append(f"ğŸ–¼ï¸  Ğ˜Ğ»Ğ»ÑÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ğ¸: {'âœ…' if self.metadata.has_illustrations() else 'âŒ'}")
        
        if self.metadata.has_illustrations():
            summary_parts.append(f"   ĞšĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾: {len(self.metadata.illustrations)}")
        
        return "\n".join(summary_parts)
