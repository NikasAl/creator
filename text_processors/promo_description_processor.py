#!/usr/bin/env python3
"""
–ü—Ä–æ—Ü–µ—Å—Å–æ—Ä –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–æ–º–æ-–æ–ø–∏—Å–∞–Ω–∏—è –∏ —Å—Ç–∞—Ç–µ–π –¥–ª—è –≤–∏–¥–µ–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—Å—Ç–æ–≤ –ø–∞–π–ø–ª–∞–π–Ω–∞

–§—É–Ω–∫—Ü–∏–∏:
- –°–∫–∞–Ω–∏—Ä—É–µ—Ç –∫–∞—Ç–∞–ª–æ–≥ –ø–∞–π–ø–ª–∞–π–Ω–∞ –∏ —Å–æ–±–∏—Ä–∞–µ—Ç .txt —Ñ–∞–π–ª—ã
- –§–æ—Ä–º–∏—Ä—É–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∑–∞–ø—Ä–æ—Å –≤ LLM —á–µ—Ä–µ–∑ OpenRouter
- –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫–æ–Ω—Ç–µ–Ω—Ç –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ–¥ –ø–ª–∞—Ç—Ñ–æ—Ä–º—É (YouTube, Pikabu –∏ —Ç.–¥.)
"""

import os
import sys
import argparse
import time
import json
from pathlib import Path
from typing import List, Dict, Optional, Tuple

import requests
from dotenv import load_dotenv


class PromoDescriptionProcessor:
    def __init__(self, config_file: str = None):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞ —Å –∑–∞–≥—Ä—É–∑–∫–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
        self.load_config(config_file)
        if not self.api_key:
            raise ValueError("API –∫–ª—é—á OpenRouter –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")

        self.base_url = "https://openrouter.ai/api/v1"
        self.headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
            "HTTP-Referer": "https://github.com/your-repo/promo-description-processor",
            "X-Title": "Promo Description Processor"
        }

    def load_config(self, config_file: str = None):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∏–∑ .env —Ñ–∞–π–ª–∞"""
        if config_file and Path(config_file).exists():
            load_dotenv(config_file)
        else:
            for env_file in [".env", "config.env", "settings.env"]:
                if Path(env_file).exists():
                    load_dotenv(env_file)
                    break

        self.api_key = os.getenv("OPENROUTER_API_KEY")
        self.model = os.getenv("DEFAULT_MODEL", "anthropic/claude-3.5-sonnet")
        self.temperature = float(os.getenv("DEFAULT_TEMPERATURE", "0.7")) # –ß—É—Ç—å –≤—ã—à–µ –¥–ª—è –∫—Ä–µ–∞—Ç–∏–≤–∞
        self.max_tokens = int(os.getenv("DEFAULT_MAX_TOKENS", "3000"))
        self.budget_model = os.getenv("BUDGET_MODEL", "meta-llama/llama-3.1-8b-instruct")
        self.quality_model = os.getenv("QUALITY_MODEL", "openai/gpt-4o")
        self.max_context_chars = int(os.getenv("PROMO_MAX_CONTEXT_CHARS", "15000"))

    def find_text_files(self, pipeline_dir: Path, prefix: Optional[str]) -> List[Path]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ .txt —Ñ–∞–π–ª–æ–≤ –∏–∑ –∫–∞—Ç–∞–ª–æ–≥–∞ –ø–∞–π–ø–ª–∞–π–Ω–∞ —Å —É—á–µ—Ç–æ–º –ø—Ä–µ—Ñ–∏–∫—Å–∞."""
        if not pipeline_dir.exists() or not pipeline_dir.is_dir():
            raise FileNotFoundError(f"–ö–∞—Ç–∞–ª–æ–≥ –ø–∞–π–ø–ª–∞–π–Ω–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω: {pipeline_dir}")

        txt_files = [p for p in sorted(pipeline_dir.glob("*.txt"))]
        if prefix:
            def _matches_prefix(path: Path) -> bool:
                stem = path.stem
                if "_" not in stem:
                    return False
                last_token = stem.split("_")[-1]
                return last_token == prefix

            txt_files = [p for p in txt_files if _matches_prefix(p)]
        return txt_files

    def build_context(self, files: List[Path]) -> str:
        """–°–æ–±–∏—Ä–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Ñ–∞–π–ª–æ–≤"""
        parts: List[str] = []
        total = 0
        for fp in files:
            try:
                text = fp.read_text(encoding="utf-8", errors="ignore")
            except Exception:
                continue
            header = f"\n===== –§–ê–ô–õ: {fp.name} =====\n"
            chunk = header + text.strip() + "\n"
            if total + len(chunk) > self.max_context_chars:
                remaining = max(self.max_context_chars - total, 0)
                if remaining > 0:
                    parts.append(chunk[:remaining])
                    total += remaining
                break
            parts.append(chunk)
            total += len(chunk)
        return "".join(parts).strip()

    def create_prompt(self, context: str, title: Optional[str], audience: str, tone: str, platform: str, lang: str) -> str:
        """–°–æ–∑–¥–∞–µ—Ç –ø—Ä–æ–º–ø—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã"""
        title_line = f"–ù–∞–∑–≤–∞–Ω–∏–µ/—Ç–µ–º–∞: {title}" if title else "–ù–∞–∑–≤–∞–Ω–∏–µ/—Ç–µ–º–∞: (–æ–ø—Ä–µ–¥–µ–ª–∏ –ø–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É)"

        # === –õ–û–ì–ò–ö–ê –î–õ–Ø PIKABU ===
        if platform.lower() == "pikabu":
            return f"""
–¢—ã ‚Äî –ø–æ–ø—É–ª—è—Ä–Ω—ã–π –∞–≤—Ç–æ—Ä –Ω–∞ Pikabu (–∏–ª–∏ Habr), –∫–æ—Ç–æ—Ä—ã–π –ø–∏—à–µ—Ç —É–≤–ª–µ–∫–∞—Ç–µ–ª—å–Ω—ã–µ –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã–µ —Å—Ç–∞—Ç—å–∏ –∏ –∏—Å—Ç–æ—Ä–∏–∏ –æ —Ä–µ—à–µ–Ω–∏–∏ –∑–∞–¥–∞—á.
–¢–≤–æ—è –∑–∞–¥–∞—á–∞: –ù–∞–ø–∏—Å–∞—Ç—å –ø–æ—Å—Ç-–ª–æ–Ω–≥—Ä–∏–¥ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –º–∞—Ç–µ—Ä–∏–∞–ª–∞.

–ü–ê–†–ê–ú–ï–¢–†–´:
- –Ø–∑—ã–∫: {lang}
- –ü–ª–∞—Ç—Ñ–æ—Ä–º–∞: –ü–∏–∫–∞–±—É (Pikabu)
- –ê—É–¥–∏—Ç–æ—Ä–∏—è: {audience} (–ª—é–¥–∏, –ª—é–±—è—â–∏–µ –Ω–∞—É—á–ø–æ–ø, IT, –º–∞—Ç–µ–º–∞—Ç–∏–∫—É, —Å—Ç—É–¥–µ–Ω—Ç—ã, –≥–∏–∫–∏)
- –¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å: {tone} (–∏—Å–ø–æ–ª—å–∑—É–π —é–º–æ—Ä, –∏—Ä–æ–Ω–∏—é, –∂–∏–≤–æ–π —è–∑—ã–∫, –∏–∑–±–µ–≥–∞–π –∫–∞–Ω—Ü–µ–ª—è—Ä–∏–∑–º–æ–≤).

–°–¢–†–£–ö–¢–£–†–ê –ü–û–°–¢–ê:
1. **–ó–∞–≥–æ–ª–æ–≤–æ–∫**: –ö–ª–∏–∫–±–µ–π—Ç–Ω—ã–π, –Ω–æ —á–µ—Å—Ç–Ω—ã–π. –°–º–µ—à–Ω–æ–π –∏–ª–∏ –∏–Ω—Ç—Ä–∏–≥—É—é—â–∏–π.
2. **–í–≤–µ–¥–µ–Ω–∏–µ (–õ–∏–¥)**: –û–ø–∏—à–∏ "–±–æ–ª—å" –∏–ª–∏ –ø—Ä–æ–±–ª–µ–º—É. –ö–∞–∫ –∞–≤—Ç–æ—Ä —Å—Ç–æ–ª–∫–Ω—É–ª—Å—è —Å —ç—Ç–æ–π –∑–∞–¥–∞—á–µ–π? –ü–æ—á–µ–º—É —ç—Ç–æ —Å–ª–æ–∂–Ω–æ/–∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ? –ò—Å–ø–æ–ª—å–∑—É–π "–Ø-–ø–æ–≤–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ".
3. **–û—Å–Ω–æ–≤–Ω–∞—è —á–∞—Å—Ç—å**:
   - –ö—Ä–∞—Ç–∫–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ —Å—É—Ç–∏ –∑–∞–¥–∞—á–∏ (–±–µ–∑ –ø–µ—Ä–µ–≥—Ä—É–∑–∞ —Ñ–æ—Ä–º—É–ª–∞–º–∏, "–Ω–∞ –ø–∞–ª—å—Ü–∞—Ö").
   - –ö–∞–∫ –º—ã —ç—Ç–æ –≤–∏–∑—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞–ª–∏ (—É–ø–æ–º—è–Ω–∏, —á—Ç–æ —ç—Ç–æ —Å–¥–µ–ª–∞–Ω–æ —Å –ø–æ–º–æ—â—å—é Manim/Python, –µ—Å–ª–∏ –µ—Å—Ç—å –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ).
   - –ò–Ω—Ç–µ—Ä–µ—Å–Ω—ã–µ –º–æ–º–µ–Ω—Ç—ã —Ä–µ—à–µ–Ω–∏—è, "–ø–æ–¥–≤–æ–¥–Ω—ã–µ –∫–∞–º–Ω–∏".
4. **–ó–∞–∫–ª—é—á–µ–Ω–∏–µ**: –ß–µ–º—É –º—ã –Ω–∞—É—á–∏–ª–∏—Å—å? –ò—Ä–æ–Ω–∏—á–Ω—ã–π –≤—ã–≤–æ–¥.
5. **–ü—Ä–∏–∑—ã–≤**: –ù–µ–Ω–∞–≤—è–∑—á–∏–≤–æ –ø—Ä–µ–¥–ª–æ–∂–∏ –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å –ø–æ–ª–Ω–æ–µ –≤–∏–¥–µ–æ (–æ—Å—Ç–∞–≤—å –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä [–°–°–´–õ–ö–ê –ù–ê –í–ò–î–ï–û]).

–§–û–†–ú–ê–¢–ò–†–û–í–ê–ù–ò–ï:
- –ò—Å–ø–æ–ª—å–∑—É–π Markdown (–∂–∏—Ä–Ω—ã–π —à—Ä–∏—Ñ—Ç, —Ü–∏—Ç–∞—Ç—ã).
- –†–∞–∑–±–∏–≤–∞–π —Ç–µ–∫—Å—Ç –Ω–∞ –∫–æ—Ä–æ—Ç–∫–∏–µ –∞–±–∑–∞—Ü—ã.
- –î–æ–±–∞–≤—å –º–µ—Å—Ç–∞ –¥–ª—è –∫–∞—Ä—Ç–∏–Ω–æ–∫ (–Ω–∞–ø—Ä–∏–º–µ—Ä: [–ö–ê–†–¢–ò–ù–ö–ê: –≥—Ä–∞—Ñ–∏–∫ —Ñ—É–Ω–∫—Ü–∏–∏]).

{title_line}

–ö–û–ù–¢–ï–ö–°–¢ (–ú–∞—Ç–µ—Ä–∏–∞–ª—ã —É—Ä–æ–∫–∞/–≤–∏–¥–µ–æ):
{context}

–¢–ï–ö–°–¢ –°–¢–ê–¢–¨–ò:
""".strip()

        # === –°–¢–ê–ù–î–ê–†–¢–ù–ê–Ø –õ–û–ì–ò–ö–ê (YouTube/Rutube) ===
        return f"""
–¢—ã ‚Äî –æ–ø—ã—Ç–Ω—ã–π –º–∞—Ä–∫–µ—Ç–æ–ª–æ–≥ –∏ —Ä–µ–¥–∞–∫—Ç–æ—Ä –≤–∏–¥–µ–æ–æ–ø–∏—Å–∞–Ω–∏–π. –ù–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ —Å–æ–∑–¥–∞–π —Å–∏–ª—å–Ω–æ–µ, —Ü–µ–ø–ª—è—é—â–µ–µ –ø—Ä–æ–º–æ-–æ–ø–∏—Å–∞–Ω–∏–µ –¥–ª—è –≤–∏–¥–µ–æ.

–¢–†–ï–ë–û–í–ê–ù–ò–Ø:
- –Ø–∑—ã–∫: {lang}
- –ü–ª–∞—Ç—Ñ–æ—Ä–º–∞: {platform} (—É—á–∏—Ç—ã–≤–∞–π –ª—É—á—à–∏–µ –ø—Ä–∞–∫—Ç–∏–∫–∏ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è)
- –ê—É–¥–∏—Ç–æ—Ä–∏—è: {audience}
- –¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å: {tone}
- –î–ª–∏–Ω–∞: –æ–∫–æ–ª–æ 3000-5000 —Å–∏–º–≤–æ–ª–æ–≤
- –°—Ç—Ä—É–∫—Ç—É—Ä–∞:
  1) –ö–æ—Ä–æ—Ç–∫–∏–π hook (1‚Äì2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è) ‚Äî —Ä–∞—Å–∫—Ä—ã–≤–∞–µ—Ç –∏–Ω—Ç—Ä–∏–≥—É/—Ü–µ–Ω–Ω–æ—Å—Ç—å
  2) –û—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞/—Ç–µ–º—ã –≤—ã–ø—É—Å–∫–∞ ‚Äî 3‚Äì6 —Å—Ç—Ä–æ–∫ –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É
  3) –ü—Ä–∏–∑—ã–≤ –∫ –¥–µ–π—Å—Ç–≤–∏—é: –ø–æ–¥–ø–∏—Å–∫–∞/–ª–∞–π–∫/–∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π
  4) –•—ç—à—Ç–µ–≥–∏ –≤ —Å—Ç—Ä–æ–∫—É, —Ä–∞–∑–¥–µ–ª–µ–Ω–Ω—ã–µ —á–µ—Ä–µ–∑ –ø—Ä–æ–±–µ–ª –∏ –Ω–∞—á–∏–Ω–∞—é—â–∏–µ—Å—è —Å # (5‚Äì10, —É–º–µ—Å—Ç–Ω—ã–µ –∏ –Ω–µ—Å–ª–æ–∂–Ω—ã–µ)
- –ù–µ –∏—Å–ø–æ–ª—å–∑—É–π —Å–ª–æ–∂–Ω—ã–π –º–∞—Ä–∫–¥–∞—É–Ω (—Ç–æ–ª—å–∫–æ –±–∞–∑–æ–≤—ã–π). –ü–∏—à–∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ.
- –ò–∑–±–µ–≥–∞–π –∫–ª–∏—à–µ –∏ –≤–æ–¥—ã. –ú–∞–∫—Å–∏–º—É–º –∫–æ–Ω–∫—Ä–µ—Ç–∏–∫–∏.

{title_line}

–ö–û–ù–¢–ï–ö–°–¢:
{context}

–û–ü–ò–°–ê–ù–ò–ï:
""".strip()

    def generate_description(self, context: str, model_choice: str = "default") -> Optional[str]:
        """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∑–∞–ø—Ä–æ—Å –∫ LLM –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ"""
        model = self.model
        if model_choice == "budget":
            model = self.budget_model
        elif model_choice == "quality":
            model = self.quality_model

        print(f"üîç –ò—Å–ø–æ–ª—å–∑—É–µ–º–∞—è –º–æ–¥–µ–ª—å: {model}")
        
        payload = {
            "model": model,
            "messages": [
                {"role": "user", "content": context}
            ],
            "temperature": self.temperature,
            "max_tokens": self.max_tokens
        }

        for attempt in range(3):
            try:
                resp = requests.post(
                    f"{self.base_url}/chat/completions",
                    headers=self.headers,
                    json=payload,
                    timeout=120
                )
                if resp.status_code == 200:
                    data = resp.json()
                    return data["choices"][0]["message"]["content"].strip()
                else:
                    if resp.status_code == 429:
                        time.sleep(2 ** (attempt + 1))
                    elif attempt < 2:
                        time.sleep(2 ** attempt)
            except Exception:
                if attempt < 2:
                    time.sleep(2 ** attempt)
        return None

    def process_pipeline(self, pipeline_dir: str, output_file: Optional[str], prefix: Optional[str],
                          audience: str, tone: str, platform: str, lang: str,
                          model_choice: str = "default", title: Optional[str] = None,
                          source_file: Optional[str] = None) -> Tuple[bool, Optional[Path]]:
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥: —Å–æ–±–∏—Ä–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ–ø–∏—Å–∞–Ω–∏–µ"""
        pdir = Path(pipeline_dir)
        if source_file:
            sf = Path(source_file)
            if not sf.exists() or not sf.is_file():
                print(f"‚ùå –£–∫–∞–∑–∞–Ω–Ω—ã–π –∏—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {sf}")
                return False, None
            txt_files = [sf]
        else:
            txt_files = self.find_text_files(pdir, prefix)

        if not txt_files:
            print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω—ã .txt —Ñ–∞–π–ª—ã –≤ –∫–∞—Ç–∞–ª–æ–≥–µ –ø–∞–π–ø–ª–∞–π–Ω–∞ (—Å —É—á–µ—Ç–æ–º —Ñ–∏–ª—å—Ç—Ä–∞)")
            return False, None

        print(f"üóÇ –ù–∞–π–¥–µ–Ω–æ txt —Ñ–∞–π–ª–æ–≤: {len(txt_files)}")
        if prefix:
            print(f"üîé –ü—Ä–µ—Ñ–∏–∫—Å-—Ñ–∏–ª—å—Ç—Ä: {prefix}")

        context = self.build_context(txt_files)
        print(f"üìä –†–∞–∑–º–µ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞: {len(context)} —Å–∏–º–≤–æ–ª–æ–≤")

        prompt = self.create_prompt(context, title, audience, tone, platform, lang)
        description = self.generate_description(prompt, model_choice)
        if not description:
            print("‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞")
            return False, None

        if not output_file:
            output_path = pdir / "promo_description.txt"
        else:
            output_path = Path(output_file)

        output_path.write_text(description, encoding="utf-8")
        print(f"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_path}")
        return True, output_path


def main():
    parser = argparse.ArgumentParser(
        description="–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–º–æ –∏ —Å—Ç–∞—Ç–µ–π –¥–ª—è –≤–∏–¥–µ–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—Å—Ç–æ–≤ –ø–∞–π–ø–ª–∞–π–Ω–∞",
        formatter_class=argparse.RawDescriptionHelpFormatter
    )

    parser.add_argument("pipeline_dir", help="–ö–∞—Ç–∞–ª–æ–≥ –ø–∞–π–ø–ª–∞–π–Ω–∞ —Å .txt —Ñ–∞–π–ª–∞–º–∏")
    parser.add_argument("-o", "--output", help="–ü—É—Ç—å –∫ –≤—ã—Ö–æ–¥–Ω–æ–º—É —Ñ–∞–π–ª—É")
    parser.add_argument("--config", help="–ü—É—Ç—å –∫ .env —Ñ–∞–π–ª—É —Å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π")
    parser.add_argument("--prefix", help="–§–∏–ª—å—Ç—Ä –ø—Ä–µ—Ñ–∏–∫—Å–∞ –¥–ª—è –≤—ã–±–æ—Ä–∞ .txt —Ñ–∞–π–ª–æ–≤")
    parser.add_argument("--model", choices=["default", "budget", "quality"], default="default", help="–í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏")
    parser.add_argument("--audience", default="—à–∏—Ä–æ–∫–∞—è –∞—É–¥–∏—Ç–æ—Ä–∏—è", help="–û–ø–∏—Å–∞–Ω–∏–µ –∞—É–¥–∏—Ç–æ—Ä–∏–∏")
    parser.add_argument("--tone", default="–¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π –∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–π", help="–¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å —Ç–µ–∫—Å—Ç–∞")
    parser.add_argument("--platform", default="YouTube", help="–ü–ª–∞—Ç—Ñ–æ—Ä–º–∞ (YouTube, Pikabu, VK...)")
    parser.add_argument("--lang", default="—Ä—É—Å—Å–∫–∏–π", help="–Ø–∑—ã–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞")
    parser.add_argument("--title", help="–ù–∞–∑–≤–∞–Ω–∏–µ/—Ç–µ–º–∞ –≤–∏–¥–µ–æ")
    parser.add_argument("--source-file", help="–ü—É—Ç—å –∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º—É –∏—Å—Ö–æ–¥–Ω–æ–º—É —Ñ–∞–π–ª—É (–Ω–∞–ø—Ä–∏–º–µ—Ä, script.txt)")

    args = parser.parse_args()

    try:
        processor = PromoDescriptionProcessor(args.config)
        ok, out = processor.process_pipeline(
            pipeline_dir=args.pipeline_dir,
            output_file=args.output,
            prefix=args.prefix,
            audience=args.audience,
            tone=args.tone,
            platform=args.platform,
            lang=args.lang,
            model_choice=args.model,
            title=args.title,
            source_file=args.source_file
        )
        return 0 if ok else 1
    except ValueError as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {e}")
        return 1
    except Exception as e:
        print(f"‚ùå –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")
        return 1


if __name__ == "__main__": {
    sys.exit(main())
}