#!/usr/bin/env python3
"""
Video discussion processor for creating summaries or discussions from segmented text.
Supports two modes: summary and discussion analysis.
"""

import os
import json
import time
import argparse
import requests
from pathlib import Path
from typing import List, Dict, Optional, Any
from dotenv import load_dotenv


class VideoDiscussionProcessor:
    def __init__(self, config_file: Optional[str] = None):
        """
        Initialize video discussion processor
        
        Args:
            config_file: Path to configuration file
        """
        self.config_file = config_file
        self.load_config()
        
        # Statistics
        self.stats = {
            'api_calls': 0,
            'total_tokens_used': 0,
            'segments_processed': 0
        }
    
    def load_config(self):
        """Load configuration from environment or config file"""
        try:
            if self.config_file:
                load_dotenv(self.config_file)
            else:
                load_dotenv()
        except ImportError:
            pass
        
        # API configuration
        self.api_key = os.getenv('OPENROUTER_API_KEY')
        self.base_url = os.getenv('OPENROUTER_BASE_URL', 'https://openrouter.ai/api/v1')
        
        # Model configuration
        self.model = os.getenv('DEFAULT_MODEL', 'anthropic/claude-3.5-sonnet')
        self.budget_model = os.getenv('BUDGET_MODEL', 'meta-llama/llama-3.1-8b-instruct')
        self.quality_model = os.getenv('QUALITY_MODEL', 'openai/gpt-4o')
        
        # Processing parameters
        self.temperature = float(os.getenv('DEFAULT_TEMPERATURE', '0.3'))
        self.max_tokens = int(os.getenv('DEFAULT_MAX_TOKENS', '4000'))
        
        # Headers for API requests
        self.headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
            "HTTP-Referer": "https://github.com/your-repo/bookreader",
            "X-Title": "Video Discussion Processor"
        }
    
    def _call_llm(self, prompt: str, system: Optional[str] = None, 
                  model: Optional[str] = None, retry_count: int = 3) -> Optional[str]:
        """
        Call LLM API with retry logic
        
        Args:
            prompt: User prompt
            system: System prompt (optional)
            model: Model to use (optional)
            retry_count: Number of retry attempts
            
        Returns:
            LLM response or None
        """
        payload = {
            "model": model or self.model,
            "messages": [],
            "temperature": self.temperature,
            "max_tokens": self.max_tokens
        }
        
        if system:
            payload["messages"].append({"role": "system", "content": system})
        payload["messages"].append({"role": "user", "content": prompt})
        
        for attempt in range(retry_count):
            try:
                self.stats["api_calls"] += 1
                response = requests.post(
                    f"{self.base_url}/chat/completions",
                    headers=self.headers,
                    json=payload,
                    timeout=120
                )
                
                if response.status_code == 200:
                    data = response.json()
                    content = data["choices"][0]["message"]["content"].strip()
                    
                    # Update token usage statistics
                    if "usage" in data:
                        self.stats["total_tokens_used"] += data["usage"].get("total_tokens", 0)
                    
                    return content
                elif response.status_code == 429:
                    wait_time = 2 ** (attempt + 1)
                    print(f"‚è≥ Rate limit, –æ–∂–∏–¥–∞–Ω–∏–µ {wait_time} —Å–µ–∫—É–Ω–¥...")
                    time.sleep(wait_time)
                else:
                    print(f"‚ùå –û—à–∏–±–∫–∞ API (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}): {response.status_code}")
                    if attempt < retry_count - 1:
                        time.sleep(2 ** attempt)
                        
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}): {e}")
                if attempt < retry_count - 1:
                    time.sleep(2 ** attempt)
        
        return None
    
    def create_summary_prompt(self, segment: Dict[str, Any], segment_index: int, 
                            total_segments: int, title: str = "", author: str = "") -> str:
        """
        Create prompt for summary mode
        
        Args:
            segment: Segment data
            segment_index: Current segment index
            total_segments: Total number of segments
            title: Video title
            author: Video author
            
        Returns:
            Formatted prompt
        """
        context_info = ""
        if title:
            context_info += f"–ù–∞–∑–≤–∞–Ω–∏–µ –≤–∏–¥–µ–æ: {title}\n"
        if author:
            context_info += f"–ê–≤—Ç–æ—Ä: {author}\n"
        
        return f"""–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Å–æ–∑–¥–∞–Ω–∏—é –∫—Ä–∞—Ç–∫–∏—Ö –∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã—Ö –ø–µ—Ä–µ—Å–∫–∞–∑–æ–≤.

–ó–ê–î–ê–ß–ê: –°–æ–∑–¥–∞–π –∫—Ä–∞—Ç–∫–∏–π –ø–µ—Ä–µ—Å–∫–∞–∑ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞ —Ç–µ–∫—Å—Ç–∞.

–ö–û–ù–¢–ï–ö–°–¢:
{context_info}–§—Ä–∞–≥–º–µ–Ω—Ç {segment_index} –∏–∑ {total_segments}

–¢–†–ï–ë–û–í–ê–ù–ò–Ø –ö –ü–ï–†–ï–°–ö–ê–ó–£:
- –°–æ—Ö—Ä–∞–Ω–∏ –≤—Å–µ –∫–ª—é—á–µ–≤—ã–µ –∏–¥–µ–∏ –∏ —Ñ–∞–∫—Ç—ã
- –ò—Å–ø–æ–ª—å–∑—É–π –ø—Ä–æ—Å—Ç–æ–π –∏ –ø–æ–Ω—è—Ç–Ω—ã–π —è–∑—ã–∫
- –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ª–æ–≥–∏—á–Ω–æ
- –í—ã–¥–µ–ª–∏ –≥–ª–∞–≤–Ω—ã–µ –º–æ–º–µ–Ω—Ç—ã
- –î–ª–∏–Ω–∞: 2-4 –∞–±–∑–∞—Ü–∞
- –°–æ—Ö—Ä–∞–Ω–∏ —Ö—Ä–æ–Ω–æ–ª–æ–≥–∏—é —Å–æ–±—ã—Ç–∏–π, –µ—Å–ª–∏ –æ–Ω–∞ –≤–∞–∂–Ω–∞

–§–†–ê–ì–ú–ï–ù–¢ –î–õ–Ø –ü–ï–†–ï–°–ö–ê–ó–ê:
**{segment.get('title', f'–§—Ä–∞–≥–º–µ–Ω—Ç {segment_index}')}**

{segment.get('content', '')}

–ü–ï–†–ï–°–ö–ê–ó:"""
    
    def create_discussion_prompt(self, segment: Dict[str, Any], segment_index: int, 
                               total_segments: int, title: str = "", author: str = "") -> str:
        """
        Create prompt for discussion mode
        
        Args:
            segment: Segment data
            segment_index: Current segment index
            total_segments: Total number of segments
            title: Video title
            author: Video author
            
        Returns:
            Formatted prompt
        """
        context_info = ""
        if title:
            context_info += f"–ù–∞–∑–≤–∞–Ω–∏–µ –≤–∏–¥–µ–æ: {title}\n"
        if author:
            context_info += f"–ê–≤—Ç–æ—Ä: {author}\n"
        
        return f"""–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –∏ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–º—É –º—ã—à–ª–µ–Ω–∏—é.

–ó–ê–î–ê–ß–ê: –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç –∏ —Å–æ–∑–¥–∞–π –æ–±—Å—É–∂–¥–µ–Ω–∏–µ —Å —Ä–∞–∑–Ω—ã–º–∏ —Ç–æ—á–∫–∞–º–∏ –∑—Ä–µ–Ω–∏—è.

–ö–û–ù–¢–ï–ö–°–¢:
{context_info}–§—Ä–∞–≥–º–µ–Ω—Ç {segment_index} –∏–∑ {total_segments}

–¢–†–ï–ë–û–í–ê–ù–ò–Ø –ö –û–ë–°–£–ñ–î–ï–ù–ò–Æ:
- –í—ã–¥–µ–ª–∏ –æ—Å–Ω–æ–≤–Ω—ã–µ —Ç–µ–∑–∏—Å—ã –∏ –∞—Ä–≥—É–º–µ–Ω—Ç—ã
- –†–∞—Å—Å–º–æ—Ç—Ä–∏ —Ä–∞–∑–Ω—ã–µ —Ç–æ—á–∫–∏ –∑—Ä–µ–Ω–∏—è –Ω–∞ –ø—Ä–æ–±–ª–µ–º—É
- –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –ª–æ–≥–∏–∫—É –∏ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–Ω–æ—Å—Ç—å —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–π
- –í—ã—Å–∫–∞–∂–∏ —Å–≤–æ–µ –º–Ω–µ–Ω–∏–µ –∫–∞–∫ —ç–∫—Å–ø–µ—Ä—Ç–∞
- –£–∫–∞–∂–∏ –Ω–∞ —Å–∏–ª—å–Ω—ã–µ –∏ —Å–ª–∞–±—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã –∞—Ä–≥—É–º–µ–Ω—Ç–∞—Ü–∏–∏
- –ü—Ä–µ–¥–ª–æ–∂–∏ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –≤–∑–≥–ª—è–¥—ã, –µ—Å–ª–∏ –ø—Ä–∏–º–µ–Ω–∏–º–æ
- –î–ª–∏–Ω–∞: 3-5 –∞–±–∑–∞—Ü–µ–≤

–§–†–ê–ì–ú–ï–ù–¢ –î–õ–Ø –ê–ù–ê–õ–ò–ó–ê:
**{segment.get('title', f'–§—Ä–∞–≥–º–µ–Ω—Ç {segment_index}')}**

{segment.get('content', '')}

–ê–ù–ê–õ–ò–ó –ò –û–ë–°–£–ñ–î–ï–ù–ò–ï:"""
    
    def process_segment(self, segment: Dict[str, Any], mode: str, segment_index: int, 
                       total_segments: int, title: str = "", author: str = "", 
                       model_choice: str = "default") -> Optional[str]:
        """
        Process a single segment
        
        Args:
            segment: Segment data
            mode: Processing mode (summary/discussion)
            segment_index: Current segment index
            total_segments: Total number of segments
            title: Video title
            author: Video author
            model_choice: Model choice
            
        Returns:
            Processed text or None
        """
        # Select model
        model = self.model
        if model_choice == "budget":
            model = self.budget_model
        elif model_choice == "quality":
            model = self.quality_model
        
        # Create appropriate prompt
        if mode == "summary":
            prompt = self.create_summary_prompt(segment, segment_index, total_segments, title, author)
        elif mode == "discussion":
            prompt = self.create_discussion_prompt(segment, segment_index, total_segments, title, author)
        else:
            print(f"‚ùå –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ä–µ–∂–∏–º: {mode}")
            return None
        
        # Call LLM
        response = self._call_llm(prompt, model=model)
        if response:
            self.stats["segments_processed"] += 1
        
        return response
    
    def process_segments(self, segments_file: str, mode: str, title: str = "", 
                       author: str = "", model_choice: str = "default") -> Optional[str]:
        """
        Process all segments and create final text
        
        Args:
            segments_file: Path to segments JSON file
            mode: Processing mode (summary/discussion)
            title: Video title
            author: Video author
            model_choice: Model choice
            
        Returns:
            Final processed text or None
        """
        try:
            # Load segments
            segments_path = Path(segments_file)
            if not segments_path.exists():
                print(f"‚ùå –§–∞–π–ª —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω: {segments_path}")
                return None
            
            with open(segments_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            segments = data.get("segments", [])
            if not segments:
                print("‚ùå –°–µ–≥–º–µ–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ —Ñ–∞–π–ª–µ")
                return None
            
            print(f"üìÑ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º {len(segments)} —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –≤ —Ä–µ–∂–∏–º–µ '{mode}'...")
            
            # Process each segment
            processed_parts = []
            for i, segment in enumerate(segments, 1):
                print(f"üîÑ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–µ–≥–º–µ–Ω—Ç {i}/{len(segments)}: {segment.get('title', f'–§—Ä–∞–≥–º–µ–Ω—Ç {i}')}")
                
                processed_text = self.process_segment(
                    segment, mode, i, len(segments), title, author, model_choice
                )
                
                if processed_text:
                    # Add segment header
                    segment_title = segment.get('title', f'–§—Ä–∞–≥–º–µ–Ω—Ç {i}')
                    processed_parts.append(f"## {segment_title}\n\n{processed_text}\n")
                else:
                    print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —Å–µ–≥–º–µ–Ω—Ç {i}")
                    processed_parts.append(f"## {segment.get('title', f'–§—Ä–∞–≥–º–µ–Ω—Ç {i}')}\n\n*[–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏]*\n")
                
                # Small delay between requests
                if i < len(segments):
                    time.sleep(1)
            
            # Combine all parts
            final_text = self._create_final_text(processed_parts, mode, title, author)
            return final_text
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–µ–≥–º–µ–Ω—Ç–æ–≤: {e}")
            return None
    
    def _create_final_text(self, processed_parts: List[str], mode: str, 
                          title: str = "", author: str = "") -> str:
        """
        Create final text with header and footer
        
        Args:
            processed_parts: List of processed segment texts
            mode: Processing mode
            title: Video title
            author: Video author
            
        Returns:
            Final formatted text
        """
        # Create header
        header_parts = []
        if title:
            header_parts.append(f"# {title}")
        if author:
            header_parts.append(f"**–ê–≤—Ç–æ—Ä:** {author}")
        
        mode_title = "–ü–µ—Ä–µ—Å–∫–∞–∑" if mode == "summary" else "–û–±—Å—É–∂–¥–µ–Ω–∏–µ"
        header_parts.append(f"**–†–µ–∂–∏–º:** {mode_title}")
        header_parts.append(f"**–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è:** {time.strftime('%Y-%m-%d %H:%M:%S')}")
        
        header = "\n".join(header_parts) + "\n\n---\n\n"
        
        # Add placeholder for timestamps
        timestamps_placeholder = "[content]\n\n"
        
        # Create footer
        footer = f"\n\n---\n\n*{mode_title} —Å–æ–∑–¥–∞–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å –ø–æ–º–æ—â—å—é Video Discussion Processor*"
        
        # Combine everything
        return header + timestamps_placeholder + "\n".join(processed_parts) + footer
    
    def save_discussion(self, text: str, output_file: str) -> bool:
        """
        Save discussion text to file
        
        Args:
            text: Discussion text
            output_file: Output file path
            
        Returns:
            True if successful
        """
        try:
            output_path = Path(output_file)
            output_path.parent.mkdir(parents=True, exist_ok=True)
            
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(text)
            
            print(f"‚úÖ –û–±—Å—É–∂–¥–µ–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {output_path}")
            return True
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –æ–±—Å—É–∂–¥–µ–Ω–∏—è: {e}")
            return False
    
    def process_pipeline(self, segments_file: str, output_file: str, mode: str,
                        title: str = "", author: str = "", model_choice: str = "default") -> bool:
        """
        Complete processing pipeline
        
        Args:
            segments_file: Path to segments JSON file
            output_file: Output text file
            mode: Processing mode (summary/discussion)
            title: Video title
            author: Video author
            model_choice: Model choice
            
        Returns:
            True if successful
        """
        # Process segments
        final_text = self.process_segments(segments_file, mode, title, author, model_choice)
        if not final_text:
            return False
        
        # Save result
        success = self.save_discussion(final_text, output_file)
        if success:
            print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
            print(f"   - –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å–µ–≥–º–µ–Ω—Ç–æ–≤: {self.stats['segments_processed']}")
            print(f"   - API –≤—ã–∑–æ–≤–æ–≤: {self.stats['api_calls']}")
            print(f"   - –¢–æ–∫–µ–Ω–æ–≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ: {self.stats['total_tokens_used']}")
        
        return success


def main():
    parser = argparse.ArgumentParser(description="–°–æ–∑–¥–∞–Ω–∏–µ –ø–µ—Ä–µ—Å–∫–∞–∑–∞ –∏–ª–∏ –æ–±—Å—É–∂–¥–µ–Ω–∏—è –∏–∑ —Å–µ–≥–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞")
    parser.add_argument('segments_file', help='JSON —Ñ–∞–π–ª —Å —Å–µ–≥–º–µ–Ω—Ç–∞–º–∏')
    parser.add_argument('--output', '-o', required=True, help='–í—ã—Ö–æ–¥–Ω–æ–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª')
    parser.add_argument('--mode', choices=['summary', 'discussion'], required=True, 
                       help='–†–µ–∂–∏–º –æ–±—Ä–∞–±–æ—Ç–∫–∏')
    parser.add_argument('--title', help='–ù–∞–∑–≤–∞–Ω–∏–µ –≤–∏–¥–µ–æ')
    parser.add_argument('--author', help='–ê–≤—Ç–æ—Ä –≤–∏–¥–µ–æ')
    parser.add_argument('--config', help='–§–∞–π–ª –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏')
    parser.add_argument('--model', choices=['default', 'budget', 'quality'], 
                       default='default', help='–í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏')
    
    args = parser.parse_args()
    
    processor = VideoDiscussionProcessor(args.config)
    
    success = processor.process_pipeline(
        args.segments_file,
        args.output,
        args.mode,
        args.title or "",
        args.author or "",
        args.model
    )
    
    if success:
        print("‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
        return 0
    else:
        print("‚ùå –û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ —É–¥–∞–ª–∞—Å—å")
        return 1


if __name__ == "__main__":
    exit(main())
