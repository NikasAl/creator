#!/usr/bin/env python3
"""
–°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –¥–ª—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ —Ç–µ–∫—Å—Ç–∞ –∫ —Å–æ–∑–¥–∞–Ω–∏—é –∞—É–¥–∏–æ–∫–Ω–∏–≥–∏
–í–∫–ª—é—á–∞–µ—Ç:
- –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
- –ö–æ—Ä—Ä–µ–∫—Ü–∏—é —Å–∏–Ω—Ç–∞–∫—Å–∏—Å–∞
- –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∞—É–¥–∏–æ-—Ç–µ–≥–æ–≤
- –†–∞–∑–±–∏–≤–∫—É –Ω–∞ –≥–ª–∞–≤—ã
- –ü–æ–¥–≥–æ—Ç–æ–≤–∫—É –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
"""

import os
import json
import time
import argparse
import requests
from pathlib import Path
from typing import List, Dict, Optional, Tuple
import re
from datetime import datetime


class AudioBookProcessor:
    def __init__(self, api_key: str, model: str = "anthropic/claude-3.5-sonnet"):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞ –∞—É–¥–∏–æ–∫–Ω–∏–≥–∏
        
        Args:
            api_key: API –∫–ª—é—á –¥–ª—è OpenRouter
            model: –ú–æ–¥–µ–ª—å –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
        """
        self.api_key = api_key
        self.model = model
        self.base_url = "https://openrouter.ai/api/v1"
        self.headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json",
            "HTTP-Referer": "https://github.com/your-repo/audiobook-processor",
            "X-Title": "AudioBook Text Processor"
        }
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        self.stats = {
            'total_chunks': 0,
            'processed_chunks': 0,
            'failed_chunks': 0,
            'total_characters': 0,
            'processing_time': 0
        }
    
    def detect_chapters(self, text: str) -> List[Tuple[str, int, int]]:
        """
        –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –≥–ª–∞–≤—ã –≤ —Ç–µ–∫—Å—Ç–µ
        
        Args:
            text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
            
        Returns:
            –°–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π (–Ω–∞–∑–≤–∞–Ω–∏–µ_–≥–ª–∞–≤—ã, –Ω–∞—á–∞–ª–æ, –∫–æ–Ω–µ—Ü)
        """
        chapters = []
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ –≥–ª–∞–≤
        patterns = [
            r'^–ì–õ–ê–í–ê\s+\d+[.:]?\s*(.+?)$',
            r'^Chapter\s+\d+[.:]?\s*(.+?)$',
            r'^–ß–∞—Å—Ç—å\s+\d+[.:]?\s*(.+?)$',
            r'^Part\s+\d+[.:]?\s*(.+?)$',
            r'^\d+[.:]\s*(.+?)$',
            r'^[IVX]+[.:]\s*(.+?)$'
        ]
        
        lines = text.split('\n')
        
        for i, line in enumerate(lines):
            line = line.strip()
            for pattern in patterns:
                match = re.match(pattern, line, re.IGNORECASE)
                if match:
                    chapter_title = match.group(1).strip()
                    chapters.append((chapter_title, i, i))
                    break
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–Ω–µ—Ü –∫–∞–∂–¥–æ–π –≥–ª–∞–≤—ã
        for i in range(len(chapters)):
            if i < len(chapters) - 1:
                chapters[i] = (chapters[i][0], chapters[i][1], chapters[i+1][1])
            else:
                chapters[i] = (chapters[i][0], chapters[i][1], len(lines))
        
        return chapters
    
    def split_text_into_chunks(self, text: str, max_chunk_size: int = 2500) -> List[str]:
        """
        –†–∞–∑–±–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ —á–∞—Å—Ç–∏ —Å —É—á–µ—Ç–æ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
        
        Args:
            text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
            max_chunk_size: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —á–∞—Å—Ç–∏
            
        Returns:
            –°–ø–∏—Å–æ–∫ —á–∞—Å—Ç–µ–π —Ç–µ–∫—Å—Ç–∞
        """
        # –°–Ω–∞—á–∞–ª–∞ —Ä–∞–∑–±–∏–≤–∞–µ–º –ø–æ –∞–±–∑–∞—Ü–∞–º
        paragraphs = [p.strip() for p in text.split('\n\n') if p.strip()]
        chunks = []
        current_chunk = ""
        
        for paragraph in paragraphs:
            # –ï—Å–ª–∏ –ø–∞—Ä–∞–≥—Ä–∞—Ñ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π, —Ä–∞–∑–±–∏–≤–∞–µ–º –µ–≥–æ
            if len(paragraph) > max_chunk_size:
                if current_chunk:
                    chunks.append(current_chunk.strip())
                    current_chunk = ""
                
                # –†–∞–∑–±–∏–≤–∞–µ–º –±–æ–ª—å—à–æ–π –ø–∞—Ä–∞–≥—Ä–∞—Ñ –ø–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º
                sentences = re.split(r'(?<=[.!?])\s+', paragraph)
                temp_chunk = ""
                
                for sentence in sentences:
                    if len(temp_chunk) + len(sentence) > max_chunk_size and temp_chunk:
                        chunks.append(temp_chunk.strip())
                        temp_chunk = sentence
                    else:
                        if temp_chunk:
                            temp_chunk += " " + sentence
                        else:
                            temp_chunk = sentence
                
                if temp_chunk:
                    current_chunk = temp_chunk
            else:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –ø—Ä–µ–≤—ã—Å–∏—Ç –ª–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞ –ª–∏–º–∏—Ç
                if len(current_chunk) + len(paragraph) > max_chunk_size and current_chunk:
                    chunks.append(current_chunk.strip())
                    current_chunk = paragraph
                else:
                    if current_chunk:
                        current_chunk += "\n\n" + paragraph
                    else:
                        current_chunk = paragraph
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —á–∞–Ω–∫
        if current_chunk:
            chunks.append(current_chunk.strip())
        
        return chunks
    
    def create_audiobook_prompt(self, text_chunk: str, chunk_number: int, total_chunks: int) -> str:
        """
        –°–æ–∑–¥–∞–µ—Ç –ø—Ä–æ–º–ø—Ç –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞ –∞—É–¥–∏–æ–∫–Ω–∏–≥–∏
        
        Args:
            text_chunk: –ß–∞—Å—Ç—å —Ç–µ–∫—Å—Ç–∞
            chunk_number: –ù–æ–º–µ—Ä —á–∞—Å—Ç–∏
            total_chunks: –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–∞—Å—Ç–µ–π
            
        Returns:
            –ü—Ä–æ–º–ø—Ç –¥–ª—è –Ω–µ–π—Ä–æ—Å–µ—Ç–∏
        """
        return f"""–¢—ã - –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π —Ä–µ–¥–∞–∫—Ç–æ—Ä –∞—É–¥–∏–æ–∫–Ω–∏–≥. –û–±—Ä–∞–±–æ—Ç–∞–π —á–∞—Å—Ç—å {chunk_number} –∏–∑ {total_chunks} –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–π –∞—É–¥–∏–æ–∫–Ω–∏–≥–∏.

–ó–ê–î–ê–ß–ò:

1. –§–û–†–ú–ê–¢–ò–†–û–í–ê–ù–ò–ï:
   - –ò—Å–ø—Ä–∞–≤—å –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫ –≤ —Å–µ—Ä–µ–¥–∏–Ω–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
   - –û–±—ä–µ–¥–∏–Ω–∏ —Ä–∞–∑–æ—Ä–≤–∞–Ω–Ω—ã–µ —Å–ª–æ–≤–∞
   - –£–±–µ—Ä–∏ –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ –ø–µ—Ä–µ–Ω–æ—Å—ã
   - –°–æ—Ö—Ä–∞–Ω–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∞–±–∑–∞—Ü–µ–≤

2. –°–ò–ù–¢–ê–ö–°–ò–° –ò –ü–£–ù–ö–¢–£–ê–¶–ò–Ø:
   - –ò—Å–ø—Ä–∞–≤—å –≥—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏
   - –î–æ–±–∞–≤—å –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –∑–Ω–∞–∫–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è
   - –ò—Å–ø—Ä–∞–≤—å —Ä–µ–≥–∏—Å—Ç—Ä –±—É–∫–≤
   - –£–ª—É—á—à–∏ —á–∏—Ç–∞–µ–º–æ—Å—Ç—å

3. –ê–£–î–ò–û-–¢–ï–ì–ò (–¥–æ–±–∞–≤–ª—è–π —É–º–µ—Ä–µ–Ω–Ω–æ):
   - [PAUSE] - –ø–∞—É–∑–∞ –º–µ–∂–¥—É –∞–±–∑–∞—Ü–∞–º–∏
   - [EMPHASIS]–≤–∞–∂–Ω—ã–π —Ç–µ–∫—Å—Ç[/EMPHASIS] - –≤—ã–¥–µ–ª–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö –º–æ–º–µ–Ω—Ç–æ–≤
   - [SLOW]–º–µ–¥–ª–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç[/SLOW] - –∑–∞–º–µ–¥–ª–µ–Ω–∏–µ –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö –ø–æ–Ω—è—Ç–∏–π
   - [BACKGROUND_MUSIC] - –≥–¥–µ —É–º–µ—Å—Ç–Ω–∞ —Ñ–æ–Ω–æ–≤–∞—è –º—É–∑—ã–∫–∞
   - [SOUND_EFFECT]–æ–ø–∏—Å–∞–Ω–∏–µ[/SOUND_EFFECT] - –∑–≤—É–∫–æ–≤—ã–µ —ç—Ñ—Ñ–µ–∫—Ç—ã
   - [CHAPTER_START] - –Ω–∞—á–∞–ª–æ –Ω–æ–≤–æ–π –≥–ª–∞–≤—ã
   - [CHAPTER_END] - –∫–æ–Ω–µ—Ü –≥–ª–∞–≤—ã

4. –°–¢–ò–õ–¨:
   - –°–æ—Ö—Ä–∞–Ω–∏ –Ω–∞—É—á–Ω—ã–π/–∞–∫–∞–¥–µ–º–∏—á–µ—Å–∫–∏–π —Ç–æ–Ω
   - –ù–µ –º–µ–Ω—è–π —Å–º—ã—Å–ª –∏ —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—é
   - –°–¥–µ–ª–∞–π —Ç–µ–∫—Å—Ç –±–æ–ª–µ–µ –ø–ª–∞–≤–Ω—ã–º –¥–ª—è —á—Ç–µ–Ω–∏—è –≤—Å–ª—É—Ö

–ò–°–•–û–î–ù–´–ô –¢–ï–ö–°–¢:
{text_chunk}

–û–ë–†–ê–ë–û–¢–ê–ù–ù–´–ô –¢–ï–ö–°–¢:"""
    
    def process_chunk_with_ai(self, text_chunk: str, chunk_number: int, total_chunks: int, retry_count: int = 3) -> Optional[str]:
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —á–∞—Å—Ç—å —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–º–æ—â—å—é –Ω–µ–π—Ä–æ—Å–µ—Ç–∏
        
        Args:
            text_chunk: –ß–∞—Å—Ç—å —Ç–µ–∫—Å—Ç–∞
            chunk_number: –ù–æ–º–µ—Ä —á–∞—Å—Ç–∏
            total_chunks: –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–∞—Å—Ç–µ–π
            retry_count: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫
            
        Returns:
            –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –∏–ª–∏ None
        """
        prompt = self.create_audiobook_prompt(text_chunk, chunk_number, total_chunks)
        
        payload = {
            "model": self.model,
            "messages": [
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            "temperature": 0.2,  # –ù–∏–∑–∫–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏
            "max_tokens": 4000
        }
        
        for attempt in range(retry_count):
            try:
                response = requests.post(
                    f"{self.base_url}/chat/completions",
                    headers=self.headers,
                    json=payload,
                    timeout=90
                )
                
                if response.status_code == 200:
                    result = response.json()
                    return result['choices'][0]['message']['content'].strip()
                else:
                    print(f"‚ùå –û—à–∏–±–∫–∞ API (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}): {response.status_code}")
                    if attempt < retry_count - 1:
                        time.sleep(2 ** attempt)
                        
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}): {e}")
                if attempt < retry_count - 1:
                    time.sleep(2 ** attempt)
        
        return None
    
    def create_metadata(self, title: str, author: str, chapters: List[Tuple[str, int, int]]) -> Dict:
        """
        –°–æ–∑–¥–∞–µ—Ç –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–ª—è –∞—É–¥–∏–æ–∫–Ω–∏–≥–∏
        
        Args:
            title: –ù–∞–∑–≤–∞–Ω–∏–µ –∫–Ω–∏–≥–∏
            author: –ê–≤—Ç–æ—Ä
            chapters: –°–ø–∏—Å–æ–∫ –≥–ª–∞–≤
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        """
        return {
            "title": title,
            "author": author,
            "processed_date": datetime.now().isoformat(),
            "total_chapters": len(chapters),
            "chapters": [
                {
                    "title": chapter[0],
                    "start_line": chapter[1],
                    "end_line": chapter[2]
                }
                for chapter in chapters
            ],
            "processing_stats": self.stats,
            "audio_tags_used": [
                "[PAUSE]", "[EMPHASIS]", "[SLOW]", 
                "[BACKGROUND_MUSIC]", "[SOUND_EFFECT]",
                "[CHAPTER_START]", "[CHAPTER_END]"
            ]
        }
    
    def process_text_file(self, input_file: str, output_file: str, 
                         metadata_file: str = None, chunk_size: int = 2500) -> bool:
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∞—É–¥–∏–æ–∫–Ω–∏–≥–∏
        
        Args:
            input_file: –í—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª
            output_file: –í—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª
            metadata_file: –§–∞–π–ª –¥–ª—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
            chunk_size: –†–∞–∑–º–µ—Ä —á–∞—Å—Ç–∏
            
        Returns:
            True –µ—Å–ª–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ —É—Å–ø–µ—à–Ω–∞
        """
        start_time = time.time()
        
        try:
            # –ß–∏—Ç–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª
            with open(input_file, 'r', encoding='utf-8') as f:
                text = f.read()
            
            print(f"üìñ –ó–∞–≥—Ä—É–∂–µ–Ω —Ñ–∞–π–ª: {input_file}")
            print(f"üìä –†–∞–∑–º–µ—Ä —Ç–µ–∫—Å—Ç–∞: {len(text):,} —Å–∏–º–≤–æ–ª–æ–≤")
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≥–ª–∞–≤—ã
            chapters = self.detect_chapters(text)
            print(f"üìö –ù–∞–π–¥–µ–Ω–æ –≥–ª–∞–≤: {len(chapters)}")
            
            # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —á–∞—Å—Ç–∏
            chunks = self.split_text_into_chunks(text, chunk_size)
            self.stats['total_chunks'] = len(chunks)
            print(f"üî™ –†–∞–∑–±–∏—Ç–æ –Ω–∞ {len(chunks)} —á–∞—Å—Ç–µ–π")
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—É—é —á–∞—Å—Ç—å
            processed_chunks = []
            
            for i, chunk in enumerate(chunks, 1):
                print(f"üîÑ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é —á–∞—Å—Ç—å {i}/{len(chunks)} ({len(chunk)} —Å–∏–º–≤–æ–ª–æ–≤)...")
                
                processed_chunk = self.process_chunk_with_ai(chunk, i, len(chunks))
                
                if processed_chunk:
                    processed_chunks.append(processed_chunk)
                    self.stats['processed_chunks'] += 1
                    self.stats['total_characters'] += len(processed_chunk)
                    print(f"‚úÖ –ß–∞—Å—Ç—å {i} –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
                else:
                    print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —á–∞—Å—Ç–∏ {i}")
                    processed_chunks.append(chunk)  # –û—Å—Ç–∞–≤–ª—è–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
                    self.stats['failed_chunks'] += 1
                
                # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
                if i < len(chunks):
                    time.sleep(1.5)
            
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ —á–∞—Å—Ç–∏
            final_text = "\n\n[PAUSE]\n\n".join(processed_chunks)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(final_text)
            
            # –°–æ–∑–¥–∞–µ–º –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            if metadata_file:
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –∏ –∞–≤—Ç–æ—Ä–∞ –∏–∑ —Ç–µ–∫—Å—Ç–∞
                title = Path(input_file).stem
                author = "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∞–≤—Ç–æ—Ä"
                
                # –ü–æ–ø—ã—Ç–∫–∞ –Ω–∞–π—Ç–∏ –∞–≤—Ç–æ—Ä–∞ –≤ —Ç–µ–∫—Å—Ç–µ
                author_patterns = [
                    r'–ê–≤—Ç–æ—Ä[:\s]+([^\n]+)',
                    r'Author[:\s]+([^\n]+)',
                    r'([–ê-–Ø][–∞-—è]+\s+[–ê-–Ø][–∞-—è]+)\s*[-‚Äì‚Äî]\s*–∞–≤—Ç–æ—Ä'
                ]
                
                for pattern in author_patterns:
                    match = re.search(pattern, text[:2000], re.IGNORECASE)
                    if match:
                        author = match.group(1).strip()
                        break
                
                metadata = self.create_metadata(title, author, chapters)
                
                with open(metadata_file, 'w', encoding='utf-8') as f:
                    json.dump(metadata, f, ensure_ascii=False, indent=2)
                
                print(f"üìã –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {metadata_file}")
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            self.stats['processing_time'] = time.time() - start_time
            
            print(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
            print(f"üìÑ –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {output_file}")
            print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
            print(f"   - –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —á–∞—Å—Ç–µ–π: {self.stats['processed_chunks']}/{self.stats['total_chunks']}")
            print(f"   - –û—à–∏–±–æ–∫: {self.stats['failed_chunks']}")
            print(f"   - –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {self.stats['processing_time']:.1f} —Å–µ–∫")
            print(f"   - –†–∞–∑–º–µ—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞: {len(final_text):,} —Å–∏–º–≤–æ–ª–æ–≤")
            
            return True
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞: {e}")
            return False


def main():
    parser = argparse.ArgumentParser(
        description="–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∞—É–¥–∏–æ–∫–Ω–∏–≥–∏",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
  python audiobook_processor.py input.txt -o output.txt
  python audiobook_processor.py input.txt -o output.txt --metadata metadata.json
  python audiobook_processor.py input.txt -o output.txt --chunk-size 2000 --model anthropic/claude-3.5-sonnet
        """
    )
    
    parser.add_argument('input_file', help='–í—Ö–æ–¥–Ω–æ–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª')
    parser.add_argument('-o', '--output', required=True, help='–í—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª')
    parser.add_argument('--metadata', help='–§–∞–π–ª –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö')
    parser.add_argument('--api-key', help='API –∫–ª—é—á OpenRouter (–∏–ª–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è OPENROUTER_API_KEY)')
    parser.add_argument('--model', default='anthropic/claude-3.5-sonnet', 
                       help='–ú–æ–¥–µ–ª—å –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è')
    parser.add_argument('--chunk-size', type=int, default=2500,
                       help='–†–∞–∑–º–µ—Ä —á–∞—Å—Ç–∏ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏')
    
    args = parser.parse_args()
    
    # –ü–æ–ª—É—á–∞–µ–º API –∫–ª—é—á
    api_key = args.api_key or os.getenv('OPENROUTER_API_KEY')
    if not api_key:
        print("‚ùå –û—à–∏–±–∫–∞: –ù–µ —É–∫–∞–∑–∞–Ω API –∫–ª—é—á OpenRouter")
        print("–£–∫–∞–∂–∏—Ç–µ —á–µ—Ä–µ–∑ --api-key –∏–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é OPENROUTER_API_KEY")
        return 1
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª
    if not Path(args.input_file).exists():
        print(f"‚ùå –û—à–∏–±–∫–∞: –§–∞–π–ª {args.input_file} –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return 1
    
    # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º
    processor = AudioBookProcessor(api_key, args.model)
    
    success = processor.process_text_file(
        args.input_file, 
        args.output, 
        args.metadata,
        args.chunk_size
    )
    
    return 0 if success else 1


if __name__ == "__main__":
    exit(main()) 