#!/usr/bin/env python3
"""
–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –∫–æ—Ä—Ä–µ–∫—Ç–æ—Ä —Ç–µ–∫—Å—Ç–∞.

–§—É–Ω–∫—Ü–∏–∏:
- –†–∞–∑–±–∏–≤–∞–µ—Ç –≤—ã–±—Ä–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –Ω–∞ —á–∞—Å—Ç–∏ –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –≤ LLM –∑–∞–ø—Ä–æ—Å –Ω–∞ –ø–æ–∏—Å–∫ –∫–æ—Ä—Ä–µ–∫—Ü–∏–π
- –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ –ø—Ä–∞–≤–æ–∫ –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON (—á—Ç–æ –∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞ —á—Ç–æ, —Å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–º)
- –ü—Ä–æ—Ö–æ–¥–∏—Ç –ø–æ –ø—Ä–∞–≤–∫–∞–º –≤ —Ç–µ—Ä–º–∏–Ω–∞–ª–µ: –ø—Ä–∏–º–µ–Ω–∏—Ç—å, –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å –∏–ª–∏ –æ—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å –≤—Ä—É—á–Ω—É—é
- –û—Å–æ–±—ã–π –∞–∫—Ü–µ–Ω—Ç –Ω–∞ –∑–∞–º–µ–Ω—É –≤—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –∏–Ω–æ—Å—Ç—Ä–∞–Ω–Ω—ã—Ö —Å–ª–æ–≤ –Ω–∞ —Ä—É—Å—Å–∫–∏–π —ç–∫–≤–∏–≤–∞–ª–µ–Ω—Ç, –µ—Å–ª–∏ –µ—Å—Ç—å —É–º–µ—Å—Ç–Ω—ã–π –∞–Ω–∞–ª–æ–≥

–ü—Ä–∏–º–µ—Ä:
  python text_processors/correction_processor.py input.txt -o corrected.txt
  python text_processors/correction_processor.py input.txt -o corrected.txt --config config.env --model budget
"""

import os
import sys
import json
import time
import argparse
import requests
from dataclasses import dataclass
from pathlib import Path
from typing import List, Dict, Optional, Tuple
from dotenv import load_dotenv
import re


@dataclass
class Correction:
    """–ï–¥–∏–Ω–∏—á–Ω–∞—è –ø—Ä–∞–≤–∫–∞, –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å—é."""
    original: str
    replacement: str
    reason: str
    start: Optional[int] = None  # –ü–æ–∑–∏—Ü–∏—è –≤ —á–∞–Ω–∫–µ (–æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–∞—è)
    end: Optional[int] = None
    chunk_index: Optional[int] = None  # –î–ª—è –æ—Ç–ª–∞–¥–∫–∏


class InteractiveCorrector:
    def __init__(self, config_file: Optional[str] = None):
        self.load_config(config_file)
        if not self.api_key:
            raise ValueError("API –∫–ª—é—á OpenRouter –Ω–µ –Ω–∞–π–¥–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ OPENROUTER_API_KEY –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ --config")

        self.base_url = "https://openrouter.ai/api/v1"
        self.headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
            "HTTP-Referer": "https://github.com/your-repo/bookreader",
            "X-Title": "Interactive Correction Processor"
        }

    def load_config(self, config_file: Optional[str]):
        if config_file and Path(config_file).exists():
            load_dotenv(config_file)
        else:
            for env_file in ['.env', 'config.env', 'settings.env']:
                if Path(env_file).exists():
                    load_dotenv(env_file)
                    break

        self.api_key = os.getenv('OPENROUTER_API_KEY')
        self.model = os.getenv('DEFAULT_MODEL', 'anthropic/claude-3.5-sonnet')
        self.chunk_size = int(os.getenv('DEFAULT_CHUNK_SIZE', '3000'))
        self.temperature = float(os.getenv('DEFAULT_TEMPERATURE', '0.2'))
        self.max_tokens = int(os.getenv('DEFAULT_MAX_TOKENS', '3000'))

        # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –º–æ–¥–µ–ª–∏
        self.budget_model = os.getenv('BUDGET_MODEL', 'meta-llama/llama-3.1-8b-instruct')
        self.quality_model = os.getenv('QUALITY_MODEL', 'openai/gpt-4o')

    def split_text(self, text: str) -> List[str]:
        # –†–∞–∑–±–∏—Ç—å –ø–æ –∞–±–∑–∞—Ü–∞–º –∏ —Å–æ–±—Ä–∞—Ç—å —á–∞–Ω–∫–∏ –¥–æ –ª–∏–º–∏—Ç–∞
        paragraphs = [p for p in text.split('\n\n')]
        chunks: List[str] = []
        current = ''
        for p in paragraphs:
            if len(current) + len(p) + 2 > self.chunk_size and current:
                chunks.append(current)
                current = p
            else:
                current = (current + ('\n\n' if current else '') + p) if p else current
        if current:
            chunks.append(current)
        return chunks

    def build_prompt(self, chunk: str, idx: int, total: int) -> str:
        return (
            "–¢—ã ‚Äî –æ–ø—ã—Ç–Ω—ã–π —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã–π –∫–æ—Ä—Ä–µ–∫—Ç–æ—Ä. –ó–∞–¥–∞—á–∞ ‚Äî –Ω–∞–π—Ç–∏ –¢–û–õ–¨–ö–û —Ä–µ–∞–ª—å–Ω—ã–µ –æ—à–∏–±–∫–∏.\n"
            "–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –ø—Ä–∞–≤–∫–∞–º:\n"
            "- –ò—Å–ø—Ä–∞–≤–ª—è–π –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏—é, –ø—É–Ω–∫—Ç—É–∞—Ü–∏—é, –≥—Ä–∞–º–º–∞—Ç–∏–∫—É.\n"
            "- –°–æ—Ö—Ä–∞–Ω—è–π —Å–º—ã—Å–ª –∞–≤—Ç–æ—Ä–∞, –Ω–µ –º–µ–Ω—è–π —Å—Ç–∏–ª—å –±–µ–∑ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏.\n"
            "- –û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –≤—ã—è–≤–ª—è–π –≤—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ –∏–Ω–æ—Å—Ç—Ä–∞–Ω–Ω—ã–µ —Å–ª–æ–≤–∞; –µ—Å–ª–∏ –µ—Å—Ç—å –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–π —Ä—É—Å—Å–∫–∏–π –∞–Ω–∞–ª–æ–≥ –≤ —ç—Ç–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ ‚Äî –ø—Ä–µ–¥–ª–æ–∂–∏ –∑–∞–º–µ–Ω—É.\n"
            "- –ù–ï –ø—Ä–µ–¥–ª–∞–≥–∞–π –ø—Ä–∞–≤–∫–∏ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤, –º–µ—Ç–æ–∫ –∏ –Ω—É–º–µ—Ä–∞—Ç–æ—Ä–æ–≤ —Ä–∞–∑–¥–µ–ª–æ–≤, –Ω–∞–ø—Ä–∏–º–µ—Ä —Å—Ç—Ä–æ–∫ –≤–∏–¥–∞ '## –§—Ä–∞–≥–º–µ–Ω—Ç N', —Å—Ç—Ä–æ–∫ –Ω–∞—á–∏–Ω–∞—é—â–∏—Ö—Å—è —Å '#', –∞ —Ç–∞–∫–∂–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö –∑–∞–≥–ª–∞–≤–∏–π.\n"
            "- –ù–ï –ø—Ä–µ–¥–ª–∞–≥–∞–π –ø—Ä–∞–≤–æ–∫, –µ—Å–ª–∏ –∑–∞–º–µ–Ω–∞ –∏–¥–µ–Ω—Ç–∏—á–Ω–∞ –∏—Å—Ö–æ–¥–Ω–æ–º—É —Ñ—Ä–∞–≥–º–µ–Ω—Ç—É.\n"
            "- –ö–∞–∂–¥–∞—è –ø—Ä–∞–≤–∫–∞ –¥–æ–ª–∂–Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞—Ç—å —Ç–æ—á–Ω–æ–π –ø–æ–¥—Å—Ç—Ä–æ–∫–µ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞.\n"
            "- –ü—Ä–µ–¥–ª–∞–≥–∞–π –º–∏–Ω–∏–º–∞–ª—å–Ω–æ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω—É—é –∑–∞–º–µ–Ω—É, –±–µ–∑ –ø–µ—Ä–µ–ø–∏—Å—ã–≤–∞–Ω–∏—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π.\n\n"
            "–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ ‚Äî —Å—Ç—Ä–æ–≥–æ JSON —Å–æ —Å—Ö–µ–º–æ–π:\n"
            "{ 'corrections': [\n"
            "    { 'original': '—Ä–æ–≤–Ω–æ –∫–∞–∫ –≤ —Ç–µ–∫—Å—Ç–µ', 'replacement': '–Ω–æ–≤—ã–π —Ç–µ–∫—Å—Ç',\n"
            "      'reason': '–∫—Ä–∞—Ç–∫–æ', 'start': —á–∏—Å–ª–æ_–∏–ª–∏_null, 'end': —á–∏—Å–ª–æ_–∏–ª–∏_null,\n"
            "      'type': 'spelling|punctuation|grammar|foreign_word|typo|other', 'confidence': 0.0..1.0 }\n"
            "] }\n\n"
            f"–ß–∞—Å—Ç—å {idx} –∏–∑ {total}. –¢–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –Ω–∏–∂–µ –º–µ–∂–¥—É <TEXT>:</TEXT>\n"
            "<TEXT>\n" + chunk + "\n</TEXT>\n"
            "–í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π JSON –±–µ–∑ –ø–æ—è—Å–Ω–µ–Ω–∏–π. –ï—Å–ª–∏ –ø—Ä–∞–≤–æ–∫ –Ω–µ—Ç, –≤–µ—Ä–Ω–∏ {\"corrections\": []}."
        )

    def request_corrections(self, chunk: str, idx: int, total: int, model: Optional[str]) -> List[Correction]:
        prompt = self.build_prompt(chunk, idx, total)
        payload = {
            "model": model or self.model,
            "messages": [{"role": "user", "content": prompt}],
            "temperature": self.temperature,
            "max_tokens": self.max_tokens
        }

        for attempt in range(3):
            try:
                resp = requests.post(f"{self.base_url}/chat/completions", headers=self.headers, json=payload, timeout=90)
                if resp.status_code == 200:
                    data = resp.json()
                    content = data['choices'][0]['message']['content'].strip()
                    # –ü–æ–ø—Ä–æ–±—É–µ–º —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON (–≤–æ–∑–º–æ–∂–Ω–æ, –æ–∫—Ä—É–∂–µ–Ω –∫–æ–¥-–±–ª–æ–∫–∞–º–∏)
                    content = self._strip_code_fences(content)
                    obj = json.loads(content)
                    result: List[Correction] = []
                    for c in obj.get('corrections', []):
                        original = c.get('original', '') or ''
                        replacement = c.get('replacement', '') or ''
                        # –ª–æ–∫–∞–ª—å–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –Ω–∞ —É—Ä–æ–≤–Ω–µ –º–æ–¥–µ–ª–∏: –æ—Ç–±—Ä–∞—Å—ã–≤–∞–µ–º –∏–¥–µ–Ω—Ç–∏—á–Ω—ã–µ
                        if self._is_effectively_identical(original, replacement):
                            continue
                        # –æ—Ç–±—Ä–∞—Å—ã–≤–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ –≤–∏–¥–∞ '## –§—Ä–∞–≥–º–µ–Ω—Ç N'
                        if self._looks_like_fragment_header(original):
                            continue
                        # —Ñ–∏–ª—å—Ç—Ä –ø–æ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏, –µ—Å–ª–∏ –µ—Å—Ç—å
                        conf = c.get('confidence')
                        if isinstance(conf, (int, float)) and conf < 0.7:
                            continue
                        result.append(Correction(
                            original=original,
                            replacement=replacement,
                            reason=c.get('reason', ''),
                            start=c.get('start'),
                            end=c.get('end'),
                            chunk_index=idx-1
                        ))
                    return result
                if resp.status_code == 429:
                    time.sleep(2 ** (attempt + 1))
                else:
                    time.sleep(1.0)
            except Exception:
                time.sleep(1.0)
        return []

    def _strip_code_fences(self, s: str) -> str:
        if s.startswith("```") and s.endswith("```"):
            # –£–¥–∞–ª–∏–º –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É –∏ –ø–æ—Å–ª–µ–¥–Ω—é—é
            lines = s.splitlines()
            if len(lines) >= 2:
                inner = "\n".join(lines[1:-1])
                return inner
        return s

    def _is_effectively_identical(self, a: str, b: str) -> bool:
        def norm(x: str) -> str:
            x = re.sub(r"\s+", " ", x or "").strip()
            return x
        return norm(a) == norm(b)

    def _looks_like_fragment_header(self, s: str) -> bool:
        s = (s or '').strip()
        if re.match(r"^#+\\s", s):
            return True
        if re.match(r"^##\\s*–§—Ä–∞–≥–º–µ–Ω—Ç\\s*\d+", s, flags=re.IGNORECASE):
            return True
        return False

    def _find_in_window(self, text: str, needle: str, expected_pos: int, window: int = 300) -> Optional[int]:
        if not needle:
            return None
        start = max(0, expected_pos - window)
        end = min(len(text), expected_pos + window)
        segment = text[start:end]
        rel = segment.find(needle)
        if rel == -1:
            # fallback: try normalized spaces
            compact = re.sub(r"\s+", " ", segment)
            rel2 = compact.find(re.sub(r"\s+", " ", needle))
            if rel2 == -1:
                return None
            # Cannot easily remap to original indices; fall back to global search
            pos = text.find(needle)
            return pos if pos != -1 else None
        return start + rel

    def _preview_context(self, text: str, start: int, end: int, max_ctx: int = 120) -> str:
        left = max(0, start - max_ctx)
        right = min(len(text), end + max_ctx)
        before = text[left:start]
        target = text[start:end]
        after = text[end:right]
        return before + "<<" + target + ">>" + after

    def _prompt_user(self, corr: Correction, context: str) -> Tuple[str, Optional[str]]:
        print()
        print("-"*80)
        print("–ü—Ä–∏—á–∏–Ω–∞:", corr.reason or "(–Ω–µ —É–∫–∞–∑–∞–Ω–æ)")
        print("–ö–æ–Ω—Ç–µ–∫—Å—Ç:")
        print(context)
        print()
        print(f"–ó–∞–º–µ–Ω–∏—Ç—å: '{corr.original}' ‚Üí '{corr.replacement}'")
        choice = input("[a] –ø—Ä–∏–º–µ–Ω–∏—Ç—å  [s] –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å  [e] –æ—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å ‚Üí ").strip().lower() or 'a'
        if choice == 'e':
            manual = input("–í–≤–µ–¥–∏—Ç–µ —Å–≤–æ–π –≤–∞—Ä–∏–∞–Ω—Ç –∑–∞–º–µ–Ω—ã (–ø—É—Å—Ç–æ —á—Ç–æ–±—ã –æ—Å—Ç–∞–≤–∏—Ç—å –∫–∞–∫ –µ—Å—Ç—å): ")
            return 'e', manual
        if choice not in ('a','s'):
            return 's', None
        return choice, None

    def run(self, input_path: Path, output_path: Path, model_choice: Optional[str] = None, dry_run: bool = False) -> bool:
        try:
            text = input_path.read_text(encoding='utf-8')
        except Exception as e:
            print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª: {e}")
            return False

        chunks = self.split_text(text)
        print(f"üìÑ –ó–∞–≥—Ä—É–∂–µ–Ω —Ç–µ–∫—Å—Ç: {len(text):,} —Å–∏–º–≤–æ–ª–æ–≤, —á–∞—Å—Ç–µ–π: {len(chunks)}")

        # –ö–∞—Ä—Ç–∞ —Å–º–µ—â–µ–Ω–∏–π —á–∞–Ω–∫–æ–≤ –≤ –æ–±—â–µ–º —Ç–µ–∫—Å—Ç–µ
        chunk_offsets: List[int] = []
        offset = 0
        for ch in chunks:
            pos = text.find(ch, offset)
            if pos == -1:
                pos = offset
            chunk_offsets.append(pos)
            offset = pos + len(ch)

        all_corrections: List[Tuple[int, Correction]] = []  # (global_pos_hint, correction)
        for i, ch in enumerate(chunks, start=1):
            print(f"üîé –ê–Ω–∞–ª–∏–∑ —á–∞—Å—Ç–∏ {i}/{len(chunks)}...")
            corrs = self.request_corrections(ch, i, len(chunks), model_choice)
            base = chunk_offsets[i-1]
            for c in corrs:
                hint = base + (c.start or 0)
                all_corrections.append((hint, c))
            # –Ω–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
            if i < len(chunks):
                time.sleep(1.2)

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º–æ–π –ø–æ–∑–∏—Ü–∏–∏ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
        all_corrections.sort(key=lambda x: x[0])

        print(f"\n–ù–∞–π–¥–µ–Ω–æ –ø—Ä–∞–≤–æ–∫: {len(all_corrections)}")
        current_text = text
        applied = 0
        skipped = 0

        for hint_pos, corr in all_corrections:
            # –ó–∞—â–∏—Ç–∞ –Ω–∞ —ç—Ç–∞–ø–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è: –∏–¥–µ–Ω—Ç–∏—á–Ω—ã–µ –ø—Ä–∞–≤–∫–∏ –∏ –∑–∞–≥–æ–ª–æ–≤–∫–∏ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
            if self._is_effectively_identical(corr.original, corr.replacement):
                skipped += 1
                continue
            if self._looks_like_fragment_header(corr.original):
                skipped += 1
                continue
            # –ù–∞—Ö–æ–¥–∏–º —Ñ–∞–∫—Ç–∏—á–µ—Å–∫—É—é –ø–æ–∑–∏—Ü–∏—é –ø–æ –æ–∫–Ω—É –≤–æ–∫—Ä—É–≥ –ø–æ–¥—Å–∫–∞–∑–∫–∏
            pos = self._find_in_window(current_text, corr.original, hint_pos)
            if pos is None:
                # fallback: –≥–ª–æ–±–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫
                pos = current_text.find(corr.original)
                if pos == -1:
                    skipped += 1
                    continue
            end = pos + len(corr.original)
            ctx = self._preview_context(current_text, pos, end)

            action, manual = self._prompt_user(corr, ctx)
            if action == 's':
                skipped += 1
                continue
            replacement = corr.replacement if action == 'a' else (manual if manual is not None else corr.replacement)
            if replacement == "":
                # –£–¥–∞–ª–µ–Ω–∏–µ
                new_text = current_text[:pos] + current_text[end:]
            else:
                new_text = current_text[:pos] + replacement + current_text[end:]

            if not dry_run:
                current_text = new_text
            applied += 1

        print()
        print(f"‚úÖ –ü—Ä–∏–º–µ–Ω–µ–Ω–æ: {applied}, –ø—Ä–æ–ø—É—â–µ–Ω–æ: {skipped}")

        if not dry_run:
            try:
                output_path.write_text(current_text, encoding='utf-8')
                print(f"üì¶ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {output_path}")
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ —Ñ–∞–π–ª–∞: {e}")
                return False

        return True


def main():
    parser = argparse.ArgumentParser(
        description="–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∞—è –∫–æ—Ä—Ä–µ–∫—Ç—É—Ä–∞ —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–º–æ—â—å—é LLM",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
–ü—Ä–∏–º–µ—Ä—ã:
  python text_processors/correction_processor.py input.txt -o corrected.txt
  python text_processors/correction_processor.py input.txt -o corrected.txt --config config.env --model budget
        """
    )

    parser.add_argument('input_file', help='–í—Ö–æ–¥–Ω–æ–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç—É—Ä—ã')
    parser.add_argument('-o', '--output', required=True, help='–í—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è–º–∏')
    parser.add_argument('--config', help='–ü—É—Ç—å –∫ .env —Ñ–∞–π–ª—É —Å –∫–ª—é—á–æ–º –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏')
    parser.add_argument('--model', choices=['default', 'budget', 'quality'], default='default', help='–í—ã–±–æ—Ä –ø—Ä–µ–¥–Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏')
    parser.add_argument('--dry-run', action='store_true', help='–ù–µ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å —Ñ–∞–π–ª, —Ç–æ–ª—å–∫–æ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –ø—Ä–æ—Å–º–æ—Ç—Ä')
    parser.add_argument('--export-html', action='store_true', help='–ü–æ—Å–ª–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ç–∞–∫–∂–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å HTML –∏–∑ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞')
    parser.add_argument('--html-title', help='–ó–∞–≥–æ–ª–æ–≤–æ–∫ HTML —Å—Ç—Ä–∞–Ω–∏—Ü—ã –ø—Ä–∏ —ç–∫—Å–ø–æ—Ä—Ç–µ')

    args = parser.parse_args()

    try:
        corrector = InteractiveCorrector(args.config)
        model_choice = None
        if args.model == 'budget':
            model_choice = corrector.budget_model
        elif args.model == 'quality':
            model_choice = corrector.quality_model
        else:
            model_choice = corrector.model

        in_path = Path(args.input_file)
        if not in_path.exists():
            print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {in_path}")
            return 1

        out_path = Path(args.output)
        ok = corrector.run(in_path, out_path, model_choice=model_choice, dry_run=args.dry_run)
        if not ok:
            return 1
        if ok and (args.export_html and not args.dry_run):
            try:
                # –õ–µ–Ω–∏–≤–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–µ—Ä–∞
                from text_processors.markdown_to_html import markdown_to_html
                html_doc = markdown_to_html(out_path.read_text(encoding='utf-8'), title=args.html_title or out_path.stem)
                html_path = out_path.with_suffix('.html')
                html_path.write_text(html_doc, encoding='utf-8')
                print(f"üåê HTML —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω: {html_path}")
            except Exception as e:
                print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å HTML: {e}")
        return 0
    except ValueError as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {e}")
        return 1
    except KeyboardInterrupt:
        print("\n‚õî –ü—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        return 1
    except Exception as e:
        print(f"‚ùå –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")
        return 1


if __name__ == "__main__":
    sys.exit(main())


