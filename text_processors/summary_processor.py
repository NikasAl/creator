#!/usr/bin/env python3
"""
–ü—Ä–æ—Ü–µ—Å—Å–æ—Ä –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ø–µ—Ä–µ—Å–∫–∞–∑–∞ –æ—Å–Ω–æ–≤–Ω—ã—Ö –∏–¥–µ–π –∏–∑ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ —Ç–µ–∫—Å—Ç–∞
–§–æ–∫—É—Å–∏—Ä—É–µ—Ç—Å—è –Ω–∞ –∏–∑–ª–æ–∂–µ–Ω–∏–∏ —Å–ª–æ–∂–Ω—ã—Ö –∫–æ–Ω—Ü–µ–ø—Ü–∏–π –ø—Ä–æ—Å—Ç—ã–º —è–∑—ã–∫–æ–º –¥–ª—è –Ω–µ–ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω–æ–≥–æ —á–∏—Ç–∞—Ç–µ–ª—è
"""

import os
import sys
import json
import time
import argparse
import requests
from pathlib import Path
from typing import List, Dict, Optional, Tuple
from dotenv import load_dotenv
import re
from datetime import datetime
import locale

# –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ä—É—Å—Å–∫—É—é –ª–æ–∫–∞–ª—å –¥–ª—è —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –¥–∞—Ç
try:
    locale.setlocale(locale.LC_TIME, 'ru_RU.UTF-8')
except:
    try:
        locale.setlocale(locale.LC_TIME, 'ru_RU')
    except:
        pass


class SummaryProcessor:
    def __init__(self, config_file: str = None, book_title: str = None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞ —Å –∑–∞–≥—Ä—É–∑–∫–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        
        Args:
            config_file: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ .env
            book_title: –ù–∞–∑–≤–∞–Ω–∏–µ –∫–Ω–∏–≥–∏ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö
        """
        # –°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∂–∞–µ–º –±–∞–∑–æ–≤—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
        self.load_config(config_file)
        
        # –ó–∞—Ç–µ–º –∑–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥ –∑–∞–¥–∞–Ω–∏—è (–µ—Å–ª–∏ –µ—Å—Ç—å)
        self.load_task_config()
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–Ω–∏–≥–∏
        self.book_title = book_title
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        if not self.api_key:
            raise ValueError("API –∫–ª—é—á OpenRouter –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ API
        self.base_url = "https://openrouter.ai/api/v1"
        self.headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
            "HTTP-Referer": "https://github.com/your-repo/summary-processor",
            "X-Title": "Summary Processor"
        }
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.stats = {
            'total_chunks': 0,
            'processed_chunks': 0,
            'failed_chunks': 0,
            'total_characters': 0,
            'total_tokens_used': 0,
            'processing_time': 0,
            'api_calls': 0,
            'topic_detection_calls': 0,
            'summaries_created': 0
        }
    
    def load_config(self, config_file: str = None):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∏–∑ .env —Ñ–∞–π–ª–∞"""
        # –ü—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
        if config_file and Path(config_file).exists():
            load_dotenv(config_file)
        else:
            # –ò—â–µ–º .env —Ñ–∞–π–ª –≤ —Ç–µ–∫—É—â–µ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
            env_files = ['.env', 'config.env', 'settings.env']
            for env_file in env_files:
                if Path(env_file).exists():
                    load_dotenv(env_file)
                    break
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        self.api_key = os.getenv('OPENROUTER_API_KEY')
        self.model = os.getenv('DEFAULT_MODEL', 'anthropic/claude-3.5-sonnet')
        self.chunk_size = int(os.getenv('DEFAULT_CHUNK_SIZE', '10000'))
        self.temperature = float(os.getenv('DEFAULT_TEMPERATURE', '0.3'))
        self.max_tokens = int(os.getenv('DEFAULT_MAX_TOKENS', '4000'))
        
        # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –º–æ–¥–µ–ª–∏
        self.budget_model = os.getenv('BUDGET_MODEL', 'meta-llama/llama-3.1-8b-instruct')
        self.quality_model = os.getenv('QUALITY_MODEL', 'openai/gpt-4o')
        
        # –ú–æ–¥–µ–ª–∏ –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞ –∑–∞–¥–∞–Ω–∏—è (–ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è—é—Ç –±–∞–∑–æ–≤—ã–µ)
        self.summary_model = os.getenv('SUMMARY_MODEL', self.model)
        self.vision_model = os.getenv('VISION_MODEL', os.getenv('VISION_MODEL', ''))
        self.image_model = os.getenv('IMAGE_MODEL', 'FLUX')
        
        print(f"‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω–∞:")
        print(f"   –ú–æ–¥–µ–ª—å: {self.model}")
        print(f"   –ú–æ–¥–µ–ª—å –¥–ª—è –ø–µ—Ä–µ—Å–∫–∞–∑–∞: {self.summary_model}")
        print(f"   –ú–æ–¥–µ–ª—å –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {self.image_model}")
        print(f"   –†–∞–∑–º–µ—Ä —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞: {self.chunk_size}")
        print(f"   –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞: {self.temperature}")
    
    def load_task_config(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∫–æ–Ω—Ñ–∏–≥–∞ –∑–∞–¥–∞–Ω–∏—è –∏–∑ –æ–∫—Ä—É–∂–µ–Ω–∏—è"""
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞ –∑–∞–¥–∞–Ω–∏—è
        task_summary_model = os.getenv('SUMMARY_MODEL')
        task_vision_model = os.getenv('VISION_MODEL')
        task_image_model = os.getenv('IMAGE_MODEL')
        
        # –ü–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ–º –º–æ–¥–µ–ª–∏ –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞ –∑–∞–¥–∞–Ω–∏—è, –µ—Å–ª–∏ –æ–Ω–∏ –∑–∞–¥–∞–Ω—ã
        if task_summary_model:
            self.summary_model = task_summary_model
            self.model = task_summary_model  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –¥–ª—è –ø–µ—Ä–µ—Å–∫–∞–∑–∞
            print(f"   –ú–æ–¥–µ–ª—å –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ –∫–æ–Ω—Ñ–∏–≥–æ–º –∑–∞–¥–∞–Ω–∏—è: {task_summary_model}")
        
        if task_vision_model:
            self.vision_model = task_vision_model
            print(f"   –ú–æ–¥–µ–ª—å –∑—Ä–µ–Ω–∏—è –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ –∫–æ–Ω—Ñ–∏–≥–æ–º –∑–∞–¥–∞–Ω–∏—è: {task_vision_model}")
        
        if task_image_model:
            self.image_model = task_image_model
            print(f"   –ú–æ–¥–µ–ª—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ –∫–æ–Ω—Ñ–∏–≥–æ–º –∑–∞–¥–∞–Ω–∏—è: {task_image_model}")
    
    def detect_topic_with_llm(self, text_sample: str) -> Dict[str, str]:
        """
        –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–µ–º—É –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–º–æ—â—å—é LLM
        
        Args:
            text_sample: –û–±—Ä–∞–∑–µ—Ü —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ (–ø–µ—Ä–≤—ã–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç)
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Ç–µ–º–µ –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ
        """
        prompt = f"""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–ª–µ–¥—É—é—â–∏–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç —Ç–µ–∫—Å—Ç–∞ –∏ –æ–ø—Ä–µ–¥–µ–ª–∏ –µ–≥–æ —Ç–µ–º—É –∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏.

–ó–ê–î–ê–ß–ò:
1. –û–ø—Ä–µ–¥–µ–ª–∏ –æ—Å–Ω–æ–≤–Ω—É—é —Ç–µ–º—É —Ç–µ–∫—Å—Ç–∞ (1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)
2. –û—Ü–µ–Ω–∏ —Å–ª–æ–∂–Ω–æ—Å—Ç—å –∏–∑–ª–æ–∂–µ–Ω–∏—è (–Ω–∏–∑–∫–∞—è/—Å—Ä–µ–¥–Ω—è—è/–≤—ã—Å–æ–∫–∞—è)
3. –û–ø—Ä–µ–¥–µ–ª–∏ —Ü–µ–ª–µ–≤—É—é –∞—É–¥–∏—Ç–æ—Ä–∏—é
4. –ü—Ä–µ–¥–ª–æ–∂–∏ —Å—Ç–∏–ª—å –∏–∑–ª–æ–∂–µ–Ω–∏—è –¥–ª—è –ø–µ—Ä–µ—Å–∫–∞–∑–∞

–§–†–ê–ì–ú–ï–ù–¢ –¢–ï–ö–°–¢–ê:
{text_sample[:2000]}...

–û–¢–í–ï–¢–¨ –í –°–õ–ï–î–£–Æ–©–ï–ú –§–û–†–ú–ê–¢–ï:
–¢–ï–ú–ê: [–∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –æ—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–º—ã]
–°–õ–û–ñ–ù–û–°–¢–¨: [–Ω–∏–∑–∫–∞—è/—Å—Ä–µ–¥–Ω—è—è/–≤—ã—Å–æ–∫–∞—è]
–ê–£–î–ò–¢–û–†–ò–Ø: [–æ–ø–∏—Å–∞–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –∞—É–¥–∏—Ç–æ—Ä–∏–∏]
–°–¢–ò–õ–¨: [—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π —Å—Ç–∏–ª—å –∏–∑–ª–æ–∂–µ–Ω–∏—è]"""

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±—é–¥–∂–µ—Ç–Ω—É—é –º–æ–¥–µ–ª—å –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–µ–º—ã
        topic_model = self.budget_model if hasattr(self, 'budget_model') else self.model
        
        payload = {
            "model": topic_model,
            "messages": [
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            "temperature": 0.1,  # –ù–∏–∑–∫–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è –±–æ–ª–µ–µ —Ç–æ—á–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
            "max_tokens": 500
        }
        
        try:
            self.stats['api_calls'] += 1
            self.stats['topic_detection_calls'] += 1
            
            response = requests.post(
                f"{self.base_url}/chat/completions",
                headers=self.headers,
                json=payload,
                timeout=60
            )
            
            if response.status_code == 200:
                result = response.json()
                analysis = result['choices'][0]['message']['content'].strip()
                
                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Ç–æ–∫–µ–Ω–æ–≤
                if 'usage' in result:
                    self.stats['total_tokens_used'] += result['usage']['total_tokens']
                
                # –ü–∞—Ä—Å–∏–º –æ—Ç–≤–µ—Ç
                context_info = self.parse_topic_analysis(analysis)
                return context_info
            else:
                print(f"‚ùå –û—à–∏–±–∫–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–µ–º—ã: {response.status_code}")
                return self.get_default_context()
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏ —Ç–µ–º—ã: {e}")
            return self.get_default_context()
    
    def parse_topic_analysis(self, analysis: str) -> Dict[str, str]:
        """
        –ü–∞—Ä—Å–∏—Ç –æ—Ç–≤–µ—Ç LLM –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ç–µ–º–µ
        
        Args:
            analysis: –û—Ç–≤–µ—Ç –æ—Ç LLM
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Ç–µ–º–µ –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ
        """
        context_info = {
            'topic': '–û–±—â–∞—è —Ç–µ–º–∞',
            'complexity': '—Å—Ä–µ–¥–Ω—è—è',
            'target_audience': '–Ω–µ–ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã–π —á–∏—Ç–∞—Ç–µ–ª—å',
            'style': '–æ–±—É—á–∞—é—â–∏–π'
        }
        
        lines = analysis.split('\n')
        for line in lines:
            line = line.strip()
            if line.startswith('–¢–ï–ú–ê:'):
                context_info['topic'] = line.replace('–¢–ï–ú–ê:', '').strip()
            elif line.startswith('–°–õ–û–ñ–ù–û–°–¢–¨:'):
                complexity = line.replace('–°–õ–û–ñ–ù–û–°–¢–¨:', '').strip().lower()
                if complexity in ['–Ω–∏–∑–∫–∞—è', '—Å—Ä–µ–¥–Ω—è—è', '–≤—ã—Å–æ–∫–∞—è']:
                    context_info['complexity'] = complexity
            elif line.startswith('–ê–£–î–ò–¢–û–†–ò–Ø:'):
                context_info['target_audience'] = line.replace('–ê–£–î–ò–¢–û–†–ò–Ø:', '').strip()
            elif line.startswith('–°–¢–ò–õ–¨:'):
                context_info['style'] = line.replace('–°–¢–ò–õ–¨:', '').strip()
        
        return context_info
    
    def get_default_context(self) -> Dict[str, str]:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –ø—Ä–∏ –æ—à–∏–±–∫–µ
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        """
        return {
            'topic': '–û–±—â–∞—è —Ç–µ–º–∞',
            'complexity': '—Å—Ä–µ–¥–Ω—è—è',
            'target_audience': '–Ω–µ–ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã–π —á–∏—Ç–∞—Ç–µ–ª—å',
            'style': '–æ–±—É—á–∞—é—â–∏–π'
        }
    
    def get_style_russian_name(self, style: str) -> str:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä—É—Å—Å–∫–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ —Å—Ç–∏–ª—è –∏–∑–ª–æ–∂–µ–Ω–∏—è
        
        Args:
            style: –ê–Ω–≥–ª–∏–π—Å–∫–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ —Å—Ç–∏–ª—è
            
        Returns:
            –†—É—Å—Å–∫–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ —Å—Ç–∏–ª—è
        """
        style_mapping = {
            'educational': '–ø–æ–∑–Ω–∞–≤–∞—Ç–µ–ª—å–Ω—ã–π',
            'simple': '–ø—Ä–æ—Å—Ç–æ–π',
            'detailed': '–ø–æ–¥—Ä–æ–±–Ω—ã–π'
        }
        return style_mapping.get(style, style)

    def detect_topic_and_context(self, text: str) -> Dict[str, str]:
        """
        –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–µ–º—É –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞
        
        Args:
            text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Ç–µ–º–µ –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ
        """
        print("üîç –û–ø—Ä–µ–¥–µ–ª—è—é —Ç–µ–º—É —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–º–æ—â—å—é LLM...")
        
        # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–º—ã
        chunks = self.split_text_into_chunks(text)
        if chunks:
            sample_text = chunks[0]
            context_info = self.detect_topic_with_llm(sample_text)
            print(f"‚úÖ –¢–µ–º–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞: {context_info['topic']}")
        else:
            context_info = self.get_default_context()
        
        return context_info
    
    def create_summary_prompt(self, text_chunk: str, chunk_number: int, total_chunks: int, 
                             context_info: Dict[str, str], style: str = 'educational') -> str:
        """
        –°–æ–∑–¥–∞–µ—Ç –ø—Ä–æ–º–ø—Ç –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ø–µ—Ä–µ—Å–∫–∞–∑–∞
        
        Args:
            text_chunk: –§—Ä–∞–≥–º–µ–Ω—Ç —Ç–µ–∫—Å—Ç–∞
            chunk_number: –ù–æ–º–µ—Ä —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞
            total_chunks: –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤
            context_info: –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ
            style: –°—Ç–∏–ª—å –∏–∑–ª–æ–∂–µ–Ω–∏—è ('educational', 'simple', 'detailed')
            
        Returns:
            –ü—Ä–æ–º–ø—Ç –¥–ª—è –Ω–µ–π—Ä–æ—Å–µ—Ç–∏
        """
        style_instructions = {
            'educational': """
–°–¢–ò–õ–¨ –ò–ó–õ–û–ñ–ï–ù–ò–Ø:
- –ò—Å–ø–æ–ª—å–∑—É–π –ø—Ä–æ—Å—Ç–æ–π, –ø–æ–Ω—è—Ç–Ω—ã–π —è–∑—ã–∫
- –û–±—ä—è—Å–Ω—è–π —Å–ª–æ–∂–Ω—ã–µ —Ç–µ—Ä–º–∏–Ω—ã –ø—Ä–æ—Å—Ç—ã–º–∏ —Å–ª–æ–≤–∞–º–∏
- –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ª–æ–≥–∏—á–Ω–æ
- –î–æ–±–∞–≤–ª—è–π –ø—Ä–∏–º–µ—Ä—ã –∏ –∞–Ω–∞–ª–æ–≥–∏–∏
- –î–µ–ª–∞–π –∞–∫—Ü–µ–Ω—Ç –Ω–∞ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–º –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–∏
- –ò—Å–ø–æ–ª—å–∑—É–π –∞–∫—Ç–∏–≤–Ω—ã–π –∑–∞–ª–æ–≥ –∏ –∫–æ—Ä–æ—Ç–∫–∏–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è""",
            
            'simple': """
–°–¢–ò–õ–¨ –ò–ó–õ–û–ñ–ï–ù–ò–Ø:
- –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –ø—Ä–æ—Å—Ç–æ–π —è–∑—ã–∫
- –ò–∑–±–µ–≥–∞–π —Å–ª–æ–∂–Ω—ã—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤
- –ö–æ—Ä–æ—Ç–∫–∏–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
- –ß–µ—Ç–∫–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞
- –û—Å–Ω–æ–≤–Ω—ã–µ —Ñ–∞–∫—Ç—ã –∏ –≤—ã–≤–æ–¥—ã""",
            
            'detailed': """
–°–¢–ò–õ–¨ –ò–ó–õ–û–ñ–ï–ù–ò–Ø:
- –ü–æ–¥—Ä–æ–±–Ω–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–π
- –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –Ω–∞—É—á–Ω–æ–π —Ç–æ—á–Ω–æ—Å—Ç–∏
- –î–µ—Ç–∞–ª—å–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã
- –ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
- –°–≤—è–∑–∏ —Å –¥—Ä—É–≥–∏–º–∏ —Ç–µ–æ—Ä–∏—è–º–∏"""
        }
        
        return f"""–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Å–æ–∑–¥–∞–Ω–∏—é –ø–æ–Ω—è—Ç–Ω—ã—Ö –ø–µ—Ä–µ—Å–∫–∞–∑–æ–≤ —Å–ª–æ–∂–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤. –°–æ–∑–¥–∞–π –ø–µ—Ä–µ—Å–∫–∞–∑ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞ {chunk_number} –∏–∑ {total_chunks}.

–ö–û–ù–¢–ï–ö–°–¢:
- –¢–µ–º–∞: {context_info['topic']}
- –°–ª–æ–∂–Ω–æ—Å—Ç—å –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞: {context_info['complexity']}
- –¶–µ–ª–µ–≤–∞—è –∞—É–¥–∏—Ç–æ—Ä–∏—è: {context_info['target_audience']}

–ó–ê–î–ê–ß–ò:

1. –í–´–î–ï–õ–ï–ù–ò–ï –ì–õ–ê–í–ù–û–ì–û:
   - –û–ø—Ä–µ–¥–µ–ª–∏ –∫–ª—é—á–µ–≤—ã–µ –∏–¥–µ–∏ –∏ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏
   - –í—ã–¥–µ–ª–∏ –æ—Å–Ω–æ–≤–Ω—ã–µ —Ñ–∞–∫—Ç—ã –∏ –∞—Ä–≥—É–º–µ–Ω—Ç—ã
   - –ù–∞–π–¥–∏ —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω—É—é –º—ã—Å–ª—å —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞
   - –ò—Å–∫–ª—é—á–∏ –≤—Ç–æ—Ä–æ—Å—Ç–µ–ø–µ–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é

2. –£–ü–†–û–©–ï–ù–ò–ï:
   - –ü–µ—Ä–µ–≤–µ–¥–∏ —Å–ª–æ–∂–Ω—ã–µ —Ç–µ—Ä–º–∏–Ω—ã –Ω–∞ –ø—Ä–æ—Å—Ç–æ–π —è–∑—ã–∫
   - –û–±—ä—è—Å–Ω–∏ –∞–±—Å—Ç—Ä–∞–∫—Ç–Ω—ã–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏ —á–µ—Ä–µ–∑ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã
   - –†–∞–∑–±–µ–π —Å–ª–æ–∂–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –Ω–∞ –ø—Ä–æ—Å—Ç—ã–µ
   - –ò—Å–ø–æ–ª—å–∑—É–π –∞–∫—Ç–∏–≤–Ω—ã–π –∑–∞–ª–æ–≥

3. –°–¢–†–£–ö–¢–£–†–ò–†–û–í–ê–ù–ò–ï:
   - –°–æ–∑–¥–∞–π –ª–æ–≥–∏—á–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∏–∑–ª–æ–∂–µ–Ω–∏—è
   - –ì—Ä—É–ø–ø–∏—Ä—É–π —Å–≤—è–∑–∞–Ω–Ω—ã–µ –∏–¥–µ–∏
   - –î–æ–±–∞–≤—å –ø–µ—Ä–µ—Ö–æ–¥—ã –º–µ–∂–¥—É —á–∞—Å—Ç—è–º–∏

4. –û–ë–£–ß–ê–Æ–©–ò–ô –ü–û–î–•–û–î:
   - –û–±—ä—è—Å–Ω–∏ "–ø–æ—á–µ–º—É" –∏ "–∫–∞–∫"
   - –î–æ–±–∞–≤—å –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–º–µ—Ä—ã
   - –°–≤—è–∂–∏ —Å –ø–æ–≤—Å–µ–¥–Ω–µ–≤–Ω–æ–π –∂–∏–∑–Ω—å—é
   - –°–¥–µ–ª–∞–π –º–∞—Ç–µ—Ä–∏–∞–ª –∑–∞–ø–æ–º–∏–Ω–∞—é—â–∏–º—Å—è

{style_instructions.get(style, style_instructions['educational'])}

5. –§–û–†–ú–ê–¢ –í–´–í–û–î–ê:
   - –ù–∞—á–Ω–∏ —Å –∫—Ä–∞—Ç–∫–æ–≥–æ –≤–≤–µ–¥–µ–Ω–∏—è –∫ —Ç–µ–º–µ
   - –û—Å–Ω–æ–≤–Ω–∞—è —á–∞—Å—Ç—å —Å –∫–ª—é—á–µ–≤—ã–º–∏ –∏–¥–µ—è–º–∏
   - –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –≤—ã–≤–æ–¥—ã
   - –î–ª–∏–Ω–∞: –ø—Ä–∏–º–µ—Ä–Ω–æ 1/3 –æ—Ç –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
   - –û—Ç–¥–µ–ª—è–π –∑–∞–≥–æ–ª–æ–≤–∫–∏ –ø—É—Å—Ç–æ–π —Å—Ç—Ä–æ–∫–æ–π
   - –ò—Å–ø–æ–ª—å–∑—É–π –º–∞—Ä–∫–¥–∞—É–Ω —Ä–∞–∑–º–µ—Ç–∫—É

–ò–°–•–û–î–ù–´–ô –§–†–ê–ì–ú–ï–ù–¢:
{text_chunk}

–ü–ï–†–ï–°–ö–ê–ó:"""
    
    def split_text_into_chunks(self, text: str) -> List[str]:
        """
        –†–∞–∑–±–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        
        Args:
            text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
            
        Returns:
            –°–ø–∏—Å–æ–∫ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ —Ç–µ–∫—Å—Ç–∞
        """
        # –†–∞–∑–±–∏–≤–∞–µ–º –ø–æ –∞–±–∑–∞—Ü–∞–º
        paragraphs = [p.strip() for p in text.split('\n\n') if p.strip()]
        chunks = []
        current_chunk = ""
        
        for paragraph in paragraphs:
            # –ï—Å–ª–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞ –ø—Ä–µ–≤—ã—Å–∏—Ç –ª–∏–º–∏—Ç
            if len(current_chunk) + len(paragraph) > self.chunk_size and current_chunk:
                chunks.append(current_chunk.strip())
                current_chunk = paragraph
            else:
                if current_chunk:
                    current_chunk += "\n\n" + paragraph
                else:
                    current_chunk = paragraph
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —á–∞–Ω–∫
        if current_chunk:
            chunks.append(current_chunk.strip())
        
        return chunks
    
    def process_chunk_with_retry(self, text_chunk: str, chunk_number: int, 
                               total_chunks: int, context_info: Dict[str, str], 
                               style: str = 'educational', retry_count: int = 3) -> Optional[str]:
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ñ—Ä–∞–≥–º–µ–Ω—Ç —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏
        
        Args:
            text_chunk: –§—Ä–∞–≥–º–µ–Ω—Ç —Ç–µ–∫—Å—Ç–∞
            chunk_number: –ù–æ–º–µ—Ä —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞
            total_chunks: –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤
            context_info: –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ
            style: –°—Ç–∏–ª—å –∏–∑–ª–æ–∂–µ–Ω–∏—è
            retry_count: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫
            
        Returns:
            –ü–µ—Ä–µ—Å–∫–∞–∑ —Ç–µ–∫—Å—Ç–∞ –∏–ª–∏ None
        """
        prompt = self.create_summary_prompt(text_chunk, chunk_number, total_chunks, context_info, style)
        
        payload = {
            "model": self.model,
            "messages": [
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            "temperature": self.temperature,
            "max_tokens": self.max_tokens
        }
        
        for attempt in range(retry_count):
            try:
                self.stats['api_calls'] += 1
                
                response = requests.post(
                    f"{self.base_url}/chat/completions",
                    headers=self.headers,
                    json=payload,
                    timeout=120
                )
                
                if response.status_code == 200:
                    result = response.json()
                    summary = result['choices'][0]['message']['content'].strip()
                    
                    # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Ç–æ–∫–µ–Ω–æ–≤
                    if 'usage' in result:
                        self.stats['total_tokens_used'] += result['usage']['total_tokens']
                    
                    return summary
                else:
                    print(f"‚ùå –û—à–∏–±–∫–∞ API (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}): {response.status_code}")
                    if response.status_code == 429:  # Rate limit
                        wait_time = 2 ** (attempt + 1)
                        print(f"‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ {wait_time} —Å–µ–∫—É–Ω–¥...")
                        time.sleep(wait_time)
                    elif attempt < retry_count - 1:
                        time.sleep(2 ** attempt)
                        
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}): {e}")
                if attempt < retry_count - 1:
                    time.sleep(2 ** attempt)
        
        return None
    
    def process_text_file(self, input_file: str, output_file: str, 
                         style: str = 'educational', chunk_size: int = None) -> bool:
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª
        
        Args:
            input_file: –í—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª
            output_file: –í—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª
            style: –°—Ç–∏–ª—å –∏–∑–ª–æ–∂–µ–Ω–∏—è ('educational', 'simple', 'detailed')
            chunk_size: –†–∞–∑–º–µ—Ä —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            
        Returns:
            True –µ—Å–ª–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ —É—Å–ø–µ—à–Ω–∞
        """
        start_time = time.time()
        
        try:
            # –ß–∏—Ç–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª
            with open(input_file, 'r', encoding='utf-8') as f:
                text = f.read()
            
            print(f"üìñ –ó–∞–≥—Ä—É–∂–µ–Ω —Ñ–∞–π–ª: {input_file}")
            print(f"üìä –†–∞–∑–º–µ—Ä —Ç–µ–∫—Å—Ç–∞: {len(text):,} —Å–∏–º–≤–æ–ª–æ–≤")
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
            context_info = self.detect_topic_and_context(text)
            print(f"üéØ –ö–æ–Ω—Ç–µ–∫—Å—Ç:")
            print(f"   –¢–µ–º–∞: {context_info['topic']}")
            print(f"   –°–ª–æ–∂–Ω–æ—Å—Ç—å: {context_info['complexity']}")
            print(f"   –°—Ç–∏–ª—å: {style}")
            
            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞
            if chunk_size:
                self.chunk_size = chunk_size
            
            # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã
            chunks = self.split_text_into_chunks(text)
            self.stats['total_chunks'] = len(chunks)
            print(f"üî™ –†–∞–∑–±–∏—Ç–æ –Ω–∞ {len(chunks)} —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤")
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç
            summaries = []
            
            for i, chunk in enumerate(chunks, 1):
                print(f"üîÑ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é —Ñ—Ä–∞–≥–º–µ–Ω—Ç {i}/{len(chunks)} ({len(chunk)} —Å–∏–º–≤–æ–ª–æ–≤)...")
                
                summary = self.process_chunk_with_retry(chunk, i, len(chunks), context_info, style)
                
                if summary:
                    summaries.append(f"## –§—Ä–∞–≥–º–µ–Ω—Ç {i}\n\n{summary}")
                    self.stats['processed_chunks'] += 1
                    self.stats['total_characters'] += len(summary)
                    self.stats['summaries_created'] += 1
                    print(f"‚úÖ –§—Ä–∞–≥–º–µ–Ω—Ç {i} –æ–±—Ä–∞–±–æ—Ç–∞–Ω —É—Å–ø–µ—à–Ω–æ")
                else:
                    print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞ {i}")
                    self.stats['failed_chunks'] += 1
                
                # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
                if i < len(chunks):
                    time.sleep(2)
            
            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–∞—Ç—É –ø–æ-—Ä—É—Å—Å–∫–∏
            now = datetime.now()
            try:
                russian_date = now.strftime('%d %B %Y –≥–æ–¥–∞')
            except:
                # Fallback: —Ä—É—á–Ω–æ–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
                months_ru = {
                    1: '—è–Ω–≤–∞—Ä—è', 2: '—Ñ–µ–≤—Ä–∞–ª—è', 3: '–º–∞—Ä—Ç–∞', 4: '–∞–ø—Ä–µ–ª—è',
                    5: '–º–∞—è', 6: '–∏—é–Ω—è', 7: '–∏—é–ª—è', 8: '–∞–≤–≥—É—Å—Ç–∞',
                    9: '—Å–µ–Ω—Ç—è–±—Ä—è', 10: '–æ–∫—Ç—è–±—Ä—è', 11: '–Ω–æ—è–±—Ä—è', 12: '–¥–µ–∫–∞–±—Ä—è'
                }
                month_name = months_ru.get(now.month, '–º–µ—Å—è—Ü–∞')
                russian_date = f"{now.day} {month_name} {now.year} –≥–æ–¥–∞"
            
            # –ü–æ–ª—É—á–∞–µ–º —Ä—É—Å—Å–∫–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ —Å—Ç–∏–ª—è
            style_russian = self.get_style_russian_name(style)
            
            # –°–æ–∑–¥–∞–µ–º –±–ª–æ–∫ —Å –º–æ–¥–µ–ª—è–º–∏
            models_block = f"**–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞** –∏–∑ —Å–∫–∞–Ω–æ–≤ –∫–Ω–∏–≥–∏, **–ü–µ—Ä–µ—Å–∫–∞–∑** –∏ **–æ–ø–∏—Å–∞–Ω–∏—è –∏–ª–ª—é—Å—Ç—Ä–∞—Ü–∏–π** —Å–æ–∑–¥–∞–Ω—ã –º–æ–¥–µ–ª—å—é: {self.summary_model}\n–ò–ª–ª—é—Å—Ç—Ä–∞—Ü–∏–∏ —Å–æ–∑–¥–∞–Ω—ã –º–æ–¥–µ–ª—å—é: {self.image_model}"
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–∞
            document_title = self.book_title if self.book_title else "–ü–µ—Ä–µ—Å–∫–∞–∑ –æ—Å–Ω–æ–≤–Ω—ã—Ö –∏–¥–µ–π"
            
            # –°–æ–∑–¥–∞–µ–º –∏—Ç–æ–≥–æ–≤—ã–π –¥–æ–∫—É–º–µ–Ω—Ç
            final_content = f"""# {document_title}

**–¢–µ–º–∞:** {context_info['topic']}  
**–°—Ç–∏–ª—å –∏–∑–ª–æ–∂–µ–Ω–∏—è:** {style_russian}  
**–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤:** {len(chunks)}  
**–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è:** {russian_date}

{models_block}

---

{chr(10).join(summaries)}

---

*–ü–µ—Ä–µ—Å–∫–∞–∑ —Å–æ–∑–¥–∞–Ω –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏ –ò–ò.*
*–ü–æ–¥–ø–∏—à–∏—Ç–µ—Å—å —á—Ç–æ–±—ã –Ω–µ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å –Ω–æ–≤—ã–µ –≤—ã–ø—É—Å–∫–∏.*
"""
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(final_content)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤—Ä–µ–º–µ–Ω–∏
            self.stats['processing_time'] = time.time() - start_time
            
            # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            self.print_statistics()
            
            return True
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞: {e}")
            return False
    
    def print_statistics(self):
        """–í—ã–≤–æ–¥–∏—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        print("\n" + "="*50)
        print("üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –û–ë–†–ê–ë–û–¢–ö–ò")
        print("="*50)
        print(f"–í—Å–µ–≥–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤: {self.stats['total_chunks']}")
        print(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —É—Å–ø–µ—à–Ω–æ: {self.stats['processed_chunks']}")
        print(f"–û—à–∏–±–æ–∫: {self.stats['failed_chunks']}")
        print(f"–°–æ–∑–¥–∞–Ω–æ –ø–µ—Ä–µ—Å–∫–∞–∑–æ–≤: {self.stats['summaries_created']}")
        print(f"API –≤—ã–∑–æ–≤–æ–≤ (–≤—Å–µ–≥–æ): {self.stats['api_calls']}")
        print(f"  - –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–µ–º—ã: {self.stats['topic_detection_calls']}")
        print(f"  - –°–æ–∑–¥–∞–Ω–∏–µ –ø–µ—Ä–µ—Å–∫–∞–∑–æ–≤: {self.stats['api_calls'] - self.stats['topic_detection_calls']}")
        print(f"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤: {self.stats['total_tokens_used']:,}")
        print(f"–í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {self.stats['processing_time']:.1f} —Å–µ–∫")
        print(f"–†–∞–∑–º–µ—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞: {self.stats['total_characters']:,} —Å–∏–º–≤–æ–ª–æ–≤")
        
        if self.stats['total_chunks'] > 0:
            success_rate = (self.stats['processed_chunks'] / self.stats['total_chunks']) * 100
            print(f"–ü—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—à–Ω–æ–≥–æ —Å–æ–∑–¥–∞–Ω–∏—è: {success_rate:.1f}%")


def main():
    parser = argparse.ArgumentParser(
        description="–ü—Ä–æ—Ü–µ—Å—Å–æ—Ä –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ø–µ—Ä–µ—Å–∫–∞–∑–∞ –æ—Å–Ω–æ–≤–Ω—ã—Ö –∏–¥–µ–π –∏–∑ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ —Ç–µ–∫—Å—Ç–∞",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
  python summary_processor.py input.txt -o summary.txt
  python summary_processor.py input.txt -o summary.txt --style simple
  python summary_processor.py input.txt -o summary.txt --style detailed --chunk-size 8000
  python summary_processor.py input.txt -o summary.txt --config config.env
        """
    )
    
    parser.add_argument('input_file', help='–í—Ö–æ–¥–Ω–æ–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª')
    parser.add_argument('-o', '--output', required=True, help='–í—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª')
    parser.add_argument('--config', help='–§–∞–π–ª –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ .env')
    parser.add_argument('--title', help='–ù–∞–∑–≤–∞–Ω–∏–µ –¥–ª—è –∑–∞–≥–æ–ª–æ–≤–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: "–ü–µ—Ä–µ—Å–∫–∞–∑ –æ—Å–Ω–æ–≤–Ω—ã—Ö –∏–¥–µ–π")')
    parser.add_argument('--style', choices=['educational', 'simple', 'detailed'], 
                       default='educational', help='–°—Ç–∏–ª—å –∏–∑–ª–æ–∂–µ–Ω–∏—è')
    parser.add_argument('--chunk-size', type=int, help='–†–∞–∑–º–µ—Ä —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞ –≤ —Å–∏–º–≤–æ–ª–∞—Ö')
    parser.add_argument('--model', choices=['default', 'budget', 'quality'], 
                       default='default', help='–ú–æ–¥–µ–ª—å –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è')
    
    args = parser.parse_args()
    
    try:
        # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä
        processor = SummaryProcessor(args.config, book_title=args.title)
        
        # –í—ã–±–∏—Ä–∞–µ–º –º–æ–¥–µ–ª—å –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω–∞
        if args.model == 'budget':
            processor.model = processor.budget_model
        elif args.model == 'quality':
            processor.model = processor.quality_model
        
        print(f"ü§ñ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –º–æ–¥–µ–ª—å: {processor.model}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª
        if not Path(args.input_file).exists():
            print(f"‚ùå –û—à–∏–±–∫–∞: –§–∞–π–ª {args.input_file} –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return 1
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª
        success = processor.process_text_file(
            args.input_file, 
            args.output,
            args.style,
            args.chunk_size
        )
        
        if success:
            print(f"\n‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
            print(f"üìÑ –ü–µ—Ä–µ—Å–∫–∞–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {args.output}")
        else:
            print("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ")
            return 1
        
        return 0
        
    except ValueError as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {e}")
        print("–°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª .env –∏–ª–∏ config.env —Å –≤–∞—à–∏–º API –∫–ª—é—á–æ–º")
        return 1
    except Exception as e:
        print(f"‚ùå –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")
        return 1


if __name__ == "__main__":
    exit(main()) 