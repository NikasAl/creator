#!/usr/bin/env python3
"""
–ü—Ä–æ—Ü–µ—Å—Å–æ—Ä –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø–æ —Ç–µ–∫—Å—Ç—É –æ–±—Å—É–∂–¥–µ–Ω–∏—è.
"""

import os
import sys
import argparse
import time
import requests
import subprocess
from pathlib import Path
from dotenv import load_dotenv

class QuestionsProcessor:
    def __init__(self, config_file: str = None):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞ —Å –∑–∞–≥—Ä—É–∑–∫–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
        self.load_config(config_file)
        if not self.api_key:
            raise ValueError("API –∫–ª—é—á OpenRouter –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")

        self.base_url = "https://openrouter.ai/api/v1"
        self.headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
            "HTTP-Referer": "https://github.com/your-repo/video-discussion",
            "X-Title": "Questions Processor"
        }

    def load_config(self, config_file: str = None):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∏–∑ .env —Ñ–∞–π–ª–∞"""
        if config_file and Path(config_file).exists():
            load_dotenv(config_file)
        else:
            for env_file in [".env", "config.env", "settings.env"]:
                if Path(env_file).exists():
                    load_dotenv(env_file)
                    break

        self.api_key = os.getenv("OPENROUTER_API_KEY")
        self.model = os.getenv("DEFAULT_MODEL", "anthropic/claude-3.5-sonnet")
        self.temperature = float(os.getenv("DEFAULT_TEMPERATURE", "0.5"))
        self.max_tokens = int(os.getenv("DEFAULT_MAX_TOKENS", "2000"))
        self.budget_model = os.getenv("BUDGET_MODEL", "meta-llama/llama-3.1-8b-instruct")
        self.quality_model = os.getenv("QUALITY_MODEL", "openai/gpt-4o")

    def create_prompt(self, discussion_text: str, questions_text: str) -> str:
        """–°–æ–∑–¥–∞–µ—Ç –ø—Ä–æ–º–ø—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–æ–≤"""
        return f"""
–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –∏ –≤–Ω–∏–º–∞—Ç–µ–ª—å–Ω—ã–π —Å–æ–±–µ—Å–µ–¥–Ω–∏–∫. –¢–µ–±–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω —Ç–µ–∫—Å—Ç –æ–±—Å—É–∂–¥–µ–Ω–∏—è –∏ —Å–ø–∏—Å–æ–∫ –≤–æ–ø—Ä–æ—Å–æ–≤, –≤–æ–∑–Ω–∏–∫—à–∏—Ö —É —á–∏—Ç–∞—Ç–µ–ª—è.

–¢–í–û–Ø –ó–ê–î–ê–ß–ê:
–î–∞—Ç—å —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç—ã–µ, –ø–æ–Ω—è—Ç–Ω—ã–µ –∏ —Ç–æ—á–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –æ—Å–Ω–æ–≤—ã–≤–∞—è—Å—å –Ω–∞ —Å–≤–æ–∏—Ö –∑–Ω–∞–Ω–∏—è—Ö –∫–∞–∫ —ç–∫—Å–ø–µ—Ä—Ç–∞ –≤ –æ–±—Å—É–∂–¥–∞–µ–º–æ–π –æ–±–ª–∞—Å—Ç–∏.

–§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê:
- –ò—Å–ø–æ–ª—å–∑—É–π Markdown.
- –î–ª—è –∫–∞–∂–¥–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞ –∏—Å–ø–æ–ª—å–∑—É–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ —É—Ä–æ–≤–Ω—è 3 (### –í–æ–ø—Ä–æ—Å).
- –°—Ä–∞–∑—É –ø–æ–¥ –∑–∞–≥–æ–ª–æ–≤–∫–æ–º –ø–∏—à–∏ –æ—Ç–≤–µ—Ç.

–¢–ï–ö–°–¢ –û–ë–°–£–ñ–î–ï–ù–ò–Ø:
{discussion_text}

–í–û–ü–†–û–°–´ –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø:
{questions_text}

–û–¢–í–ï–¢–´:
""".strip()

    def generate_answers(self, prompt: str, model_choice: str = "default") -> str:
        """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∑–∞–ø—Ä–æ—Å –∫ LLM"""
        model = self.model
        if model_choice == "budget":
            model = self.budget_model
        elif model_choice == "quality":
            model = self.quality_model

        print(f"üîç –ò—Å–ø–æ–ª—å–∑—É–µ–º–∞—è –º–æ–¥–µ–ª—å: {model}")

        payload = {
            "model": model,
            "messages": [
                {"role": "user", "content": prompt}
            ],
            "temperature": self.temperature,
            "max_tokens": self.max_tokens
        }

        for attempt in range(3):
            try:
                resp = requests.post(
                    f"{self.base_url}/chat/completions",
                    headers=self.headers,
                    json=payload,
                    timeout=120
                )
                if resp.status_code == 200:
                    data = resp.json()
                    content = data["choices"][0]["message"]["content"].strip()
                    return content
                else:
                    print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ API {resp.status_code}: {resp.text}")
                    if resp.status_code == 429:
                        time.sleep(2 ** (attempt + 1))
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è: {e}")
                if attempt < 2:
                    time.sleep(2 ** attempt)
        
        raise RuntimeError("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç LLM –ø–æ—Å–ª–µ 3 –ø–æ–ø—ã—Ç–æ–∫")

    def process(self, discussion_path: str, questions_path: str, output_path: str, model_choice: str):
        d_path = Path(discussion_path)
        q_path = Path(questions_path)
        o_path = Path(output_path)

        if not d_path.exists():
            raise FileNotFoundError(f"–§–∞–π–ª –æ–±—Å—É–∂–¥–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω: {d_path}")
        if not q_path.exists():
            raise FileNotFoundError(f"–§–∞–π–ª –≤–æ–ø—Ä–æ—Å–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω: {q_path}")

        discussion_text = d_path.read_text(encoding="utf-8")
        questions_text = q_path.read_text(encoding="utf-8").strip()

        if not questions_text:
            print("‚ö†Ô∏è –§–∞–π–ª –≤–æ–ø—Ä–æ—Å–æ–≤ –ø—É—Å—Ç. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–æ–ø—É—â–µ–Ω–∞.")
            return

        print(f"‚è≥ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã...")
        prompt = self.create_prompt(discussion_text, questions_text)

        # === –†–ï–ñ–ò–ú CUSTOM (–†–£–ß–ù–û–ô) ===
        if model_choice == "custom":
            print("\n" + "="*60)
            print("ü§ñ –†–ï–ñ–ò–ú CUSTOM MODEL: –ì–ï–ù–ï–†–ê–¶–ò–Ø –û–¢–í–ï–¢–û–í –ù–ê –í–û–ü–†–û–°–´")
            print("="*60)
            print("1. –°–∫–æ–ø–∏—Ä—É–π—Ç–µ –ø—Ä–æ–º–ø—Ç –Ω–∏–∂–µ –∏ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –µ–≥–æ –≤ —á–∞—Ç (ChatGPT/Claude).")
            print("-" * 60)
            print(prompt)
            print("-" * 60)

            # –°–æ–∑–¥–∞–µ–º –ø—É—Å—Ç–æ–π —Ñ–∞–π–ª, –µ—Å–ª–∏ –Ω–µ—Ç
            if not o_path.exists():
                o_path.write_text("", encoding="utf-8")

            print(f"2. –û—Ç–∫—Ä—ã–≤–∞–µ—Ç—Å—è Sublime Text: {output_path}")
            print("3. –í—Å—Ç–∞–≤—å—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤ —Ñ–∞–π–ª, —Å–æ—Ö—Ä–∞–Ω–∏—Ç–µ –∏ –∑–∞–∫—Ä–æ–π—Ç–µ –≤–∫–ª–∞–¥–∫—É —Ä–µ–¥–∞–∫—Ç–æ—Ä–∞.")

            try:
                subprocess.run(["subl", "-w", output_path], check=True)
                print(f"‚úÖ –§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω (Custom): {output_path}")
            except FileNotFoundError:
                print("‚ùå Sublime Text (subl) –Ω–µ –Ω–∞–π–¥–µ–Ω. –û—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä—É–π—Ç–µ —Ñ–∞–π–ª –≤—Ä—É—á–Ω—É—é.")
                input("–ù–∞–∂–º–∏—Ç–µ Enter, –∫–æ–≥–¥–∞ —Å–æ—Ö—Ä–∞–Ω–∏—Ç–µ —Ñ–∞–π–ª...")
            return

        answers = self.generate_answers(prompt, model_choice)

        o_path.write_text(answers, encoding="utf-8")
        print(f"‚úÖ –û—Ç–≤–µ—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {o_path}")

def main():
    parser = argparse.ArgumentParser(description="–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø–æ –æ–±—Å—É–∂–¥–µ–Ω–∏—é")
    parser.add_argument("--discussion", required=True, help="–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –æ–±—Å—É–∂–¥–µ–Ω–∏—è (discussion.txt)")
    parser.add_argument("--questions", required=True, help="–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å –≤–æ–ø—Ä–æ—Å–∞–º–∏ (questions.txt)")
    parser.add_argument("--output", required=True, help="–ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –æ—Ç–≤–µ—Ç–æ–≤ (answers.txt)")
    parser.add_argument("--config", help="–ü—É—Ç—å –∫ –∫–æ–Ω—Ñ–∏–≥—É .env")
    parser.add_argument("--model", default="default", choices=["default", "budget", "quality", "custom"], help="–í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏")

    args = parser.parse_args()

    try:
        processor = QuestionsProcessor(args.config)
        processor.process(args.discussion, args.questions, args.output, args.model)
        return 0
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        return 1

if __name__ == "__main__":
    sys.exit(main())
