#!/usr/bin/env python3
"""
Ğ‘ĞµÑĞ¿Ğ»Ğ°Ñ‚Ğ½Ñ‹Ğ¹ Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ°Ğ¹Ğ±ĞµÑ€ Ñ Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶ĞºĞ¾Ğ¹ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ±ĞµÑĞ¿Ğ»Ğ°Ñ‚Ğ½Ñ‹Ñ… ÑĞµÑ€Ğ²Ğ¸ÑĞ¾Ğ²
"""

import os
import json
import time
import argparse
import requests
import subprocess
from pathlib import Path
from typing import List, Dict, Optional, Tuple
import re
from datetime import datetime


class FreeTranscriber:
    def __init__(self, config_file: str = None):
        """
        Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ±ĞµÑĞ¿Ğ»Ğ°Ñ‚Ğ½Ğ¾Ğ³Ğ¾ Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ°Ğ¹Ğ±ĞµÑ€Ğ°
        
        Args:
            config_file: ĞŸÑƒÑ‚ÑŒ Ğº Ñ„Ğ°Ğ¹Ğ»Ñƒ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¸ .env
        """
        self.config_file = config_file
        self.load_config()
        
        # Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸
        self.stats = {
            'audio_duration': 0,
            'transcription_time': 0,
            'segments_count': 0,
            'total_words': 0,
            'accuracy_estimate': 0
        }
    
    def load_config(self):
        """Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµÑ‚ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ Ğ¸Ğ· .env Ñ„Ğ°Ğ¹Ğ»Ğ°"""
        try:
            from dotenv import load_dotenv
            if self.config_file:
                load_dotenv(self.config_file)
            else:
                load_dotenv()
            
            # OpenRouter API (Ğ±ĞµÑĞ¿Ğ»Ğ°Ñ‚Ğ½Ñ‹Ğ¹ Ğ»Ğ¸Ğ¼Ğ¸Ñ‚)
            self.openrouter_api_key = os.getenv('OPENROUTER_API_KEY')
            self.openrouter_base_url = os.getenv('OPENROUTER_BASE_URL', 'https://openrouter.ai/api/v1')
            
            # Hugging Face API (Ğ±ĞµÑĞ¿Ğ»Ğ°Ñ‚Ğ½Ñ‹Ğ¹)
            self.huggingface_token = os.getenv('HUGGINGFACE_TOKEN')
            
            # Ğ›Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
            self.use_local_whisper = os.getenv('USE_LOCAL_WHISPER', 'false').lower() == 'true'
            
        except ImportError:
            print("âš ï¸  python-dotenv Ğ½Ğµ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ")
    
    def transcribe_with_openrouter_free(self, audio_file: str) -> Optional[Dict]:
        """
        Ğ¢Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ñ Ñ‡ĞµÑ€ĞµĞ· OpenRouter (Ğ±ĞµÑĞ¿Ğ»Ğ°Ñ‚Ğ½Ñ‹Ğ¹ Ğ»Ğ¸Ğ¼Ğ¸Ñ‚)
        
        Args:
            audio_file: ĞŸÑƒÑ‚ÑŒ Ğº Ğ°ÑƒĞ´Ğ¸Ğ¾ Ñ„Ğ°Ğ¹Ğ»Ñƒ
            
        Returns:
            Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ğ¸ Ğ¸Ğ»Ğ¸ None
        """
        if not self.openrouter_api_key:
            print("âŒ OPENROUTER_API_KEY Ğ½Ğµ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½")
            return None
        
        try:
            # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€ Ñ„Ğ°Ğ¹Ğ»Ğ° (Ğ±ĞµÑĞ¿Ğ»Ğ°Ñ‚Ğ½Ñ‹Ğ¹ Ğ»Ğ¸Ğ¼Ğ¸Ñ‚ Ğ¾Ğ±Ñ‹Ñ‡Ğ½Ğ¾ 25MB)
            file_size = Path(audio_file).stat().st_size
            if file_size > 25 * 1024 * 1024:  # 25MB
                print("âš ï¸  Ğ¤Ğ°Ğ¹Ğ» ÑĞ»Ğ¸ÑˆĞºĞ¾Ğ¼ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¾Ğ¹ Ğ´Ğ»Ñ Ğ±ĞµÑĞ¿Ğ»Ğ°Ñ‚Ğ½Ğ¾Ğ³Ğ¾ Ğ»Ğ¸Ğ¼Ğ¸Ñ‚Ğ° OpenRouter")
                return None
            
            # Ğ§Ğ¸Ñ‚Ğ°ĞµĞ¼ Ğ°ÑƒĞ´Ğ¸Ğ¾ Ñ„Ğ°Ğ¹Ğ»
            with open(audio_file, 'rb') as f:
                audio_data = f.read()
            
            headers = {
                "Authorization": f"Bearer {self.openrouter_api_key}",
                "Content-Type": "multipart/form-data"
            }
            
            # Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Whisper Ñ‡ĞµÑ€ĞµĞ· OpenRouter
            files = {
                'file': (Path(audio_file).name, audio_data, 'audio/mpeg')
            }
            
            data = {
                'model': 'openai/whisper-1',
                'response_format': 'verbose_json',
                'timestamp_granularities': ['word', 'segment']
            }
            
            print("ğŸµ ĞÑ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ°ÑƒĞ´Ğ¸Ğ¾ Ğ½Ğ° Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ñ (OpenRouter Ğ±ĞµÑĞ¿Ğ»Ğ°Ñ‚Ğ½Ñ‹Ğ¹)...")
            
            response = requests.post(
                f"{self.openrouter_base_url}/audio/transcriptions",
                headers=headers,
                files=files,
                data=data,
                timeout=300
            )
            
            if response.status_code == 200:
                result = response.json()
                print("âœ… Ğ¢Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ñ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ° ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾")
                return result
            elif response.status_code == 402:
                print("âŒ ĞŸÑ€ĞµĞ²Ñ‹ÑˆĞµĞ½ Ğ±ĞµÑĞ¿Ğ»Ğ°Ñ‚Ğ½Ñ‹Ğ¹ Ğ»Ğ¸Ğ¼Ğ¸Ñ‚ OpenRouter")
                return None
            else:
                print(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ğ¸: {response.status_code}")
                return None
                
        except Exception as e:
            print(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ğ¸: {e}")
            return None
    
    def transcribe_with_huggingface(self, audio_file: str) -> Optional[Dict]:
        """
        Ğ¢Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ñ Ñ‡ĞµÑ€ĞµĞ· Hugging Face (Ğ±ĞµÑĞ¿Ğ»Ğ°Ñ‚Ğ½Ñ‹Ğ¹)
        
        Args:
            audio_file: ĞŸÑƒÑ‚ÑŒ Ğº Ğ°ÑƒĞ´Ğ¸Ğ¾ Ñ„Ğ°Ğ¹Ğ»Ñƒ
            
        Returns:
            Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ğ¸ Ğ¸Ğ»Ğ¸ None
        """
        try:
            # Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Ğ±ĞµÑĞ¿Ğ»Ğ°Ñ‚Ğ½ÑƒÑ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Whisper Ñ‡ĞµÑ€ĞµĞ· Hugging Face
            model_name = "openai/whisper-base"  # ĞœĞµĞ½ÑŒÑˆĞ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ´Ğ»Ñ ÑĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸Ğ¸ Ñ€ĞµÑÑƒÑ€ÑĞ¾Ğ²
            
            print("ğŸµ ĞÑ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ°ÑƒĞ´Ğ¸Ğ¾ Ğ½Ğ° Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ñ (Hugging Face)...")
            
            # Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ API Hugging Face
            api_url = f"https://api-inference.huggingface.co/models/{model_name}"
            
            headers = {}
            if self.huggingface_token:
                headers["Authorization"] = f"Bearer {self.huggingface_token}"
            
            with open(audio_file, 'rb') as f:
                audio_data = f.read()
            
            response = requests.post(
                api_url,
                headers=headers,
                data=audio_data,
                timeout=300
            )
            
            if response.status_code == 200:
                result = response.json()
                print("âœ… Ğ¢Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ñ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ° ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾")
                
                # ĞŸÑ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·ÑƒĞµĞ¼ Ğ² Ğ½ÑƒĞ¶Ğ½Ñ‹Ğ¹ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚
                return self.convert_huggingface_result(result)
            else:
                print(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ğ¸: {response.status_code}")
                return None
                
        except Exception as e:
            print(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ğ¸: {e}")
            return None
    
    def convert_huggingface_result(self, result: Dict) -> Dict:
        """ĞŸÑ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·ÑƒĞµÑ‚ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Hugging Face Ğ² Ğ½ÑƒĞ¶Ğ½Ñ‹Ğ¹ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚"""
        if isinstance(result, list) and len(result) > 0:
            result = result[0]
        
        # Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾Ğ¹ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚ Ñ ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ°Ğ¼Ğ¸
        text = result.get('text', '')
        
        # Ğ Ğ°Ğ·Ğ±Ğ¸Ğ²Ğ°ĞµĞ¼ Ğ½Ğ° ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ 10 ÑĞµĞºÑƒĞ½Ğ´
        words = text.split()
        segments = []
        words_per_segment = max(1, len(words) // 10)  # ĞŸÑ€Ğ¸Ğ¼ĞµÑ€Ğ½Ğ¾ 10 ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ²
        
        for i in range(0, len(words), words_per_segment):
            segment_words = words[i:i + words_per_segment]
            segment_text = ' '.join(segment_words)
            
            segments.append({
                'start': i * 0.5,  # ĞŸÑ€Ğ¸Ğ¼ĞµÑ€Ğ½Ğ¾Ğµ Ğ²Ñ€ĞµĞ¼Ñ
                'end': (i + len(segment_words)) * 0.5,
                'text': segment_text,
                'words': [{'word': word, 'start': j * 0.5, 'end': (j + 1) * 0.5} 
                         for j, word in enumerate(segment_words)]
            })
        
        return {
            'text': text,
            'segments': segments,
            'language': 'ru'
        }
    
    def transcribe_with_local_whisper(self, audio_file: str) -> Optional[Dict]:
        """
        Ğ›Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ°Ñ Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ñ Ñ Whisper (Ğ±ĞµÑĞ¿Ğ»Ğ°Ñ‚Ğ½Ğ¾)
        
        Args:
            audio_file: ĞŸÑƒÑ‚ÑŒ Ğº Ğ°ÑƒĞ´Ğ¸Ğ¾ Ñ„Ğ°Ğ¹Ğ»Ñƒ
            
        Returns:
            Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ğ¸ Ğ¸Ğ»Ğ¸ None
        """
        try:
            print("ğŸµ Ğ—Ğ°Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½ÑƒÑ Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ñ Ñ Whisper...")
            
            # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼, ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½ Ğ»Ğ¸ Whisper
            try:
                import whisper
            except ImportError:
                print("âŒ Whisper Ğ½Ğµ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½. Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚Ğµ: pip install openai-whisper")
                return None
            
            # Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµĞ¼ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ
            model = whisper.load_model("base")  # Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ base Ğ´Ğ»Ñ ÑĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸Ğ¸ Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸
            
            # Ğ¢Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ¸Ñ€ÑƒĞµĞ¼
            result = model.transcribe(
                audio_file,
                language="ru",
                verbose=True,
                word_timestamps=True
            )
            
            print("âœ… Ğ›Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ°Ñ Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ñ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ° ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾")
            return result
            
        except Exception as e:
            print(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ¾Ğ¹ Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ğ¸: {e}")
            return None
    
    def transcribe_with_web_services(self, audio_file: str) -> Optional[Dict]:
        """
        Ğ¢Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ñ Ñ‡ĞµÑ€ĞµĞ· Ğ±ĞµÑĞ¿Ğ»Ğ°Ñ‚Ğ½Ñ‹Ğµ Ğ²ĞµĞ±-ÑĞµÑ€Ğ²Ğ¸ÑÑ‹
        
        Args:
            audio_file: ĞŸÑƒÑ‚ÑŒ Ğº Ğ°ÑƒĞ´Ğ¸Ğ¾ Ñ„Ğ°Ğ¹Ğ»Ñƒ
            
        Returns:
            Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ğ¸ Ğ¸Ğ»Ğ¸ None
        """
        print("ğŸŒ ĞŸÑ€Ğ¾Ğ±ÑƒĞµĞ¼ Ğ±ĞµÑĞ¿Ğ»Ğ°Ñ‚Ğ½Ñ‹Ğµ Ğ²ĞµĞ±-ÑĞµÑ€Ğ²Ğ¸ÑÑ‹...")
        
        # Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº Ğ±ĞµÑĞ¿Ğ»Ğ°Ñ‚Ğ½Ñ‹Ñ… ÑĞµÑ€Ğ²Ğ¸ÑĞ¾Ğ² Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ¿Ñ‹Ñ‚ĞºĞ¸
        services = [
            ("https://api.voicenotebook.com/transcribe", "VoiceNotebook"),
            ("https://api.speechmatics.com/v1/jobs", "Speechmatics"),
        ]
        
        for url, service_name in services:
            try:
                print(f"ğŸ”„ ĞŸÑ€Ğ¾Ğ±ÑƒĞµĞ¼ {service_name}...")
                
                with open(audio_file, 'rb') as f:
                    audio_data = f.read()
                
                response = requests.post(
                    url,
                    files={'audio': audio_data},
                    timeout=60
                )
                
                if response.status_code == 200:
                    result = response.json()
                    print(f"âœ… {service_name} Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ñ ÑƒÑĞ¿ĞµÑˆĞ½Ğ°")
                    return result
                else:
                    print(f"âŒ {service_name} Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½")
                    
            except Exception as e:
                print(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° {service_name}: {e}")
                continue
        
        return None
    
    def create_simple_segments(self, text: str, estimated_duration: float = 60.0) -> List[Dict]:
        """
        Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµÑ‚ Ğ¿Ñ€Ğ¾ÑÑ‚Ñ‹Ğµ ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ñ‚ĞµĞºÑÑ‚Ğ°
        
        Args:
            text: Ğ¢Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ñ‚ĞµĞºÑÑ‚
            estimated_duration: ĞŸÑ€Ğ¸Ğ¼ĞµÑ€Ğ½Ğ°Ñ Ğ´Ğ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ°ÑƒĞ´Ğ¸Ğ¾ Ğ² ÑĞµĞºÑƒĞ½Ğ´Ğ°Ñ…
            
        Returns:
            Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ²
        """
        # Ğ Ğ°Ğ·Ğ±Ğ¸Ğ²Ğ°ĞµĞ¼ Ñ‚ĞµĞºÑÑ‚ Ğ½Ğ° Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ
        sentences = re.split(r'[.!?]+', text)
        sentences = [s.strip() for s in sentences if s.strip()]
        
        if not sentences:
            return []
        
        # ĞÑ†ĞµĞ½Ğ¸Ğ²Ğ°ĞµĞ¼ Ğ²Ñ€ĞµĞ¼Ñ Ğ½Ğ° Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ
        time_per_sentence = estimated_duration / len(sentences)
        
        segments = []
        current_time = 0
        
        for i, sentence in enumerate(sentences):
            segment_duration = time_per_sentence * (len(sentence.split()) / 10)  # ĞŸÑ€Ğ¸Ğ¼ĞµÑ€Ğ½Ğ¾ 10 ÑĞ»Ğ¾Ğ² Ğ² ÑĞµĞºÑƒĞ½Ğ´Ñƒ
            
            segments.append({
                'start': current_time,
                'end': current_time + segment_duration,
                'text': sentence,
                'words': [{'word': word, 'start': current_time + j * 0.1, 'end': current_time + (j + 1) * 0.1} 
                         for j, word in enumerate(sentence.split())]
            })
            
            current_time += segment_duration
        
        return segments
    
    def align_text_with_audio(self, text_file: str, audio_file: str, 
                             output_file: str = None, method: str = "auto") -> bool:
        """
        Ğ¡Ğ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ Ñ‚ĞµĞºÑÑ‚ Ñ Ğ°ÑƒĞ´Ğ¸Ğ¾ Ñ‡ĞµÑ€ĞµĞ· Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ñ
        
        Args:
            text_file: Ğ¤Ğ°Ğ¹Ğ» Ñ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ¼
            audio_file: ĞÑƒĞ´Ğ¸Ğ¾ Ñ„Ğ°Ğ¹Ğ»
            output_file: Ğ’Ñ‹Ñ…Ğ¾Ğ´Ğ½Ğ¾Ğ¹ Ñ„Ğ°Ğ¹Ğ» Ñ Ñ‚Ğ°Ğ¹Ğ¼ÑÑ‚Ğ°Ğ¼Ğ¿Ğ°Ğ¼Ğ¸
            method: ĞœĞµÑ‚Ğ¾Ğ´ Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ğ¸ (auto/openrouter/huggingface/local/web)
            
        Returns:
            True ĞµÑĞ»Ğ¸ ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ ÑƒÑĞ¿ĞµÑˆĞ½Ğ°
        """
        start_time = time.time()
        
        try:
            # Ğ§Ğ¸Ñ‚Ğ°ĞµĞ¼ Ñ‚ĞµĞºÑÑ‚
            with open(text_file, 'r', encoding='utf-8') as f:
                text_content = f.read()
            
            print(f"ğŸ“– Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½ Ñ‚ĞµĞºÑÑ‚: {text_file}")
            print(f"ğŸµ ĞÑƒĞ´Ğ¸Ğ¾ Ñ„Ğ°Ğ¹Ğ»: {audio_file}")
            
            # ĞŸÑ€Ğ¾Ğ±ÑƒĞµĞ¼ Ñ€Ğ°Ğ·Ğ½Ñ‹Ğµ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹ Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ğ¸
            transcription = None
            
            if method == "auto" or method == "openrouter":
                # 1. ĞŸÑ€Ğ¾Ğ±ÑƒĞµĞ¼ OpenRouter (Ğ±ĞµÑĞ¿Ğ»Ğ°Ñ‚Ğ½Ñ‹Ğ¹ Ğ»Ğ¸Ğ¼Ğ¸Ñ‚)
                if self.openrouter_api_key:
                    print("ğŸ”„ ĞŸÑ€Ğ¾Ğ±ÑƒĞµĞ¼ Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ñ Ñ‡ĞµÑ€ĞµĞ· OpenRouter (Ğ±ĞµÑĞ¿Ğ»Ğ°Ñ‚Ğ½Ñ‹Ğ¹)...")
                    transcription = self.transcribe_with_openrouter_free(audio_file)
                    if transcription:
                        method = "openrouter"
            
            if not transcription and (method == "auto" or method == "huggingface"):
                # 2. ĞŸÑ€Ğ¾Ğ±ÑƒĞµĞ¼ Hugging Face
                print("ğŸ”„ ĞŸÑ€Ğ¾Ğ±ÑƒĞµĞ¼ Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ñ Ñ‡ĞµÑ€ĞµĞ· Hugging Face...")
                transcription = self.transcribe_with_huggingface(audio_file)
                if transcription:
                    method = "huggingface"
            
            if not transcription and (method == "auto" or method == "local"):
                # 3. ĞŸÑ€Ğ¾Ğ±ÑƒĞµĞ¼ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Whisper
                if self.use_local_whisper:
                    print("ğŸ”„ ĞŸÑ€Ğ¾Ğ±ÑƒĞµĞ¼ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½ÑƒÑ Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ñ...")
                    transcription = self.transcribe_with_local_whisper(audio_file)
                    if transcription:
                        method = "local"
            
            if not transcription and (method == "auto" or method == "web"):
                # 4. ĞŸÑ€Ğ¾Ğ±ÑƒĞµĞ¼ Ğ²ĞµĞ±-ÑĞµÑ€Ğ²Ğ¸ÑÑ‹
                transcription = self.transcribe_with_web_services(audio_file)
                if transcription:
                    method = "web"
            
            if not transcription:
                print("âŒ ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ÑŒ Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ñ Ğ½Ğ¸ Ğ¾Ğ´Ğ½Ğ¸Ğ¼ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ¼")
                print("ğŸ’¡ Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ Ğ¿Ñ€Ğ¾ÑÑ‚ÑƒÑ ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ñ‚ĞµĞºÑÑ‚Ğ°...")
                
                # Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ Ğ¿Ñ€Ğ¾ÑÑ‚ÑƒÑ ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ
                estimated_duration = 60.0  # ĞŸÑ€ĞµĞ´Ğ¿Ğ¾Ğ»Ğ°Ğ³Ğ°ĞµĞ¼ 1 Ğ¼Ğ¸Ğ½ÑƒÑ‚Ñƒ
                segments = self.create_simple_segments(text_content, estimated_duration)
                method = "simple"
            else:
                # Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¸Ğ· Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ğ¸
                segments = self.create_segments_from_transcription(transcription, method)
            
            if not segments:
                print("âŒ ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ ÑĞ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ñ‹")
                return False
            
            # Ğ Ğ°Ğ·Ğ±Ğ¸Ğ²Ğ°ĞµĞ¼ Ñ‚ĞµĞºÑÑ‚ Ğ½Ğ° Ñ„Ñ€Ğ°Ğ³Ğ¼ĞµĞ½Ñ‚Ñ‹
            text_fragments = self.split_text_into_fragments(text_content)
            
            # Ğ¡Ğ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµĞ¼ Ñ‚ĞµĞºÑÑ‚ Ñ ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ°Ğ¼Ğ¸
            aligned_content = self.sync_text_with_segments(text_fragments, segments)
            
            # ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼ Ğ²Ñ‹Ñ…Ğ¾Ğ´Ğ½Ğ¾Ğ¹ Ñ„Ğ°Ğ¹Ğ»
            if not output_file:
                output_file = f"{Path(text_file).stem}_aligned.json"
            
            # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚
            result = {
                'metadata': {
                    'text_file': text_file,
                    'audio_file': audio_file,
                    'transcription_method': method,
                    'aligned_at': datetime.now().isoformat(),
                    'total_segments': len(segments),
                    'total_fragments': len(text_fragments),
                    'free_service': True
                },
                'segments': segments,
                'aligned_content': aligned_content,
                'statistics': {
                    'audio_duration': segments[-1]['end'] if segments else 0,
                    'transcription_time': time.time() - start_time,
                    'segments_count': len(segments),
                    'total_words': sum(len(seg['text'].split()) for seg in segments)
                }
            }
            
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… Ğ¡Ğ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ°: {output_file}")
            print(f"ğŸ“Š Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ°:")
            print(f"   - ĞœĞµÑ‚Ğ¾Ğ´: {method}")
            print(f"   - Ğ¡ĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ²: {len(segments)}")
            print(f"   - Ğ¤Ñ€Ğ°Ğ³Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ñ‚ĞµĞºÑÑ‚Ğ°: {len(text_fragments)}")
            print(f"   - Ğ”Ğ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ°ÑƒĞ´Ğ¸Ğ¾: {result['statistics']['audio_duration']:.1f} ÑĞµĞº")
            print(f"   - Ğ’Ñ€ĞµĞ¼Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸: {result['statistics']['transcription_time']:.1f} ÑĞµĞº")
            
            return True
            
        except Exception as e:
            print(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸: {e}")
            return False
    
    def create_segments_from_transcription(self, transcription: Dict, method: str = "unknown") -> List[Dict]:
        """Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµÑ‚ ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¸Ğ· Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ° Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ğ¸"""
        segments = []
        
        if method == "openrouter" or method == "local":
            # OpenAI Whisper Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚
            if 'segments' in transcription:
                for segment in transcription['segments']:
                    segments.append({
                        'start': segment['start'],
                        'end': segment['end'],
                        'text': segment['text'].strip(),
                        'words': segment.get('words', [])
                    })
            elif 'text' in transcription:
                # Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ Ğ¿Ñ€Ğ¾ÑÑ‚Ñ‹Ğµ ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ñ‹
                segments = self.create_simple_segments(transcription['text'])
        
        elif method == "huggingface":
            # Hugging Face Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚
            if 'segments' in transcription:
                segments = transcription['segments']
            elif 'text' in transcription:
                segments = self.create_simple_segments(transcription['text'])
        
        return segments
    
    def split_text_into_fragments(self, text: str) -> List[str]:
        """Ğ Ğ°Ğ·Ğ±Ğ¸Ğ²Ğ°ĞµÑ‚ Ñ‚ĞµĞºÑÑ‚ Ğ½Ğ° Ñ„Ñ€Ğ°Ğ³Ğ¼ĞµĞ½Ñ‚Ñ‹"""
        # Ğ˜Ñ‰ĞµĞ¼ Ñ„Ñ€Ğ°Ğ³Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ñƒ "Ğ¤Ñ€Ğ°Ğ³Ğ¼ĞµĞ½Ñ‚ X"
        pattern = r'(?:##? )?Ğ¤Ñ€Ğ°Ğ³Ğ¼ĞµĞ½Ñ‚ \d+\s*\n(.*?)(?=\n(?:##? )?Ğ¤Ñ€Ğ°Ğ³Ğ¼ĞµĞ½Ñ‚|\Z)'
        matches = re.findall(pattern, text, re.DOTALL)
        
        if matches:
            return [match.strip() for match in matches]
        else:
            # Ğ•ÑĞ»Ğ¸ Ñ„Ñ€Ğ°Ğ³Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ñ‹, Ñ€Ğ°Ğ·Ğ±Ğ¸Ğ²Ğ°ĞµĞ¼ Ğ¿Ğ¾ Ğ°Ğ±Ğ·Ğ°Ñ†Ğ°Ğ¼
            paragraphs = text.split('\n\n')
            return [p.strip() for p in paragraphs if p.strip()]
    
    def sync_text_with_segments(self, text_fragments: List[str], 
                               segments: List[Dict]) -> List[Dict]:
        """Ğ¡Ğ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ Ñ„Ñ€Ğ°Ğ³Ğ¼ĞµĞ½Ñ‚Ñ‹ Ñ‚ĞµĞºÑÑ‚Ğ° Ñ Ğ°ÑƒĞ´Ğ¸Ğ¾ ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ°Ğ¼Ğ¸"""
        aligned_content = []
        
        # ĞŸÑ€Ğ¾ÑÑ‚Ğ°Ñ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ: Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼ Ñ„Ñ€Ğ°Ğ³Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸
        total_duration = segments[-1]['end'] if segments else 0
        fragment_duration = total_duration / len(text_fragments) if text_fragments else 0
        
        for i, fragment in enumerate(text_fragments):
            start_time = i * fragment_duration
            end_time = (i + 1) * fragment_duration
            
            # ĞĞ°Ñ…Ğ¾Ğ´Ğ¸Ğ¼ ÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğµ ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ñ‹
            matching_segments = [
                seg for seg in segments 
                if seg['start'] >= start_time and seg['end'] <= end_time
            ]
            
            aligned_content.append({
                'fragment_number': i + 1,
                'text': fragment,
                'start_time': start_time,
                'end_time': end_time,
                'duration': end_time - start_time,
                'matching_segments': matching_segments,
                'transcribed_text': ' '.join(seg['text'] for seg in matching_segments)
            })
        
        return aligned_content


def main():
    parser = argparse.ArgumentParser(
        description="Ğ‘ĞµÑĞ¿Ğ»Ğ°Ñ‚Ğ½Ñ‹Ğ¹ Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ°Ğ¹Ğ±ĞµÑ€ Ñ Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶ĞºĞ¾Ğ¹ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ±ĞµÑĞ¿Ğ»Ğ°Ñ‚Ğ½Ñ‹Ñ… ÑĞµÑ€Ğ²Ğ¸ÑĞ¾Ğ²",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ĞŸÑ€Ğ¸Ğ¼ĞµÑ€Ñ‹ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ:
  python free_transcriber.py text.txt audio.mp3
  python free_transcriber.py text.txt audio.mp3 --method huggingface
  python free_transcriber.py text.txt audio.mp3 --method local
  python free_transcriber.py text.txt audio.mp3 -o aligned.json
        """
    )
    
    parser.add_argument('text_file', help='Ğ¤Ğ°Ğ¹Ğ» Ñ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ¼')
    parser.add_argument('audio_file', help='ĞÑƒĞ´Ğ¸Ğ¾ Ñ„Ğ°Ğ¹Ğ»')
    parser.add_argument('-o', '--output', help='Ğ’Ñ‹Ñ…Ğ¾Ğ´Ğ½Ğ¾Ğ¹ Ñ„Ğ°Ğ¹Ğ» Ñ Ñ‚Ğ°Ğ¹Ğ¼ÑÑ‚Ğ°Ğ¼Ğ¿Ğ°Ğ¼Ğ¸')
    parser.add_argument('--method', choices=['auto', 'openrouter', 'huggingface', 'local', 'web'], 
                       default='auto', help='ĞœĞµÑ‚Ğ¾Ğ´ Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ğ¸')
    parser.add_argument('--config', help='Ğ¤Ğ°Ğ¹Ğ» ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¸ .env')
    
    args = parser.parse_args()
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ²Ñ…Ğ¾Ğ´Ğ½Ñ‹Ğµ Ñ„Ğ°Ğ¹Ğ»Ñ‹
    if not Path(args.text_file).exists():
        print(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ°: Ğ¤Ğ°Ğ¹Ğ» {args.text_file} Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½")
        return 1
    
    if not Path(args.audio_file).exists():
        print(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ°: Ğ¤Ğ°Ğ¹Ğ» {args.audio_file} Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½")
        return 1
    
    try:
        # Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ°Ğ¹Ğ±ĞµÑ€
        transcriber = FreeTranscriber(args.config)
        
        # Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½ÑĞµĞ¼ ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ
        success = transcriber.align_text_with_audio(
            args.text_file,
            args.audio_file,
            args.output,
            args.method
        )
        
        if success:
            print("âœ… Ğ¡Ğ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ° ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾!")
        else:
            print("âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸")
            return 1
        
        return 0
        
    except Exception as e:
        print(f"âŒ ĞĞµĞ¾Ğ¶Ğ¸Ğ´Ğ°Ğ½Ğ½Ğ°Ñ Ğ¾ÑˆĞ¸Ğ±ĞºĞ°: {e}")
        return 1


if __name__ == "__main__":
    exit(main()) 