#!/usr/bin/env python3
"""
Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ğ¸ Ğ°ÑƒĞ´Ğ¸Ğ¾ Ñ Ñ‚Ğ°Ğ¹Ğ¼ÑÑ‚Ğ°Ğ¼Ğ¿Ğ°Ğ¼Ğ¸ Ğ´Ğ»Ñ ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ñ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ¼
ĞŸĞ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ĞµÑ‚ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğµ ÑĞµÑ€Ğ²Ğ¸ÑÑ‹ Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ğ¸
"""

import os
import json
import time
import argparse
import requests
from pathlib import Path
from typing import List, Dict, Optional, Tuple
import re
from datetime import datetime, timedelta


class AudioTranscriber:
    def __init__(self, config_file: str = None):
        """
        Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ°Ğ¹Ğ±ĞµÑ€Ğ°
        
        Args:
            config_file: ĞŸÑƒÑ‚ÑŒ Ğº Ñ„Ğ°Ğ¹Ğ»Ñƒ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¸ .env
        """
        self.config_file = config_file
        self.load_config()
        
        # Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸
        self.stats = {
            'audio_duration': 0,
            'transcription_time': 0,
            'segments_count': 0,
            'total_words': 0,
            'accuracy_estimate': 0
        }
    
    def load_config(self):
        """Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµÑ‚ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ Ğ¸Ğ· .env Ñ„Ğ°Ğ¹Ğ»Ğ°"""
        try:
            from dotenv import load_dotenv
            if self.config_file:
                load_dotenv(self.config_file)
            else:
                load_dotenv()
            
            # OpenRouter API Ğ´Ğ»Ñ Whisper
            self.openrouter_api_key = os.getenv('OPENROUTER_API_KEY')
            self.openrouter_base_url = os.getenv('OPENROUTER_BASE_URL', 'https://openrouter.ai/api/v1')
            
            # ĞĞ»ÑŒÑ‚ĞµÑ€Ğ½Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ ÑĞµÑ€Ğ²Ğ¸ÑÑ‹
            self.whisper_api_key = os.getenv('WHISPER_API_KEY')
            self.assemblyai_key = os.getenv('ASSEMBLYAI_KEY')
            
            if not self.openrouter_api_key:
                print("âš ï¸  ĞŸÑ€ĞµĞ´ÑƒĞ¿Ñ€ĞµĞ¶Ğ´ĞµĞ½Ğ¸Ğµ: OPENROUTER_API_KEY Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½ Ğ² ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¸")
                
        except ImportError:
            print("âš ï¸  python-dotenv Ğ½Ğµ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ")
    
    def transcribe_with_openrouter(self, audio_file: str) -> Optional[Dict]:
        """
        Ğ¢Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ñ Ñ‡ĞµÑ€ĞµĞ· OpenRouter (Whisper)
        
        Args:
            audio_file: ĞŸÑƒÑ‚ÑŒ Ğº Ğ°ÑƒĞ´Ğ¸Ğ¾ Ñ„Ğ°Ğ¹Ğ»Ñƒ
            
        Returns:
            Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ğ¸ Ğ¸Ğ»Ğ¸ None
        """
        if not self.openrouter_api_key:
            print("âŒ OPENROUTER_API_KEY Ğ½Ğµ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½")
            return None
        
        try:
            # Ğ§Ğ¸Ñ‚Ğ°ĞµĞ¼ Ğ°ÑƒĞ´Ğ¸Ğ¾ Ñ„Ğ°Ğ¹Ğ»
            with open(audio_file, 'rb') as f:
                audio_data = f.read()
            
            headers = {
                "Authorization": f"Bearer {self.openrouter_api_key}",
                "Content-Type": "multipart/form-data"
            }
            
            # Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Whisper Ñ‡ĞµÑ€ĞµĞ· OpenRouter
            files = {
                'file': (Path(audio_file).name, audio_data, 'audio/mpeg')
            }
            
            data = {
                'model': 'openai/whisper-1',
                'response_format': 'verbose_json',
                'timestamp_granularities': ['word', 'segment']
            }
            
            print("ğŸµ ĞÑ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ°ÑƒĞ´Ğ¸Ğ¾ Ğ½Ğ° Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ñ...")
            
            response = requests.post(
                f"{self.openrouter_base_url}/audio/transcriptions",
                headers=headers,
                files=files,
                data=data,
                timeout=300
            )
            
            if response.status_code == 200:
                result = response.json()
                print("âœ… Ğ¢Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ñ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ° ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾")
                return result
            else:
                print(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ğ¸: {response.status_code}")
                print(f"ĞÑ‚Ğ²ĞµÑ‚: {response.text}")
                return None
                
        except Exception as e:
            print(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ğ¸: {e}")
            return None
    
    def transcribe_with_whisper_api(self, audio_file: str) -> Optional[Dict]:
        """
        Ğ¢Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ñ Ñ‡ĞµÑ€ĞµĞ· OpenAI Whisper API
        
        Args:
            audio_file: ĞŸÑƒÑ‚ÑŒ Ğº Ğ°ÑƒĞ´Ğ¸Ğ¾ Ñ„Ğ°Ğ¹Ğ»Ñƒ
            
        Returns:
            Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ğ¸ Ğ¸Ğ»Ğ¸ None
        """
        if not self.whisper_api_key:
            print("âŒ WHISPER_API_KEY Ğ½Ğµ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½")
            return None
        
        try:
            with open(audio_file, 'rb') as f:
                audio_data = f.read()
            
            headers = {
                "Authorization": f"Bearer {self.whisper_api_key}"
            }
            
            files = {
                'file': (Path(audio_file).name, audio_data, 'audio/mpeg')
            }
            
            data = {
                'model': 'whisper-1',
                'response_format': 'verbose_json',
                'timestamp_granularities': ['word', 'segment']
            }
            
            print("ğŸµ ĞÑ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ°ÑƒĞ´Ğ¸Ğ¾ Ğ½Ğ° Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ñ (Whisper API)...")
            
            response = requests.post(
                "https://api.openai.com/v1/audio/transcriptions",
                headers=headers,
                files=files,
                data=data,
                timeout=300
            )
            
            if response.status_code == 200:
                result = response.json()
                print("âœ… Ğ¢Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ñ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ° ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾")
                return result
            else:
                print(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ğ¸: {response.status_code}")
                return None
                
        except Exception as e:
            print(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ğ¸: {e}")
            return None
    
    def transcribe_with_assemblyai(self, audio_file: str) -> Optional[Dict]:
        """
        Ğ¢Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ñ Ñ‡ĞµÑ€ĞµĞ· AssemblyAI
        
        Args:
            audio_file: ĞŸÑƒÑ‚ÑŒ Ğº Ğ°ÑƒĞ´Ğ¸Ğ¾ Ñ„Ğ°Ğ¹Ğ»Ñƒ
            
        Returns:
            Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ğ¸ Ğ¸Ğ»Ğ¸ None
        """
        if not self.assemblyai_key:
            print("âŒ ASSEMBLYAI_KEY Ğ½Ğµ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½")
            return None
        
        try:
            # Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµĞ¼ Ñ„Ğ°Ğ¹Ğ»
            with open(audio_file, 'rb') as f:
                audio_data = f.read()
            
            headers = {
                "authorization": self.assemblyai_key,
                "content-type": "application/json"
            }
            
            # Ğ¡Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ° Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµĞ¼ Ñ„Ğ°Ğ¹Ğ»
            upload_url = "https://api.assemblyai.com/v2/upload"
            upload_response = requests.post(upload_url, headers=headers, data=audio_data)
            
            if upload_response.status_code != 200:
                print(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ Ñ„Ğ°Ğ¹Ğ»Ğ°: {upload_response.status_code}")
                return None
            
            upload_url = upload_response.json()["upload_url"]
            
            # Ğ—Ğ°Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ñ
            transcript_url = "https://api.assemblyai.com/v2/transcript"
            transcript_request = {
                "audio_url": upload_url,
                "word_boost": ["Ğ¿ÑĞ¸Ñ…Ğ¾Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·", "ÑˆĞ¸Ğ·Ğ¾Ğ¸Ğ´", "Ğ»Ğ¸Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ", "Ñ‚ĞµÑ€Ğ°Ğ¿Ğ¸Ñ"],
                "punctuate": True,
                "format_text": True
            }
            
            transcript_response = requests.post(transcript_url, json=transcript_request, headers=headers)
            
            if transcript_response.status_code != 200:
                print(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ·Ğ°Ğ¿ÑƒÑĞºĞ° Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ğ¸: {transcript_response.status_code}")
                return None
            
            transcript_id = transcript_response.json()["id"]
            polling_url = f"https://api.assemblyai.com/v2/transcript/{transcript_id}"
            
            # Ğ–Ğ´ĞµĞ¼ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¸Ñ
            print("â³ ĞĞ¶Ğ¸Ğ´Ğ°ĞµĞ¼ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¸Ñ Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ğ¸...")
            while True:
                polling_response = requests.get(polling_url, headers=headers)
                polling_response = polling_response.json()
                
                if polling_response["status"] == "completed":
                    print("âœ… Ğ¢Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ñ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ° ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾")
                    return polling_response
                elif polling_response["status"] == "error":
                    print("âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ğ¸")
                    return None
                
                time.sleep(3)
                
        except Exception as e:
            print(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ğ¸: {e}")
            return None
    
    def create_segments_from_transcription(self, transcription: Dict, method: str = "openrouter") -> List[Dict]:
        """
        Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµÑ‚ ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¸Ğ· Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ° Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ğ¸
        
        Args:
            transcription: Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ğ¸
            method: ĞœĞµÑ‚Ğ¾Ğ´ Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ğ¸
            
        Returns:
            Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ñ Ñ‚Ğ°Ğ¹Ğ¼ÑÑ‚Ğ°Ğ¼Ğ¿Ğ°Ğ¼Ğ¸
        """
        segments = []
        
        if method == "openrouter" or method == "whisper":
            # OpenAI Whisper Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚
            if 'segments' in transcription:
                for segment in transcription['segments']:
                    segments.append({
                        'start': segment['start'],
                        'end': segment['end'],
                        'text': segment['text'].strip(),
                        'words': segment.get('words', [])
                    })
            elif 'words' in transcription:
                # Ğ“Ñ€ÑƒĞ¿Ğ¿Ğ¸Ñ€ÑƒĞµĞ¼ ÑĞ»Ğ¾Ğ²Ğ° Ğ² ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ 10 ÑĞµĞºÑƒĞ½Ğ´
                current_segment = {'start': 0, 'end': 0, 'text': '', 'words': []}
                
                for word in transcription['words']:
                    if word['end'] - current_segment['start'] > 10:
                        if current_segment['text']:
                            segments.append(current_segment)
                        current_segment = {
                            'start': word['start'],
                            'end': word['end'],
                            'text': word['word'],
                            'words': [word]
                        }
                    else:
                        current_segment['end'] = word['end']
                        current_segment['text'] += ' ' + word['word']
                        current_segment['words'].append(word)
                
                if current_segment['text']:
                    segments.append(current_segment)
        
        elif method == "assemblyai":
            # AssemblyAI Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚
            if 'words' in transcription:
                current_segment = {'start': 0, 'end': 0, 'text': '', 'words': []}
                
                for word in transcription['words']:
                    if word['end'] - current_segment['start'] > 10:
                        if current_segment['text']:
                            segments.append(current_segment)
                        current_segment = {
                            'start': word['start'] / 1000,  # ĞšĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ Ğ² ÑĞµĞºÑƒĞ½Ğ´Ñ‹
                            'end': word['end'] / 1000,
                            'text': word['text'],
                            'words': [word]
                        }
                    else:
                        current_segment['end'] = word['end'] / 1000
                        current_segment['text'] += ' ' + word['text']
                        current_segment['words'].append(word)
                
                if current_segment['text']:
                    segments.append(current_segment)
        
        return segments
    
    def align_text_with_audio(self, text_file: str, audio_file: str, 
                             output_file: str = None) -> bool:
        """
        Ğ¡Ğ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ Ñ‚ĞµĞºÑÑ‚ Ñ Ğ°ÑƒĞ´Ğ¸Ğ¾ Ñ‡ĞµÑ€ĞµĞ· Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ñ
        
        Args:
            text_file: Ğ¤Ğ°Ğ¹Ğ» Ñ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ¼
            audio_file: ĞÑƒĞ´Ğ¸Ğ¾ Ñ„Ğ°Ğ¹Ğ»
            output_file: Ğ’Ñ‹Ñ…Ğ¾Ğ´Ğ½Ğ¾Ğ¹ Ñ„Ğ°Ğ¹Ğ» Ñ Ñ‚Ğ°Ğ¹Ğ¼ÑÑ‚Ğ°Ğ¼Ğ¿Ğ°Ğ¼Ğ¸
            
        Returns:
            True ĞµÑĞ»Ğ¸ ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ ÑƒÑĞ¿ĞµÑˆĞ½Ğ°
        """
        start_time = time.time()
        
        try:
            # Ğ§Ğ¸Ñ‚Ğ°ĞµĞ¼ Ñ‚ĞµĞºÑÑ‚
            with open(text_file, 'r', encoding='utf-8') as f:
                text_content = f.read()
            
            print(f"ğŸ“– Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½ Ñ‚ĞµĞºÑÑ‚: {text_file}")
            print(f"ğŸµ ĞÑƒĞ´Ğ¸Ğ¾ Ñ„Ğ°Ğ¹Ğ»: {audio_file}")
            
            # ĞŸÑ€Ğ¾Ğ±ÑƒĞµĞ¼ Ñ€Ğ°Ğ·Ğ½Ñ‹Ğµ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹ Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ğ¸
            transcription = None
            method = "unknown"
            
            # 1. ĞŸÑ€Ğ¾Ğ±ÑƒĞµĞ¼ OpenRouter
            if self.openrouter_api_key:
                print("ğŸ”„ ĞŸÑ€Ğ¾Ğ±ÑƒĞµĞ¼ Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ñ Ñ‡ĞµÑ€ĞµĞ· OpenRouter...")
                transcription = self.transcribe_with_openrouter(audio_file)
                if transcription:
                    method = "openrouter"
            
            # 2. ĞŸÑ€Ğ¾Ğ±ÑƒĞµĞ¼ Whisper API
            if not transcription and self.whisper_api_key:
                print("ğŸ”„ ĞŸÑ€Ğ¾Ğ±ÑƒĞµĞ¼ Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ñ Ñ‡ĞµÑ€ĞµĞ· Whisper API...")
                transcription = self.transcribe_with_whisper_api(audio_file)
                if transcription:
                    method = "whisper"
            
            # 3. ĞŸÑ€Ğ¾Ğ±ÑƒĞµĞ¼ AssemblyAI
            if not transcription and self.assemblyai_key:
                print("ğŸ”„ ĞŸÑ€Ğ¾Ğ±ÑƒĞµĞ¼ Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ñ Ñ‡ĞµÑ€ĞµĞ· AssemblyAI...")
                transcription = self.transcribe_with_assemblyai(audio_file)
                if transcription:
                    method = "assemblyai"
            
            if not transcription:
                print("âŒ ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ÑŒ Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ñ Ğ½Ğ¸ Ğ¾Ğ´Ğ½Ğ¸Ğ¼ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ¼")
                return False
            
            # Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ñ‹
            segments = self.create_segments_from_transcription(transcription, method)
            
            if not segments:
                print("âŒ ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ ÑĞ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¸Ğ· Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ğ¸")
                return False
            
            # Ğ Ğ°Ğ·Ğ±Ğ¸Ğ²Ğ°ĞµĞ¼ Ñ‚ĞµĞºÑÑ‚ Ğ½Ğ° Ñ„Ñ€Ğ°Ğ³Ğ¼ĞµĞ½Ñ‚Ñ‹
            text_fragments = self.split_text_into_fragments(text_content)
            
            # Ğ¡Ğ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµĞ¼ Ñ‚ĞµĞºÑÑ‚ Ñ ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ°Ğ¼Ğ¸
            aligned_content = self.sync_text_with_segments(text_fragments, segments)
            
            # ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼ Ğ²Ñ‹Ñ…Ğ¾Ğ´Ğ½Ğ¾Ğ¹ Ñ„Ğ°Ğ¹Ğ»
            if not output_file:
                output_file = f"{Path(text_file).stem}_aligned.json"
            
            # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚
            result = {
                'metadata': {
                    'text_file': text_file,
                    'audio_file': audio_file,
                    'transcription_method': method,
                    'aligned_at': datetime.now().isoformat(),
                    'total_segments': len(segments),
                    'total_fragments': len(text_fragments)
                },
                'segments': segments,
                'aligned_content': aligned_content,
                'statistics': {
                    'audio_duration': segments[-1]['end'] if segments else 0,
                    'transcription_time': time.time() - start_time,
                    'segments_count': len(segments),
                    'total_words': sum(len(seg['text'].split()) for seg in segments)
                }
            }
            
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… Ğ¡Ğ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ°: {output_file}")
            print(f"ğŸ“Š Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ°:")
            print(f"   - Ğ¡ĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ²: {len(segments)}")
            print(f"   - Ğ¤Ñ€Ğ°Ğ³Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ñ‚ĞµĞºÑÑ‚Ğ°: {len(text_fragments)}")
            print(f"   - Ğ”Ğ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ°ÑƒĞ´Ğ¸Ğ¾: {result['statistics']['audio_duration']:.1f} ÑĞµĞº")
            print(f"   - Ğ’Ñ€ĞµĞ¼Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸: {result['statistics']['transcription_time']:.1f} ÑĞµĞº")
            
            return True
            
        except Exception as e:
            print(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸: {e}")
            return False
    
    def split_text_into_fragments(self, text: str) -> List[str]:
        """Ğ Ğ°Ğ·Ğ±Ğ¸Ğ²Ğ°ĞµÑ‚ Ñ‚ĞµĞºÑÑ‚ Ğ½Ğ° Ñ„Ñ€Ğ°Ğ³Ğ¼ĞµĞ½Ñ‚Ñ‹"""
        # Ğ˜Ñ‰ĞµĞ¼ Ñ„Ñ€Ğ°Ğ³Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ñƒ "Ğ¤Ñ€Ğ°Ğ³Ğ¼ĞµĞ½Ñ‚ X"
        pattern = r'(?:##? )?Ğ¤Ñ€Ğ°Ğ³Ğ¼ĞµĞ½Ñ‚ \d+\s*\n(.*?)(?=\n(?:##? )?Ğ¤Ñ€Ğ°Ğ³Ğ¼ĞµĞ½Ñ‚|\Z)'
        matches = re.findall(pattern, text, re.DOTALL)
        
        if matches:
            return [match.strip() for match in matches]
        else:
            # Ğ•ÑĞ»Ğ¸ Ñ„Ñ€Ğ°Ğ³Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ñ‹, Ñ€Ğ°Ğ·Ğ±Ğ¸Ğ²Ğ°ĞµĞ¼ Ğ¿Ğ¾ Ğ°Ğ±Ğ·Ğ°Ñ†Ğ°Ğ¼
            paragraphs = text.split('\n\n')
            return [p.strip() for p in paragraphs if p.strip()]
    
    def sync_text_with_segments(self, text_fragments: List[str], 
                               segments: List[Dict]) -> List[Dict]:
        """
        Ğ¡Ğ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ Ñ„Ñ€Ğ°Ğ³Ğ¼ĞµĞ½Ñ‚Ñ‹ Ñ‚ĞµĞºÑÑ‚Ğ° Ñ Ğ°ÑƒĞ´Ğ¸Ğ¾ ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ°Ğ¼Ğ¸
        
        Args:
            text_fragments: Ğ¤Ñ€Ğ°Ğ³Ğ¼ĞµĞ½Ñ‚Ñ‹ Ñ‚ĞµĞºÑÑ‚Ğ°
            segments: Ğ¡ĞµĞ³Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ°ÑƒĞ´Ğ¸Ğ¾ Ñ Ñ‚Ğ°Ğ¹Ğ¼ÑÑ‚Ğ°Ğ¼Ğ¿Ğ°Ğ¼Ğ¸
            
        Returns:
            Ğ¡Ğ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚
        """
        aligned_content = []
        
        # ĞŸÑ€Ğ¾ÑÑ‚Ğ°Ñ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ: Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼ Ñ„Ñ€Ğ°Ğ³Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸
        total_duration = segments[-1]['end'] if segments else 0
        fragment_duration = total_duration / len(text_fragments) if text_fragments else 0
        
        for i, fragment in enumerate(text_fragments):
            start_time = i * fragment_duration
            end_time = (i + 1) * fragment_duration
            
            # ĞĞ°Ñ…Ğ¾Ğ´Ğ¸Ğ¼ ÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğµ ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ñ‹
            matching_segments = [
                seg for seg in segments 
                if seg['start'] >= start_time and seg['end'] <= end_time
            ]
            
            aligned_content.append({
                'fragment_number': i + 1,
                'text': fragment,
                'start_time': start_time,
                'end_time': end_time,
                'duration': end_time - start_time,
                'matching_segments': matching_segments,
                'transcribed_text': ' '.join(seg['text'] for seg in matching_segments)
            })
        
        return aligned_content


def main():
    parser = argparse.ArgumentParser(
        description="Ğ¢Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ñ Ğ°ÑƒĞ´Ğ¸Ğ¾ Ğ¸ ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ñ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ¼",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ĞŸÑ€Ğ¸Ğ¼ĞµÑ€Ñ‹ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ:
  python audio_transcriber.py text.txt audio.mp3
  python audio_transcriber.py text.txt audio.mp3 -o aligned.json
  python audio_transcriber.py text.txt audio.mp3 --config config.env
        """
    )
    
    parser.add_argument('text_file', help='Ğ¤Ğ°Ğ¹Ğ» Ñ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ¼')
    parser.add_argument('audio_file', help='ĞÑƒĞ´Ğ¸Ğ¾ Ñ„Ğ°Ğ¹Ğ»')
    parser.add_argument('-o', '--output', help='Ğ’Ñ‹Ñ…Ğ¾Ğ´Ğ½Ğ¾Ğ¹ Ñ„Ğ°Ğ¹Ğ» Ñ Ñ‚Ğ°Ğ¹Ğ¼ÑÑ‚Ğ°Ğ¼Ğ¿Ğ°Ğ¼Ğ¸')
    parser.add_argument('--config', help='Ğ¤Ğ°Ğ¹Ğ» ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¸ .env')
    
    args = parser.parse_args()
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ²Ñ…Ğ¾Ğ´Ğ½Ñ‹Ğµ Ñ„Ğ°Ğ¹Ğ»Ñ‹
    if not Path(args.text_file).exists():
        print(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ°: Ğ¤Ğ°Ğ¹Ğ» {args.text_file} Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½")
        return 1
    
    if not Path(args.audio_file).exists():
        print(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ°: Ğ¤Ğ°Ğ¹Ğ» {args.audio_file} Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½")
        return 1
    
    try:
        # Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ°Ğ¹Ğ±ĞµÑ€
        transcriber = AudioTranscriber(args.config)
        
        # Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½ÑĞµĞ¼ ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ
        success = transcriber.align_text_with_audio(
            args.text_file,
            args.audio_file,
            args.output
        )
        
        if success:
            print("âœ… Ğ¡Ğ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ° ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾!")
        else:
            print("âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸")
            return 1
        
        return 0
        
    except Exception as e:
        print(f"âŒ ĞĞµĞ¾Ğ¶Ğ¸Ğ´Ğ°Ğ½Ğ½Ğ°Ñ Ğ¾ÑˆĞ¸Ğ±ĞºĞ°: {e}")
        return 1


if __name__ == "__main__":
    exit(main()) 